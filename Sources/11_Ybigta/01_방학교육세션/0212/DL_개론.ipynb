{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL 개론.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "L1iRv6yroAKJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "    <img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/02/pytorch-logo-flat-300x210.png\">\n",
        "</p>\n",
        "\n",
        "다양한 딥러닝 프레임워크가 있지만 오늘은 파이토치를 CIFAR-10 데이터셋에 이용해 간단한 MLP를 실습해보겠습니다.\n",
        "\n",
        "파이토치는 파이썬에서 그냥 `torch` 라는 이름으로 불러올 수 있습니다.\n",
        "\n",
        "구글 콜랩에 기본적으로 설치가 안되어있을수도 있으니 먼저 설치해줄게요"
      ]
    },
    {
      "metadata": {
        "id": "Y0yk6uvtmj8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "59484e15-49b6-4ecb-8b3b-4d0a05a57570"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch  # Requirement already satisfied 라고 뜨는걸 보니 요즘엔 기본적으로 깔려오는가 보네요\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz  # CIFAR-10 데이터를 받아옵니다\n",
        "!tar -xvzf cifar-10-python.tar.gz  # 압축을 풀어줄게요"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "--2019-02-12 07:06:14--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  5.41MB/s    in 18s     \n",
            "\n",
            "2019-02-12 07:06:32 (9.16 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_9yirhlUyhfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db76296f-73b2-4a3a-83ab-fd43bc3d3551"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py  cifar-10-python.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D6ayDUDtpi6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "84eab71f-a690-4148-d287-e5269dfe6aba"
      },
      "cell_type": "code",
      "source": [
        "!ls -l cifar-10-batches-py  # 구조를 한번 볼게요. data_batch_x가 5개 있는데 데이터 설명에 의하면 피클링된 딕셔너리라고 합니다."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 181876\n",
            "-rw-r--r-- 1 2156 1103      158 Mar 31  2009 batches.meta\n",
            "-rw-r--r-- 1 2156 1103 31035704 Mar 31  2009 data_batch_1\n",
            "-rw-r--r-- 1 2156 1103 31035320 Mar 31  2009 data_batch_2\n",
            "-rw-r--r-- 1 2156 1103 31035999 Mar 31  2009 data_batch_3\n",
            "-rw-r--r-- 1 2156 1103 31035696 Mar 31  2009 data_batch_4\n",
            "-rw-r--r-- 1 2156 1103 31035623 Mar 31  2009 data_batch_5\n",
            "-rw-r--r-- 1 2156 1103       88 Jun  4  2009 readme.html\n",
            "-rw-r--r-- 1 2156 1103 31035526 Mar 31  2009 test_batch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2B19cBpk0mQL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "Zv1zP0bNs8zQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 그럼 unpickling을 할 수 있도록 함수를 짜줍시다\n",
        "\n",
        "import pickle, os\n",
        "\n",
        "def unpickle(fpath):\n",
        "    with open(fpath, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89Bo1c5DoWgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "base_path = 'cifar-10-batches-py'\n",
        "fname = 'data_batch_1'  # 튜토리얼이니 간단하게 1번 데이터셋만 써봅시다\n",
        "\n",
        "fpath = os.path.join(base_path, fname)\n",
        "dict_ = unpickle(fpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UffUB_7hzOiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "909e549e-5c8d-41b1-c532-752ee289a2e9"
      },
      "cell_type": "code",
      "source": [
        "dict_.keys()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "mDXv3uEyzP34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7adeef73-585b-410d-ed32-d3632fd8ed63"
      },
      "cell_type": "code",
      "source": [
        "X_train = dict_[b'data']\n",
        "y_list  = dict_[b'labels']\n",
        "\n",
        "n_row, n_dim = X_train.shape\n",
        "n_cls = 10\n",
        "\n",
        "y_true  = np.zeros((n_row, n_cls), dtype=np.uint8)\n",
        "y_true[np.arange(n_row), y_list] = 1\n",
        "\n",
        "\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_true.shape:  ', y_true.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape:  (10000, 3072)\n",
            "y_true.shape:   (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TbCaha7v27qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c9871895-4422-4640-8c5e-0adf482b5e13"
      },
      "cell_type": "code",
      "source": [
        "# 제대로 됐는지 확인\n",
        "y_true[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "UQKLZ5r551Hs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 데이터 10000개에 대해 매번 경사를 구하기는 힘드니, 미니배치를 사용할 수 있게 함수를 짜줍니다\n",
        "\n",
        "def minibatch(X, y, size):\n",
        "    nrow = X.shape[0]\n",
        "    idx = np.random.choice(np.arange(nrow), size)\n",
        "    return X[idx], y[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtsXJyCO0to7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (아주 간단한) 시각화"
      ]
    },
    {
      "metadata": {
        "id": "Jld2q_Ckt5EG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "37967ea4-6522-445d-bfb5-3a16b0ca2821"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = 1  # 시각화하려는 데이터 번호\n",
        "img = X_train[idx].reshape([3,32,32]).transpose([1,2,0])\n",
        "label = y_true[idx]\n",
        "\n",
        "print('label:', label)\n",
        "plt.figure(figsize=(1.5,1.5))\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: [0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe691d9bac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABzCAYAAABEgVbYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 108x108 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bniCProFzyE4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 모델링\n",
        "\n",
        "```\n",
        "# 기본 골자\n",
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "dW5xmoYH07td",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/nn.html#linear-layers\n",
        "\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.layer = nn.Linear(n_in, n_out)  # W가 랜덤으로 생성됨\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.tensor(x, dtype=torch.float32)\n",
        "        x = self.layer(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rfKpUuz4Chm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LinearClassifier(n_dim, n_cls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNaDd7v97HWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch = minibatch(X_train, y_true, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulY2hX9u7hSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "98291c9d-53b9-4488-f7a0-237d293daa30"
      },
      "cell_type": "code",
      "source": [
        "output = model(X_batch)\n",
        "print('Output shape:', output.shape)\n",
        "print('Actual output:\\n', output)  # raw class score를 logit이라고도 부릅니다. 얘네를 exponentiate 한 후 비율을 구하면 softmax의 아웃풋이 됩니다.\n",
        "print('Predicted labels:', output.argmax(dim=1))\n",
        "print('True labels:     ', np.argmax(y_batch, axis=1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([4, 10])\n",
            "Actual output:\n",
            " tensor([[ -37.1305,   59.7090,   34.6117,   17.4214,  -65.5523,   85.8139,\n",
            "          -31.1532,   59.8931,   59.7251,  -95.2393],\n",
            "        [  21.1037,  104.3964,   89.4687,   53.3366,  -36.9933,   78.6085,\n",
            "          -75.7398,   63.4855,   54.6945,  -97.7436],\n",
            "        [ -41.9172,   77.1968,  -10.9243,   10.4547,   -6.6623,    3.9538,\n",
            "          -98.5574,   31.5553,  -26.6848, -150.1195],\n",
            "        [ -17.7222,   42.6076,   49.5088,  -19.9929,  -28.9665,   27.0795,\n",
            "           -7.9767,    5.3331,   35.8892,  -81.9889]], grad_fn=<AddmmBackward>)\n",
            "Predicted labels: tensor([5, 1, 1, 2])\n",
            "True labels:      [4 0 5 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I9mIGuEg_kZX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining Optimizer\n",
        "\n",
        "발표에서는 backprop을 통해 W에 대한 경사를 구하고, 그 경사를 다시 W에 적용해야 한다고 말씀드렸는데, 대부분의 딥러닝 프레임워크들은 이 과정을 옵티마이저라는 클래스를 통해 아주 간단하게 구현할 수 있도록 기능을 제공하고 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "Oigfq1vq_yNH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "neKY8lpS87og",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining Loss\n",
        "\n",
        "Forward inference는 간단하게 되도록 짰습니다. 하지만 아직 Linear 레이어의 가중치들 (W)이 랜덤으로 생성돼서 그런지 예측값들이 영 별로네요.\n",
        "\n",
        "이제는 Loss를 정의하고 Loss를 W에 대해 경사를 구한 후, 경사를 바탕으로 W를 업데이트 하는 과정을 짜보겠습니다"
      ]
    },
    {
      "metadata": {
        "id": "ToSI3D7r9csh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "loss = criterion(output, torch.tensor(y_batch, dtype=torch.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvuHxYcI98Kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8IHg-xMA1aV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](http://cs231n.github.io/assets/stepsize.jpg)\n",
        "\n",
        "위 코드에서 `step()`을 한번 하면, 사진에서 화살표 방향으로 조금 움직인거라 생각하시면 됩니다.\n",
        "\n",
        "파란지점이 loss가 최소화되는 지점이라 생각하면, 이번 한번의 `step()`으로는 아직 갈길이 멀죠.\n",
        "\n",
        "따라서 딥러닝을 할때는 아래의 과정을 루프로 돌리며 계속 계산을 하게 됩니다.\n",
        "\n",
        "1. 미니배치를 뽑음\n",
        "2. score 계산\n",
        "3. loss 계산\n",
        "4. loss를 W에 대해 backprop\n",
        "5. `optimizer.step()`"
      ]
    },
    {
      "metadata": {
        "id": "stgyXdrzBxH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeNwRxcTCGJr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 루프로 돌려보자"
      ]
    },
    {
      "metadata": {
        "id": "sJp48g2sCHry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_steps = 10000\n",
        "batch_size = 64\n",
        "\n",
        "for i in range(n_steps):\n",
        "    X_batch, y_batch = minibatch(X_train, y_true, batch_size)\n",
        "    output = model(X_batch)\n",
        "    loss = criterion(output, torch.tensor(y_batch, dtype=torch.float32))\n",
        "    if i % 500 == 0:\n",
        "        print(f'Step [{i} / {n_steps}] | loss: {loss}')\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbqfHSTdCsND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_X, sample_y = minibatch(X_train, y_true, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQiKib8DD8NH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f1658fe8-4aa7-4ac4-845d-870de846e50f"
      },
      "cell_type": "code",
      "source": [
        "img = sample_X.reshape(3,32,32).transpose([1,2,0])\n",
        "print('label:', sample_y.argmax(axis=1))\n",
        "plt.figure(figsize=(1.5,1.5))\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe690405940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABzCAYAAABEgVbYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npCVwE2kJ3ERaAjeRlsBNpCX4N1T6KNSFpBgZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 108x108 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wjvYcYOVEDg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9a050f4-dc5a-4e10-91ad-1032c3fef8b8"
      },
      "cell_type": "code",
      "source": [
        "model(sample_X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -677.8120,  -742.8472, -1987.2703,   259.4281,  -737.1789, -1394.9772,\n",
              "         -2199.3174,  -124.6948,  -693.7646,   408.6739]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "a0gfKV8_E1zv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Checking accuracy"
      ]
    },
    {
      "metadata": {
        "id": "nusr7-1CE3lT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06b7af0e-0567-4afb-c7af-2143a34aab7a"
      },
      "cell_type": "code",
      "source": [
        "total = model(X_train)\n",
        "pred = total.argmax(dim=1).numpy()\n",
        "(np.array(y_list) - pred == 0).sum() / n_row  # accuracy on train set"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ev_Ls_mFwYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ]
    },
    {
      "metadata": {
        "id": "-fE5QZ2WFxUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(MLP, self).__init__()\n",
        "        self.h = 400  # number of hidden units\n",
        "        \n",
        "        # ------ TODO: define three nn.Linear layers ------- #\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        # -------------------------------------------------- #\n",
        "        \n",
        "        # ---------- TODO: define a ReLU function ---------- #\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        # -------------------------------------------------- #\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.tensor(x, dtype=torch.float32).to(device)\n",
        "            \n",
        "        # --- TODO: forward propagate through the layers --- #\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        # -------------------------------------------------- #\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOiiMuX9GS7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MLP(n_dim, n_cls).to(device)  # device가 지금은 'cuda'라서 GPU에서 돌아요!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pzx8f1CyGVw_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/optim.html  여기 참고해서 어떤 옵티마이저가 있는지 한번 확인해보세요!\n",
        "optimizer = pass # define optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQgu7SJUGkcR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/nn.html#loss-functions  여기에서 loss function들은 어떻게 있는지 확인해보세요!\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrRifROyGox4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "91939b35-92c9-44bb-87bf-2c514c81b8da"
      },
      "cell_type": "code",
      "source": [
        "n_steps = 30000\n",
        "batch_size = 64\n",
        "\n",
        "for i in range(n_steps):\n",
        "    X_batch, y_batch = minibatch(X_train, y_true, batch_size)\n",
        "    output = model(X_batch)\n",
        "    loss = criterion(output, torch.tensor(y_batch, dtype=torch.float32).to(device))\n",
        "    if i % 500 == 0:\n",
        "        print(f'Step [{i} / {n_steps}] | loss: {loss}')\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0 / 30000] | loss: 0.19526973366737366\n",
            "Step [500 / 30000] | loss: 0.14716064929962158\n",
            "Step [1000 / 30000] | loss: 0.15943506360054016\n",
            "Step [1500 / 30000] | loss: 0.16370323300361633\n",
            "Step [2000 / 30000] | loss: 0.16242757439613342\n",
            "Step [2500 / 30000] | loss: 0.16038461029529572\n",
            "Step [3000 / 30000] | loss: 0.13436144590377808\n",
            "Step [3500 / 30000] | loss: 0.1369234323501587\n",
            "Step [4000 / 30000] | loss: 0.16454572975635529\n",
            "Step [4500 / 30000] | loss: 0.14131863415241241\n",
            "Step [5000 / 30000] | loss: 0.11575169861316681\n",
            "Step [5500 / 30000] | loss: 0.13749276101589203\n",
            "Step [6000 / 30000] | loss: 0.16824816167354584\n",
            "Step [6500 / 30000] | loss: 0.1504296213388443\n",
            "Step [7000 / 30000] | loss: 0.14504443109035492\n",
            "Step [7500 / 30000] | loss: 0.1387624442577362\n",
            "Step [8000 / 30000] | loss: 0.14606936275959015\n",
            "Step [8500 / 30000] | loss: 0.13666744530200958\n",
            "Step [9000 / 30000] | loss: 0.17618730664253235\n",
            "Step [9500 / 30000] | loss: 0.14012610912322998\n",
            "Step [10000 / 30000] | loss: 0.15798698365688324\n",
            "Step [10500 / 30000] | loss: 0.12516506016254425\n",
            "Step [11000 / 30000] | loss: 0.12744192779064178\n",
            "Step [11500 / 30000] | loss: 0.12794189155101776\n",
            "Step [12000 / 30000] | loss: 0.15526609122753143\n",
            "Step [12500 / 30000] | loss: 0.15357346832752228\n",
            "Step [13000 / 30000] | loss: 0.11539991199970245\n",
            "Step [13500 / 30000] | loss: 0.12265700101852417\n",
            "Step [14000 / 30000] | loss: 0.14784252643585205\n",
            "Step [14500 / 30000] | loss: 0.1264747828245163\n",
            "Step [15000 / 30000] | loss: 0.12831024825572968\n",
            "Step [15500 / 30000] | loss: 0.1462067812681198\n",
            "Step [16000 / 30000] | loss: 0.15824608504772186\n",
            "Step [16500 / 30000] | loss: 0.1275448054075241\n",
            "Step [17000 / 30000] | loss: 0.15858912467956543\n",
            "Step [17500 / 30000] | loss: 0.139792799949646\n",
            "Step [18000 / 30000] | loss: 0.12258657068014145\n",
            "Step [18500 / 30000] | loss: 0.1315537393093109\n",
            "Step [19000 / 30000] | loss: 0.11633457988500595\n",
            "Step [19500 / 30000] | loss: 0.1534554660320282\n",
            "Step [20000 / 30000] | loss: 0.14331158995628357\n",
            "Step [20500 / 30000] | loss: 0.10822656005620956\n",
            "Step [21000 / 30000] | loss: 0.13262958824634552\n",
            "Step [21500 / 30000] | loss: 0.1481359899044037\n",
            "Step [22000 / 30000] | loss: 0.13909807801246643\n",
            "Step [22500 / 30000] | loss: 0.13209882378578186\n",
            "Step [23000 / 30000] | loss: 0.14385388791561127\n",
            "Step [23500 / 30000] | loss: 0.13886316120624542\n",
            "Step [24000 / 30000] | loss: 0.1380540132522583\n",
            "Step [24500 / 30000] | loss: 0.11469727009534836\n",
            "Step [25000 / 30000] | loss: 0.10505304485559464\n",
            "Step [25500 / 30000] | loss: 0.1383785456418991\n",
            "Step [26000 / 30000] | loss: 0.1293141394853592\n",
            "Step [26500 / 30000] | loss: 0.1175922378897667\n",
            "Step [27000 / 30000] | loss: 0.12207193672657013\n",
            "Step [27500 / 30000] | loss: 0.12221045792102814\n",
            "Step [28000 / 30000] | loss: 0.14241249859333038\n",
            "Step [28500 / 30000] | loss: 0.14030030369758606\n",
            "Step [29000 / 30000] | loss: 0.12482626736164093\n",
            "Step [29500 / 30000] | loss: 0.12636293470859528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P6GmsL9WGsRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85d256ef-cb31-4616-84db-df69e9cf6ec6"
      },
      "cell_type": "code",
      "source": [
        "total = model(X_train)\n",
        "pred = total.argmax(dim=1).cpu().numpy()\n",
        "(np.array(y_list) - pred == 0).sum() / n_row  # accuracy on train set"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "MILa_7EUJzzT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### On test set"
      ]
    },
    {
      "metadata": {
        "id": "0WklF-zsHZXJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_ = unpickle(os.path.join(base_path,'test_batch'))\n",
        "X_test = data_[b'data']\n",
        "y_test = np.array(data_[b'labels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0DdJ4RpJheR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46906ede-22b3-41ca-9f4a-520530e70f79"
      },
      "cell_type": "code",
      "source": [
        "total = model(X_test)\n",
        "pred = total.argmax(dim=1).cpu().numpy()\n",
        "(y_test - pred == 0).sum() / X_test.shape[0]  # accuracy on train set"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "6i2adlT1J5Ll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") #Needed to save figures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "\n",
    "# Gather some features\n",
    "def build_features(features, data):\n",
    "    # remove NaNs\n",
    "    #data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment']) #, 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    #data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "\n",
    "    # CompetionOpen en PromoOpen from https://www.kaggle.com/ananya77041/rossmann-store-sales/randomforestpython/code\n",
    "    # Calculate time competition open time in months\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique()[1:4]:\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training, test and store data using pandas\n",
      "Assume store open, if not provided\n",
      "Consider only open stores for training. Closed stores wont count into the score.\n",
      "Use only Sales bigger then zero. Simplifies calculation of rmspe\n",
      "Join with store\n",
      "augment features\n",
      "['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday', 'StoreType', 'Assortment', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n",
      "training data processed\n"
     ]
    }
   ],
   "source": [
    "## Start of main script\n",
    "\n",
    "print(\"Load the training, test and store data using pandas\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "         'StateHoliday': np.dtype(str),\n",
    "         'Promo2SinceWeek': np.dtype(int),\n",
    "         'SchoolHoliday': np.dtype(int),\n",
    "         'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"Drugstore_data/train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"Drugstore_data/test.csv\", parse_dates=[3], dtype=types)\n",
    "store = pd.read_csv(\"Drugstore_data/store.csv\")\n",
    "\n",
    "print(\"Assume store open, if not provided\")\n",
    "#train.fillna(1, inplace=True)\n",
    "#test.fillna(1, inplace=True)\n",
    "\n",
    "print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n",
    "train = train[train[\"Open\"] != 0]\n",
    "print(\"Use only Sales bigger then zero. Simplifies calculation of rmspe\")\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "print(\"Join with store\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"augment features\")\n",
    "build_features(features, train)\n",
    "build_features([], test)\n",
    "print(features)\n",
    "\n",
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.01,\n",
    "          \"subsample\": 0.5,\n",
    "          \"max_depth\": 8,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 4428\n",
    "          }\n",
    "num_boost_round = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a XGBoost model\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a XGBoost model\")\n",
    "\n",
    "X_train = train[(train['Date'] <= '2014-12-31')] \n",
    "X_valid = train[(train['Date'] > '2014-12-31')]\n",
    "y_train = np.log1p(X_train.Sales)\n",
    "y_valid = np.log1p(X_valid.Sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:7.43672\teval-rmse:7.46565\ttrain-rmspe:0.999524\teval-rmspe:0.999541\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:6.69467\teval-rmse:6.72452\ttrain-rmspe:0.998819\teval-rmspe:0.998861\n",
      "[2]\ttrain-rmse:6.02696\teval-rmse:6.05737\ttrain-rmspe:0.997545\teval-rmspe:0.997634\n",
      "[3]\ttrain-rmse:5.42611\teval-rmse:5.45744\ttrain-rmspe:0.995404\teval-rmspe:0.99557\n",
      "[4]\ttrain-rmse:4.88535\teval-rmse:4.91669\ttrain-rmspe:0.992027\teval-rmspe:0.992309\n",
      "[5]\ttrain-rmse:4.39887\teval-rmse:4.42944\ttrain-rmspe:0.986971\teval-rmspe:0.987412\n",
      "[6]\ttrain-rmse:3.96088\teval-rmse:3.99184\ttrain-rmspe:0.979826\teval-rmspe:0.980496\n",
      "[7]\ttrain-rmse:3.56702\teval-rmse:3.59807\ttrain-rmspe:0.970092\teval-rmspe:0.971061\n",
      "[8]\ttrain-rmse:3.21272\teval-rmse:3.2423\ttrain-rmspe:0.95741\teval-rmspe:0.958696\n",
      "[9]\ttrain-rmse:2.89407\teval-rmse:2.92322\ttrain-rmspe:0.941499\teval-rmspe:0.943187\n",
      "[10]\ttrain-rmse:2.60737\teval-rmse:2.63595\ttrain-rmspe:0.92222\teval-rmspe:0.924356\n",
      "[11]\ttrain-rmse:2.34962\teval-rmse:2.37721\ttrain-rmspe:0.899508\teval-rmspe:0.902084\n",
      "[12]\ttrain-rmse:2.11725\teval-rmse:2.14524\ttrain-rmspe:0.873665\teval-rmspe:0.876865\n",
      "[13]\ttrain-rmse:1.90841\teval-rmse:1.93511\ttrain-rmspe:0.84478\teval-rmspe:0.848331\n",
      "[14]\ttrain-rmse:1.72061\teval-rmse:1.74704\ttrain-rmspe:0.813245\teval-rmspe:0.817325\n",
      "[15]\ttrain-rmse:1.552\teval-rmse:1.57706\ttrain-rmspe:0.779409\teval-rmspe:0.783603\n",
      "[16]\ttrain-rmse:1.39918\teval-rmse:1.42461\ttrain-rmspe:0.744226\teval-rmspe:0.748942\n",
      "[17]\ttrain-rmse:1.26289\teval-rmse:1.28767\ttrain-rmspe:0.707331\teval-rmspe:0.71231\n",
      "[18]\ttrain-rmse:1.13929\teval-rmse:1.16476\ttrain-rmspe:0.670127\teval-rmspe:0.675743\n",
      "[19]\ttrain-rmse:1.02913\teval-rmse:1.05465\ttrain-rmspe:0.63216\teval-rmspe:0.638462\n",
      "[20]\ttrain-rmse:0.930408\teval-rmse:0.956474\ttrain-rmspe:0.594377\teval-rmspe:0.601502\n",
      "[21]\ttrain-rmse:0.841423\teval-rmse:0.868984\ttrain-rmspe:0.557326\teval-rmspe:0.565558\n",
      "[22]\ttrain-rmse:0.760996\teval-rmse:0.789194\ttrain-rmspe:0.521278\teval-rmspe:0.530577\n",
      "[23]\ttrain-rmse:0.68848\teval-rmse:0.719912\ttrain-rmspe:0.486582\teval-rmspe:0.498019\n",
      "[24]\ttrain-rmse:0.624595\teval-rmse:0.657801\ttrain-rmspe:0.453206\teval-rmspe:0.466511\n",
      "[25]\ttrain-rmse:0.566708\teval-rmse:0.602063\ttrain-rmspe:0.421407\teval-rmspe:0.437077\n",
      "[26]\ttrain-rmse:0.514406\teval-rmse:0.553051\ttrain-rmspe:0.391236\teval-rmspe:0.410119\n",
      "[27]\ttrain-rmse:0.467023\teval-rmse:0.507999\ttrain-rmspe:0.362939\teval-rmspe:0.384633\n",
      "[28]\ttrain-rmse:0.425254\teval-rmse:0.469415\ttrain-rmspe:0.336573\teval-rmspe:0.361933\n",
      "[29]\ttrain-rmse:0.38794\teval-rmse:0.43565\ttrain-rmspe:0.31204\teval-rmspe:0.341624\n",
      "[30]\ttrain-rmse:0.354273\teval-rmse:0.404604\ttrain-rmspe:0.289402\teval-rmspe:0.322833\n",
      "[31]\ttrain-rmse:0.3245\teval-rmse:0.378743\ttrain-rmspe:0.268807\teval-rmspe:0.306958\n",
      "[32]\ttrain-rmse:0.297485\teval-rmse:0.355539\ttrain-rmspe:0.249715\teval-rmspe:0.293049\n",
      "[33]\ttrain-rmse:0.2736\teval-rmse:0.335997\ttrain-rmspe:0.232374\teval-rmspe:0.28129\n",
      "[34]\ttrain-rmse:0.252286\teval-rmse:0.318734\ttrain-rmspe:0.216503\teval-rmspe:0.271203\n",
      "[35]\ttrain-rmse:0.233009\teval-rmse:0.303612\ttrain-rmspe:0.202069\teval-rmspe:0.262163\n",
      "[36]\ttrain-rmse:0.215978\teval-rmse:0.290895\ttrain-rmspe:0.189179\teval-rmspe:0.255057\n",
      "[37]\ttrain-rmse:0.200511\teval-rmse:0.2788\ttrain-rmspe:0.177453\teval-rmspe:0.248348\n",
      "[38]\ttrain-rmse:0.18663\teval-rmse:0.269025\ttrain-rmspe:0.16675\teval-rmspe:0.243312\n",
      "[39]\ttrain-rmse:0.173825\teval-rmse:0.259512\ttrain-rmspe:0.156778\teval-rmspe:0.23804\n",
      "[40]\ttrain-rmse:0.16307\teval-rmse:0.252144\ttrain-rmspe:0.148094\teval-rmspe:0.23484\n",
      "[41]\ttrain-rmse:0.153403\teval-rmse:0.246167\ttrain-rmspe:0.140248\teval-rmspe:0.232013\n",
      "[42]\ttrain-rmse:0.145194\teval-rmse:0.241051\ttrain-rmspe:0.133755\teval-rmspe:0.230163\n",
      "[43]\ttrain-rmse:0.137697\teval-rmse:0.236096\ttrain-rmspe:0.127794\teval-rmspe:0.228193\n",
      "[44]\ttrain-rmse:0.131365\teval-rmse:0.232387\ttrain-rmspe:0.122766\teval-rmspe:0.227016\n",
      "[45]\ttrain-rmse:0.125098\teval-rmse:0.228266\ttrain-rmspe:0.117753\teval-rmspe:0.225237\n",
      "[46]\ttrain-rmse:0.119232\teval-rmse:0.225117\ttrain-rmspe:0.112887\teval-rmspe:0.224287\n",
      "[47]\ttrain-rmse:0.113911\teval-rmse:0.222736\ttrain-rmspe:0.108407\teval-rmspe:0.223977\n",
      "[48]\ttrain-rmse:0.109146\teval-rmse:0.220469\ttrain-rmspe:0.10444\teval-rmspe:0.223409\n",
      "[49]\ttrain-rmse:0.104848\teval-rmse:0.21792\ttrain-rmspe:0.10091\teval-rmspe:0.222403\n",
      "[50]\ttrain-rmse:0.100994\teval-rmse:0.216113\ttrain-rmspe:0.097634\teval-rmspe:0.221913\n",
      "[51]\ttrain-rmse:0.09813\teval-rmse:0.214453\ttrain-rmspe:0.095401\teval-rmspe:0.221463\n",
      "[52]\ttrain-rmse:0.095228\teval-rmse:0.212806\ttrain-rmspe:0.093039\teval-rmspe:0.22084\n",
      "[53]\ttrain-rmse:0.092488\teval-rmse:0.211542\ttrain-rmspe:0.090712\teval-rmspe:0.220555\n",
      "[54]\ttrain-rmse:0.089983\teval-rmse:0.210305\ttrain-rmspe:0.088603\teval-rmspe:0.220308\n",
      "[55]\ttrain-rmse:0.087268\teval-rmse:0.209347\ttrain-rmspe:0.08617\teval-rmspe:0.220335\n",
      "[56]\ttrain-rmse:0.085065\teval-rmse:0.20821\ttrain-rmspe:0.084268\teval-rmspe:0.219938\n",
      "[57]\ttrain-rmse:0.083239\teval-rmse:0.207113\ttrain-rmspe:0.082753\teval-rmspe:0.219474\n",
      "[58]\ttrain-rmse:0.08114\teval-rmse:0.206241\ttrain-rmspe:0.080907\teval-rmspe:0.219306\n",
      "[59]\ttrain-rmse:0.079183\teval-rmse:0.205953\ttrain-rmspe:0.079082\teval-rmspe:0.219606\n",
      "[60]\ttrain-rmse:0.07769\teval-rmse:0.20516\ttrain-rmspe:0.077792\teval-rmspe:0.219409\n",
      "[61]\ttrain-rmse:0.076451\teval-rmse:0.204656\ttrain-rmspe:0.076721\teval-rmspe:0.219381\n",
      "[62]\ttrain-rmse:0.074678\teval-rmse:0.203655\ttrain-rmspe:0.075107\teval-rmspe:0.218922\n",
      "[63]\ttrain-rmse:0.073602\teval-rmse:0.203204\ttrain-rmspe:0.074147\teval-rmspe:0.21875\n",
      "[64]\ttrain-rmse:0.072301\teval-rmse:0.202537\ttrain-rmspe:0.072936\teval-rmspe:0.218473\n",
      "[65]\ttrain-rmse:0.071161\teval-rmse:0.20196\ttrain-rmspe:0.071903\teval-rmspe:0.218037\n",
      "[66]\ttrain-rmse:0.068651\teval-rmse:0.200988\ttrain-rmspe:0.069419\teval-rmspe:0.21733\n",
      "[67]\ttrain-rmse:0.067016\teval-rmse:0.200705\ttrain-rmspe:0.067788\teval-rmspe:0.217338\n",
      "[68]\ttrain-rmse:0.065034\teval-rmse:0.200144\ttrain-rmspe:0.065811\teval-rmspe:0.217022\n",
      "[69]\ttrain-rmse:0.063697\teval-rmse:0.200248\ttrain-rmspe:0.064454\teval-rmspe:0.217244\n",
      "[70]\ttrain-rmse:0.062705\teval-rmse:0.200139\ttrain-rmspe:0.063467\teval-rmspe:0.217312\n",
      "[71]\ttrain-rmse:0.062122\teval-rmse:0.19987\ttrain-rmspe:0.062928\teval-rmspe:0.217236\n",
      "[72]\ttrain-rmse:0.061181\teval-rmse:0.199636\ttrain-rmspe:0.062011\teval-rmspe:0.217254\n",
      "[73]\ttrain-rmse:0.060254\teval-rmse:0.199352\ttrain-rmspe:0.061102\teval-rmspe:0.217024\n",
      "[74]\ttrain-rmse:0.059692\teval-rmse:0.199127\ttrain-rmspe:0.060577\teval-rmspe:0.216948\n",
      "[75]\ttrain-rmse:0.058608\teval-rmse:0.199069\ttrain-rmspe:0.059464\teval-rmspe:0.216905\n",
      "[76]\ttrain-rmse:0.05789\teval-rmse:0.198772\ttrain-rmspe:0.058751\teval-rmspe:0.21671\n",
      "[77]\ttrain-rmse:0.056891\teval-rmse:0.198831\ttrain-rmspe:0.057712\teval-rmspe:0.216807\n",
      "[78]\ttrain-rmse:0.056305\teval-rmse:0.198731\ttrain-rmspe:0.057134\teval-rmspe:0.216777\n",
      "[79]\ttrain-rmse:0.055584\teval-rmse:0.198631\ttrain-rmspe:0.056419\teval-rmspe:0.216729\n",
      "[80]\ttrain-rmse:0.054494\teval-rmse:0.198548\ttrain-rmspe:0.055305\teval-rmspe:0.216712\n",
      "[81]\ttrain-rmse:0.053984\teval-rmse:0.198385\ttrain-rmspe:0.05481\teval-rmspe:0.216628\n",
      "[82]\ttrain-rmse:0.053042\teval-rmse:0.198207\ttrain-rmspe:0.053867\teval-rmspe:0.216454\n",
      "[83]\ttrain-rmse:0.052617\teval-rmse:0.198056\ttrain-rmspe:0.053446\teval-rmspe:0.216363\n",
      "[84]\ttrain-rmse:0.051711\teval-rmse:0.198068\ttrain-rmspe:0.052512\teval-rmspe:0.216429\n",
      "[85]\ttrain-rmse:0.051072\teval-rmse:0.198095\ttrain-rmspe:0.051869\teval-rmspe:0.216498\n",
      "[86]\ttrain-rmse:0.05045\teval-rmse:0.197848\ttrain-rmspe:0.051247\teval-rmspe:0.216339\n",
      "[87]\ttrain-rmse:0.050107\teval-rmse:0.197756\ttrain-rmspe:0.050911\teval-rmspe:0.216293\n",
      "[88]\ttrain-rmse:0.049135\teval-rmse:0.197823\ttrain-rmspe:0.049901\teval-rmspe:0.216385\n",
      "[89]\ttrain-rmse:0.04853\teval-rmse:0.197583\ttrain-rmspe:0.049294\teval-rmspe:0.216214\n",
      "[90]\ttrain-rmse:0.048329\teval-rmse:0.197505\ttrain-rmspe:0.049098\teval-rmspe:0.216176\n",
      "[91]\ttrain-rmse:0.047558\teval-rmse:0.197622\ttrain-rmspe:0.048302\teval-rmspe:0.21632\n",
      "[92]\ttrain-rmse:0.046702\teval-rmse:0.19739\ttrain-rmspe:0.047425\teval-rmspe:0.21615\n",
      "[93]\ttrain-rmse:0.046445\teval-rmse:0.197321\ttrain-rmspe:0.047169\teval-rmspe:0.216115\n",
      "[94]\ttrain-rmse:0.045935\teval-rmse:0.197232\ttrain-rmspe:0.046639\teval-rmspe:0.216054\n",
      "[95]\ttrain-rmse:0.045095\teval-rmse:0.197221\ttrain-rmspe:0.045762\teval-rmspe:0.215942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-rmse:0.044831\teval-rmse:0.19716\ttrain-rmspe:0.045498\teval-rmspe:0.215918\n",
      "[97]\ttrain-rmse:0.044369\teval-rmse:0.196978\ttrain-rmspe:0.045027\teval-rmspe:0.215777\n",
      "[98]\ttrain-rmse:0.043614\teval-rmse:0.196785\ttrain-rmspe:0.04425\teval-rmspe:0.21555\n",
      "[99]\ttrain-rmse:0.04285\teval-rmse:0.19675\ttrain-rmspe:0.043454\teval-rmspe:0.215533\n",
      "[100]\ttrain-rmse:0.042487\teval-rmse:0.196709\ttrain-rmspe:0.04309\teval-rmspe:0.215446\n",
      "[101]\ttrain-rmse:0.042051\teval-rmse:0.196732\ttrain-rmspe:0.042644\teval-rmspe:0.215487\n",
      "[102]\ttrain-rmse:0.041542\teval-rmse:0.196599\ttrain-rmspe:0.042109\teval-rmspe:0.215338\n",
      "[103]\ttrain-rmse:0.041107\teval-rmse:0.196539\ttrain-rmspe:0.041662\teval-rmspe:0.21525\n",
      "[104]\ttrain-rmse:0.040297\teval-rmse:0.196588\ttrain-rmspe:0.040823\teval-rmspe:0.215316\n",
      "[105]\ttrain-rmse:0.039587\teval-rmse:0.196659\ttrain-rmspe:0.04009\teval-rmspe:0.215399\n",
      "[106]\ttrain-rmse:0.038975\teval-rmse:0.19669\ttrain-rmspe:0.039453\teval-rmspe:0.215446\n",
      "[107]\ttrain-rmse:0.038815\teval-rmse:0.196613\ttrain-rmspe:0.039291\teval-rmspe:0.215364\n",
      "[108]\ttrain-rmse:0.038465\teval-rmse:0.196536\ttrain-rmspe:0.038938\teval-rmspe:0.215311\n",
      "[109]\ttrain-rmse:0.038283\teval-rmse:0.19651\ttrain-rmspe:0.038751\teval-rmspe:0.215266\n",
      "[110]\ttrain-rmse:0.037774\teval-rmse:0.19638\ttrain-rmspe:0.03823\teval-rmspe:0.215147\n",
      "[111]\ttrain-rmse:0.037524\teval-rmse:0.196354\ttrain-rmspe:0.037975\teval-rmspe:0.215137\n",
      "[112]\ttrain-rmse:0.037386\teval-rmse:0.196322\ttrain-rmspe:0.037831\teval-rmspe:0.215116\n",
      "[113]\ttrain-rmse:0.036852\teval-rmse:0.196253\ttrain-rmspe:0.037285\teval-rmspe:0.215039\n",
      "[114]\ttrain-rmse:0.036012\teval-rmse:0.196155\ttrain-rmspe:0.03642\teval-rmspe:0.214933\n",
      "[115]\ttrain-rmse:0.035414\teval-rmse:0.196213\ttrain-rmspe:0.035803\teval-rmspe:0.215045\n",
      "[116]\ttrain-rmse:0.03479\teval-rmse:0.196242\ttrain-rmspe:0.035147\teval-rmspe:0.215095\n",
      "[117]\ttrain-rmse:0.03425\teval-rmse:0.196258\ttrain-rmspe:0.034593\teval-rmspe:0.215082\n",
      "[118]\ttrain-rmse:0.033881\teval-rmse:0.196271\ttrain-rmspe:0.034214\teval-rmspe:0.215093\n",
      "[119]\ttrain-rmse:0.033407\teval-rmse:0.196284\ttrain-rmspe:0.033717\teval-rmspe:0.215138\n",
      "[120]\ttrain-rmse:0.032999\teval-rmse:0.19631\ttrain-rmspe:0.033295\teval-rmspe:0.215168\n",
      "[121]\ttrain-rmse:0.032646\teval-rmse:0.196325\ttrain-rmspe:0.032927\teval-rmspe:0.215174\n",
      "[122]\ttrain-rmse:0.032514\teval-rmse:0.196311\ttrain-rmspe:0.032794\teval-rmspe:0.215162\n",
      "[123]\ttrain-rmse:0.032141\teval-rmse:0.196326\ttrain-rmspe:0.032409\teval-rmspe:0.215187\n",
      "[124]\ttrain-rmse:0.031693\teval-rmse:0.196322\ttrain-rmspe:0.031952\teval-rmspe:0.21514\n",
      "[125]\ttrain-rmse:0.031582\teval-rmse:0.196309\ttrain-rmspe:0.03184\teval-rmspe:0.21513\n",
      "[126]\ttrain-rmse:0.031154\teval-rmse:0.196313\ttrain-rmspe:0.031403\teval-rmspe:0.215133\n",
      "[127]\ttrain-rmse:0.030981\teval-rmse:0.196288\ttrain-rmspe:0.031224\teval-rmspe:0.215109\n",
      "[128]\ttrain-rmse:0.030788\teval-rmse:0.19628\ttrain-rmspe:0.031018\teval-rmspe:0.21509\n",
      "[129]\ttrain-rmse:0.030517\teval-rmse:0.196263\ttrain-rmspe:0.03074\teval-rmspe:0.215061\n",
      "[130]\ttrain-rmse:0.030369\teval-rmse:0.196243\ttrain-rmspe:0.030591\teval-rmspe:0.215035\n",
      "[131]\ttrain-rmse:0.030124\teval-rmse:0.196265\ttrain-rmspe:0.030335\teval-rmspe:0.215052\n",
      "[132]\ttrain-rmse:0.029766\teval-rmse:0.196257\ttrain-rmspe:0.029971\teval-rmspe:0.215039\n",
      "[133]\ttrain-rmse:0.029596\teval-rmse:0.196254\ttrain-rmspe:0.029788\teval-rmspe:0.21502\n",
      "[134]\ttrain-rmse:0.029307\teval-rmse:0.196221\ttrain-rmspe:0.029498\teval-rmspe:0.214991\n",
      "[135]\ttrain-rmse:0.029091\teval-rmse:0.196222\ttrain-rmspe:0.029279\teval-rmspe:0.214982\n",
      "[136]\ttrain-rmse:0.028692\teval-rmse:0.196232\ttrain-rmspe:0.028875\teval-rmspe:0.214983\n",
      "[137]\ttrain-rmse:0.028235\teval-rmse:0.19623\ttrain-rmspe:0.028412\teval-rmspe:0.214953\n",
      "[138]\ttrain-rmse:0.0281\teval-rmse:0.196218\ttrain-rmspe:0.028274\teval-rmspe:0.21494\n",
      "[139]\ttrain-rmse:0.027732\teval-rmse:0.196207\ttrain-rmspe:0.027903\teval-rmspe:0.21491\n",
      "[140]\ttrain-rmse:0.027407\teval-rmse:0.196177\ttrain-rmspe:0.027574\teval-rmspe:0.214898\n",
      "[141]\ttrain-rmse:0.027164\teval-rmse:0.196158\ttrain-rmspe:0.027331\teval-rmspe:0.21489\n",
      "[142]\ttrain-rmse:0.026928\teval-rmse:0.19614\ttrain-rmspe:0.027093\teval-rmspe:0.214873\n",
      "[143]\ttrain-rmse:0.026615\teval-rmse:0.19613\ttrain-rmspe:0.02678\teval-rmspe:0.214869\n",
      "[144]\ttrain-rmse:0.026358\teval-rmse:0.19615\ttrain-rmspe:0.026516\teval-rmspe:0.214891\n",
      "[145]\ttrain-rmse:0.026235\teval-rmse:0.196157\ttrain-rmspe:0.02639\teval-rmspe:0.214891\n",
      "[146]\ttrain-rmse:0.026021\teval-rmse:0.196147\ttrain-rmspe:0.026174\teval-rmspe:0.214882\n",
      "[147]\ttrain-rmse:0.025727\teval-rmse:0.196136\ttrain-rmspe:0.02588\teval-rmspe:0.214889\n",
      "[148]\ttrain-rmse:0.025562\teval-rmse:0.196135\ttrain-rmspe:0.025713\teval-rmspe:0.214889\n",
      "[149]\ttrain-rmse:0.025298\teval-rmse:0.196127\ttrain-rmspe:0.025449\teval-rmspe:0.214878\n",
      "[150]\ttrain-rmse:0.025218\teval-rmse:0.196137\ttrain-rmspe:0.025368\teval-rmspe:0.214888\n",
      "[151]\ttrain-rmse:0.025146\teval-rmse:0.196132\ttrain-rmspe:0.025297\teval-rmspe:0.214881\n",
      "[152]\ttrain-rmse:0.024975\teval-rmse:0.196119\ttrain-rmspe:0.025121\teval-rmspe:0.214868\n",
      "[153]\ttrain-rmse:0.02485\teval-rmse:0.1961\ttrain-rmspe:0.024996\teval-rmspe:0.214849\n",
      "[154]\ttrain-rmse:0.024705\teval-rmse:0.19609\ttrain-rmspe:0.02485\teval-rmspe:0.214832\n",
      "[155]\ttrain-rmse:0.024526\teval-rmse:0.196097\ttrain-rmspe:0.024671\teval-rmspe:0.214848\n",
      "[156]\ttrain-rmse:0.024397\teval-rmse:0.196079\ttrain-rmspe:0.024541\teval-rmspe:0.214825\n",
      "[157]\ttrain-rmse:0.024227\teval-rmse:0.196105\ttrain-rmspe:0.024366\teval-rmspe:0.214846\n",
      "[158]\ttrain-rmse:0.024166\teval-rmse:0.1961\ttrain-rmspe:0.024301\teval-rmspe:0.214873\n",
      "[159]\ttrain-rmse:0.023952\teval-rmse:0.196105\ttrain-rmspe:0.024082\teval-rmspe:0.214877\n",
      "[160]\ttrain-rmse:0.023805\teval-rmse:0.196099\ttrain-rmspe:0.023934\teval-rmspe:0.214862\n",
      "[161]\ttrain-rmse:0.023707\teval-rmse:0.196091\ttrain-rmspe:0.023836\teval-rmspe:0.214865\n",
      "[162]\ttrain-rmse:0.023592\teval-rmse:0.196085\ttrain-rmspe:0.023721\teval-rmspe:0.214866\n",
      "[163]\ttrain-rmse:0.023427\teval-rmse:0.196072\ttrain-rmspe:0.023555\teval-rmspe:0.21486\n",
      "[164]\ttrain-rmse:0.023315\teval-rmse:0.19606\ttrain-rmspe:0.023442\teval-rmspe:0.214854\n",
      "[165]\ttrain-rmse:0.023033\teval-rmse:0.196044\ttrain-rmspe:0.023156\teval-rmspe:0.214839\n",
      "[166]\ttrain-rmse:0.022892\teval-rmse:0.196043\ttrain-rmspe:0.023014\teval-rmspe:0.214834\n",
      "[167]\ttrain-rmse:0.022826\teval-rmse:0.196042\ttrain-rmspe:0.022947\teval-rmspe:0.214829\n",
      "[168]\ttrain-rmse:0.022686\teval-rmse:0.196026\ttrain-rmspe:0.022804\teval-rmspe:0.214815\n",
      "[169]\ttrain-rmse:0.022468\teval-rmse:0.19602\ttrain-rmspe:0.022584\teval-rmspe:0.214812\n",
      "[170]\ttrain-rmse:0.022378\teval-rmse:0.196025\ttrain-rmspe:0.022488\teval-rmspe:0.214808\n",
      "[171]\ttrain-rmse:0.02228\teval-rmse:0.196037\ttrain-rmspe:0.022387\teval-rmspe:0.214816\n",
      "[172]\ttrain-rmse:0.022225\teval-rmse:0.196026\ttrain-rmspe:0.022331\teval-rmspe:0.214808\n",
      "[173]\ttrain-rmse:0.021839\teval-rmse:0.196018\ttrain-rmspe:0.021942\teval-rmspe:0.214805\n",
      "[174]\ttrain-rmse:0.021624\teval-rmse:0.19602\ttrain-rmspe:0.021724\teval-rmspe:0.214807\n",
      "[175]\ttrain-rmse:0.021379\teval-rmse:0.196017\ttrain-rmspe:0.021477\teval-rmspe:0.214801\n",
      "[176]\ttrain-rmse:0.021261\teval-rmse:0.196028\ttrain-rmspe:0.021357\teval-rmspe:0.214807\n",
      "[177]\ttrain-rmse:0.021142\teval-rmse:0.196049\ttrain-rmspe:0.021237\teval-rmspe:0.21483\n",
      "[178]\ttrain-rmse:0.021\teval-rmse:0.196044\ttrain-rmspe:0.021093\teval-rmspe:0.214827\n",
      "[179]\ttrain-rmse:0.02087\teval-rmse:0.196043\ttrain-rmspe:0.020961\teval-rmspe:0.21482\n",
      "[180]\ttrain-rmse:0.020779\teval-rmse:0.196039\ttrain-rmspe:0.020868\teval-rmspe:0.214818\n",
      "[181]\ttrain-rmse:0.020549\teval-rmse:0.196054\ttrain-rmspe:0.020636\teval-rmspe:0.214835\n",
      "[182]\ttrain-rmse:0.020355\teval-rmse:0.196076\ttrain-rmspe:0.020439\teval-rmspe:0.214853\n",
      "[183]\ttrain-rmse:0.020137\teval-rmse:0.196082\ttrain-rmspe:0.020217\teval-rmspe:0.214867\n",
      "[184]\ttrain-rmse:0.020084\teval-rmse:0.196082\ttrain-rmspe:0.020165\teval-rmspe:0.21486\n",
      "[185]\ttrain-rmse:0.01977\teval-rmse:0.196081\ttrain-rmspe:0.01985\teval-rmspe:0.214865\n",
      "[186]\ttrain-rmse:0.019548\teval-rmse:0.196082\ttrain-rmspe:0.019627\teval-rmspe:0.214866\n",
      "[187]\ttrain-rmse:0.019291\teval-rmse:0.196082\ttrain-rmspe:0.019367\teval-rmspe:0.214867\n",
      "[188]\ttrain-rmse:0.019003\teval-rmse:0.196091\ttrain-rmspe:0.019077\teval-rmspe:0.214878\n",
      "[189]\ttrain-rmse:0.018811\teval-rmse:0.1961\ttrain-rmspe:0.018883\teval-rmspe:0.214889\n",
      "[190]\ttrain-rmse:0.018665\teval-rmse:0.196103\ttrain-rmspe:0.018736\teval-rmspe:0.214887\n",
      "[191]\ttrain-rmse:0.018546\teval-rmse:0.196096\ttrain-rmspe:0.018616\teval-rmspe:0.214873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-rmse:0.018486\teval-rmse:0.196093\ttrain-rmspe:0.018555\teval-rmspe:0.214871\n",
      "[193]\ttrain-rmse:0.018321\teval-rmse:0.196093\ttrain-rmspe:0.01839\teval-rmspe:0.214877\n",
      "[194]\ttrain-rmse:0.018277\teval-rmse:0.196089\ttrain-rmspe:0.018345\teval-rmspe:0.214873\n",
      "[195]\ttrain-rmse:0.018074\teval-rmse:0.196098\ttrain-rmspe:0.01814\teval-rmspe:0.214875\n",
      "[196]\ttrain-rmse:0.017935\teval-rmse:0.196104\ttrain-rmspe:0.018\teval-rmspe:0.214883\n",
      "[197]\ttrain-rmse:0.017869\teval-rmse:0.196103\ttrain-rmspe:0.017934\teval-rmspe:0.214879\n",
      "[198]\ttrain-rmse:0.017819\teval-rmse:0.196101\ttrain-rmspe:0.017883\teval-rmspe:0.214873\n",
      "[199]\ttrain-rmse:0.017734\teval-rmse:0.1961\ttrain-rmspe:0.017797\teval-rmspe:0.21487\n",
      "[200]\ttrain-rmse:0.017703\teval-rmse:0.1961\ttrain-rmspe:0.017766\teval-rmspe:0.214869\n",
      "[201]\ttrain-rmse:0.017578\teval-rmse:0.196088\ttrain-rmspe:0.017641\teval-rmspe:0.214856\n",
      "[202]\ttrain-rmse:0.017463\teval-rmse:0.19609\ttrain-rmspe:0.017525\teval-rmspe:0.214855\n",
      "[203]\ttrain-rmse:0.017397\teval-rmse:0.196093\ttrain-rmspe:0.017458\teval-rmspe:0.214855\n",
      "[204]\ttrain-rmse:0.017257\teval-rmse:0.196104\ttrain-rmspe:0.017314\teval-rmspe:0.214864\n",
      "[205]\ttrain-rmse:0.017176\teval-rmse:0.196104\ttrain-rmspe:0.017233\teval-rmspe:0.214862\n",
      "[206]\ttrain-rmse:0.01702\teval-rmse:0.196115\ttrain-rmspe:0.017074\teval-rmspe:0.214847\n",
      "[207]\ttrain-rmse:0.016938\teval-rmse:0.196117\ttrain-rmspe:0.016991\teval-rmspe:0.214848\n",
      "[208]\ttrain-rmse:0.016797\teval-rmse:0.196124\ttrain-rmspe:0.016849\teval-rmspe:0.21485\n",
      "[209]\ttrain-rmse:0.016694\teval-rmse:0.196129\ttrain-rmspe:0.016745\teval-rmspe:0.214854\n",
      "[210]\ttrain-rmse:0.016584\teval-rmse:0.196137\ttrain-rmspe:0.016633\teval-rmspe:0.214863\n",
      "[211]\ttrain-rmse:0.016485\teval-rmse:0.196139\ttrain-rmspe:0.016534\teval-rmspe:0.214854\n",
      "[212]\ttrain-rmse:0.01645\teval-rmse:0.19614\ttrain-rmspe:0.0165\teval-rmspe:0.214857\n",
      "[213]\ttrain-rmse:0.016411\teval-rmse:0.196137\ttrain-rmspe:0.01646\teval-rmspe:0.21486\n",
      "[214]\ttrain-rmse:0.01635\teval-rmse:0.196136\ttrain-rmspe:0.016399\teval-rmspe:0.214859\n",
      "[215]\ttrain-rmse:0.016227\teval-rmse:0.196128\ttrain-rmspe:0.016274\teval-rmspe:0.214851\n",
      "[216]\ttrain-rmse:0.016147\teval-rmse:0.196131\ttrain-rmspe:0.016194\teval-rmspe:0.214856\n",
      "[217]\ttrain-rmse:0.016035\teval-rmse:0.196135\ttrain-rmspe:0.01608\teval-rmspe:0.214857\n",
      "[218]\ttrain-rmse:0.015858\teval-rmse:0.196132\ttrain-rmspe:0.015903\teval-rmspe:0.214853\n",
      "[219]\ttrain-rmse:0.015806\teval-rmse:0.196136\ttrain-rmspe:0.01585\teval-rmspe:0.21486\n",
      "[220]\ttrain-rmse:0.015651\teval-rmse:0.196135\ttrain-rmspe:0.015693\teval-rmspe:0.214862\n",
      "[221]\ttrain-rmse:0.01561\teval-rmse:0.196135\ttrain-rmspe:0.015652\teval-rmspe:0.214844\n",
      "[222]\ttrain-rmse:0.015552\teval-rmse:0.196135\ttrain-rmspe:0.015594\teval-rmspe:0.214846\n",
      "[223]\ttrain-rmse:0.015466\teval-rmse:0.196134\ttrain-rmspe:0.015508\teval-rmspe:0.214845\n",
      "[224]\ttrain-rmse:0.015221\teval-rmse:0.196144\ttrain-rmspe:0.015261\teval-rmspe:0.214845\n",
      "[225]\ttrain-rmse:0.01513\teval-rmse:0.196144\ttrain-rmspe:0.015169\teval-rmspe:0.214854\n",
      "[226]\ttrain-rmse:0.01508\teval-rmse:0.196143\ttrain-rmspe:0.01512\teval-rmspe:0.214852\n",
      "[227]\ttrain-rmse:0.014945\teval-rmse:0.196141\ttrain-rmspe:0.014983\teval-rmspe:0.214845\n",
      "[228]\ttrain-rmse:0.014919\teval-rmse:0.196143\ttrain-rmspe:0.014957\teval-rmspe:0.214845\n",
      "[229]\ttrain-rmse:0.014796\teval-rmse:0.196147\ttrain-rmspe:0.014833\teval-rmspe:0.214863\n",
      "[230]\ttrain-rmse:0.014686\teval-rmse:0.196151\ttrain-rmspe:0.014723\teval-rmspe:0.214869\n",
      "[231]\ttrain-rmse:0.014595\teval-rmse:0.196154\ttrain-rmspe:0.014631\teval-rmspe:0.214875\n",
      "[232]\ttrain-rmse:0.014522\teval-rmse:0.196154\ttrain-rmspe:0.014558\teval-rmspe:0.214878\n",
      "[233]\ttrain-rmse:0.014402\teval-rmse:0.196163\ttrain-rmspe:0.014436\teval-rmspe:0.214889\n",
      "[234]\ttrain-rmse:0.014331\teval-rmse:0.196172\ttrain-rmspe:0.014365\teval-rmspe:0.214901\n",
      "[235]\ttrain-rmse:0.014243\teval-rmse:0.196176\ttrain-rmspe:0.014276\teval-rmspe:0.214905\n",
      "[236]\ttrain-rmse:0.014006\teval-rmse:0.19618\ttrain-rmspe:0.014038\teval-rmspe:0.214911\n",
      "[237]\ttrain-rmse:0.013868\teval-rmse:0.196184\ttrain-rmspe:0.013898\teval-rmspe:0.214917\n",
      "[238]\ttrain-rmse:0.013799\teval-rmse:0.196189\ttrain-rmspe:0.013829\teval-rmspe:0.214924\n",
      "[239]\ttrain-rmse:0.013756\teval-rmse:0.19619\ttrain-rmspe:0.013784\teval-rmspe:0.214924\n",
      "[240]\ttrain-rmse:0.013709\teval-rmse:0.196192\ttrain-rmspe:0.013737\teval-rmspe:0.214929\n",
      "[241]\ttrain-rmse:0.013671\teval-rmse:0.196195\ttrain-rmspe:0.013699\teval-rmspe:0.214932\n",
      "[242]\ttrain-rmse:0.013558\teval-rmse:0.196208\ttrain-rmspe:0.013585\teval-rmspe:0.21494\n",
      "[243]\ttrain-rmse:0.013473\teval-rmse:0.19621\ttrain-rmspe:0.013498\teval-rmspe:0.21494\n",
      "[244]\ttrain-rmse:0.013318\teval-rmse:0.196213\ttrain-rmspe:0.013343\teval-rmspe:0.214947\n",
      "[245]\ttrain-rmse:0.013223\teval-rmse:0.196217\ttrain-rmspe:0.013247\teval-rmspe:0.21495\n",
      "[246]\ttrain-rmse:0.013142\teval-rmse:0.19622\ttrain-rmspe:0.013166\teval-rmspe:0.214948\n",
      "[247]\ttrain-rmse:0.013022\teval-rmse:0.196225\ttrain-rmspe:0.013045\teval-rmspe:0.214949\n",
      "[248]\ttrain-rmse:0.012973\teval-rmse:0.196229\ttrain-rmspe:0.012995\teval-rmspe:0.214953\n",
      "[249]\ttrain-rmse:0.012874\teval-rmse:0.196226\ttrain-rmspe:0.012897\teval-rmspe:0.21495\n",
      "[250]\ttrain-rmse:0.012771\teval-rmse:0.196227\ttrain-rmspe:0.012793\teval-rmspe:0.214946\n",
      "[251]\ttrain-rmse:0.012719\teval-rmse:0.196225\ttrain-rmspe:0.012741\teval-rmspe:0.214937\n",
      "[252]\ttrain-rmse:0.012632\teval-rmse:0.196225\ttrain-rmspe:0.012654\teval-rmspe:0.214933\n",
      "[253]\ttrain-rmse:0.012608\teval-rmse:0.196225\ttrain-rmspe:0.012629\teval-rmspe:0.214936\n",
      "[254]\ttrain-rmse:0.012564\teval-rmse:0.196223\ttrain-rmspe:0.012585\teval-rmspe:0.214938\n",
      "[255]\ttrain-rmse:0.012505\teval-rmse:0.196224\ttrain-rmspe:0.012525\teval-rmspe:0.214939\n",
      "[256]\ttrain-rmse:0.012451\teval-rmse:0.196225\ttrain-rmspe:0.012471\teval-rmspe:0.214936\n",
      "[257]\ttrain-rmse:0.012401\teval-rmse:0.196227\ttrain-rmspe:0.012421\teval-rmspe:0.214938\n",
      "[258]\ttrain-rmse:0.012355\teval-rmse:0.196227\ttrain-rmspe:0.012375\teval-rmspe:0.214938\n",
      "[259]\ttrain-rmse:0.012321\teval-rmse:0.196228\ttrain-rmspe:0.01234\teval-rmspe:0.214935\n",
      "[260]\ttrain-rmse:0.01216\teval-rmse:0.196229\ttrain-rmspe:0.012179\teval-rmspe:0.214937\n",
      "[261]\ttrain-rmse:0.01208\teval-rmse:0.196232\ttrain-rmspe:0.012099\teval-rmspe:0.214939\n",
      "[262]\ttrain-rmse:0.012026\teval-rmse:0.196236\ttrain-rmspe:0.012043\teval-rmspe:0.214943\n",
      "[263]\ttrain-rmse:0.011903\teval-rmse:0.196239\ttrain-rmspe:0.01192\teval-rmspe:0.214947\n",
      "[264]\ttrain-rmse:0.011864\teval-rmse:0.196241\ttrain-rmspe:0.01188\teval-rmspe:0.214952\n",
      "[265]\ttrain-rmse:0.011764\teval-rmse:0.196241\ttrain-rmspe:0.01178\teval-rmspe:0.214952\n",
      "[266]\ttrain-rmse:0.011637\teval-rmse:0.196245\ttrain-rmspe:0.011653\teval-rmspe:0.214956\n",
      "[267]\ttrain-rmse:0.011535\teval-rmse:0.196245\ttrain-rmspe:0.01155\teval-rmspe:0.214956\n",
      "[268]\ttrain-rmse:0.011424\teval-rmse:0.196245\ttrain-rmspe:0.011439\teval-rmspe:0.214957\n",
      "[269]\ttrain-rmse:0.011349\teval-rmse:0.196246\ttrain-rmspe:0.011365\teval-rmspe:0.214959\n",
      "[270]\ttrain-rmse:0.01134\teval-rmse:0.196248\ttrain-rmspe:0.011355\teval-rmspe:0.214961\n",
      "[271]\ttrain-rmse:0.01127\teval-rmse:0.196249\ttrain-rmspe:0.011286\teval-rmspe:0.214963\n",
      "[272]\ttrain-rmse:0.011202\teval-rmse:0.196252\ttrain-rmspe:0.011217\teval-rmspe:0.214965\n",
      "[273]\ttrain-rmse:0.011108\teval-rmse:0.196255\ttrain-rmspe:0.011123\teval-rmspe:0.214969\n",
      "[274]\ttrain-rmse:0.011055\teval-rmse:0.196257\ttrain-rmspe:0.01107\teval-rmspe:0.214974\n",
      "[275]\ttrain-rmse:0.010983\teval-rmse:0.196258\ttrain-rmspe:0.010998\teval-rmspe:0.214975\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-rmse:0.021379\teval-rmse:0.196017\ttrain-rmspe:0.021477\teval-rmspe:0.214801\n",
      "\n",
      "Validating\n",
      "RMSPE: 0.214975\n",
      "Make predictions on the test set\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)\n",
    "\n",
    "print(\"Validating\")\n",
    "yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "error = rmspe(X_valid.Sales.values, np.expm1(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "test_probs = gbm.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17010021168813647"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Id\": test[\"ID\"], 'Sales': np.expm1(test_probs)})\n",
    "result.loc[test['Open']==0,'Sales'] = 0\n",
    "sorted_result = result.sort_values('Id').reset_index().drop(columns = 'index')\n",
    "test_ans = pd.read_csv(\"Drugstore_data/test_ans.csv\")\n",
    "rmspe(test_ans['Sales'],sorted_result['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5171.888672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4965.195801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4646.045410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5846.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4629.857910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        Sales\n",
       "0   1  5171.888672\n",
       "1   2  4965.195801\n",
       "2   3  4646.045410\n",
       "3   4  5846.708984\n",
       "4   5  4629.857910"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_result.to_csv(\"xgboost_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans = pd.read_csv('Drugstore_data/test_ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = pd.read_csv('Rossmann_submission_1.csv')\n",
    "sub = pd.read_csv('Rossmann_submission_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 =sub.sort_values(by='ID').reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.loc[test_ans['Sales']==0,'Sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.to_csv('team1_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46830,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans['Sales'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40282,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans['Sales'][test_ans['Sales']!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1398152422709307"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_ans['Sales'],sub2['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13914959000590033"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_ans['Sales'][test_ans['Sales']!=0],sub2['Sales'][sub2['Sales']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-86400000000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(train['Date'])[0]-pd.to_numeric(train['Date'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2013-01-01\n",
       "1        2013-01-02\n",
       "2        2013-01-03\n",
       "3        2013-01-04\n",
       "4        2013-01-05\n",
       "5        2013-01-06\n",
       "6        2013-01-07\n",
       "7        2013-01-08\n",
       "8        2013-01-09\n",
       "9        2013-01-10\n",
       "10       2013-01-11\n",
       "11       2013-01-12\n",
       "12       2013-01-13\n",
       "13       2013-01-14\n",
       "14       2013-01-15\n",
       "15       2013-01-16\n",
       "16       2013-01-17\n",
       "17       2013-01-18\n",
       "18       2013-01-19\n",
       "19       2013-01-20\n",
       "20       2013-01-21\n",
       "21       2013-01-22\n",
       "22       2013-01-23\n",
       "23       2013-01-24\n",
       "24       2013-01-25\n",
       "25       2013-01-26\n",
       "26       2013-01-27\n",
       "27       2013-01-28\n",
       "28       2013-01-29\n",
       "29       2013-01-30\n",
       "            ...    \n",
       "785697   2015-05-02\n",
       "785698   2015-05-03\n",
       "785699   2015-05-04\n",
       "785700   2015-05-05\n",
       "785701   2015-05-06\n",
       "785702   2015-05-07\n",
       "785703   2015-05-08\n",
       "785704   2015-05-09\n",
       "785705   2015-05-10\n",
       "785706   2015-05-11\n",
       "785707   2015-05-12\n",
       "785708   2015-05-13\n",
       "785709   2015-05-14\n",
       "785710   2015-05-15\n",
       "785711   2015-05-16\n",
       "785712   2015-05-17\n",
       "785713   2015-05-18\n",
       "785714   2015-05-19\n",
       "785715   2015-05-20\n",
       "785716   2015-05-21\n",
       "785717   2015-05-22\n",
       "785718   2015-05-23\n",
       "785719   2015-05-24\n",
       "785720   2015-05-25\n",
       "785721   2015-05-26\n",
       "785722   2015-05-27\n",
       "785723   2015-05-28\n",
       "785724   2015-05-29\n",
       "785725   2015-05-30\n",
       "785726   2015-05-31\n",
       "Name: Date, Length: 785727, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

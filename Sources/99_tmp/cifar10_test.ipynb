{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CIFAR-10 Convolutional Neural Networks(CNN) Example\n",
    "next_batch function is copied from edo's answer\n",
    "https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data\n",
    "Author : solaris33\n",
    "Project URL : http://solarisailab.com/archives/2325\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 µ¥ÀÌÅÍžŠ ŽÙ¿î·Îµå ¹Þ±â À§ÇÑ kerasÀÇ helper ÇÔŒöÀÎ load_data ÇÔŒöžŠ ÀÓÆ÷Æ®ÇÕŽÏŽÙ.\n",
    "from tensorflow.keras.datasets.cifar10 import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "  '''\n",
    "  `num` °³Œö žžÅ­ÀÇ ·£ŽýÇÑ »ùÇÃµé°ú ·¹ÀÌºíµéÀ» ž®ÅÏÇÕŽÏŽÙ.\n",
    "  '''\n",
    "  idx = np.arange(0 , len(data))\n",
    "  np.random.shuffle(idx)\n",
    "  idx = idx[:num]\n",
    "  data_shuffle = [data[ i] for i in idx]\n",
    "  labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "  return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN žðµšÀ» Á€ÀÇÇÕŽÏŽÙ. \n",
    "def build_CNN_classifier(x):\n",
    "  # ÀÔ·Â ÀÌ¹ÌÁö\n",
    "  x_image = x\n",
    "\n",
    "  # Ã¹¹øÂ° convolutional layer - ÇÏ³ªÀÇ grayscale ÀÌ¹ÌÁöžŠ 64°³ÀÇ Æ¯Â¡µé(feature)Àž·Î žÊÇÎ(maping)ÇÕŽÏŽÙ.\n",
    "  W_conv1 = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], stddev=5e-2))\n",
    "  b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "  h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
    "\n",
    "  # Ã¹¹øÂ° Pooling layer\n",
    "  h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "  # µÎ¹øÂ° convolutional layer - 32°³ÀÇ Æ¯Â¡µé(feature)À» 64°³ÀÇ Æ¯Â¡µé(feature)·Î žÊÇÎ(maping)ÇÕŽÏŽÙ.\n",
    "  W_conv2 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], stddev=5e-2))\n",
    "  b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "  h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
    "\n",
    "  # µÎ¹øÂ° pooling layer.\n",
    "  h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "  # ŒŒ¹øÂ° convolutional layer\n",
    "  W_conv3 = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], stddev=5e-2))\n",
    "  b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "  h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME') + b_conv3)\n",
    "\n",
    "  # ³×¹øÂ° convolutional layer\n",
    "  W_conv4 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "  b_conv4 = tf.Variable(tf.constant(0.1, shape=[128])) \n",
    "  h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME') + b_conv4)\n",
    "\n",
    "  # ŽÙŒž¹øÂ° convolutional layer\n",
    "  W_conv5 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
    "  b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "  h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5, strides=[1, 1, 1, 1], padding='SAME') + b_conv5)\n",
    "\n",
    "  # Fully Connected Layer 1 - 2¹øÀÇ downsampling ÀÌÈÄ¿¡, ¿ìž®ÀÇ 32x32 ÀÌ¹ÌÁöŽÂ 8x8x128 Æ¯Â¡žÊ(feature map)ÀÌ µËŽÏŽÙ.\n",
    "  # ÀÌžŠ 384°³ÀÇ Æ¯Â¡µé·Î žÊÇÎ(maping)ÇÕŽÏŽÙ.\n",
    "  W_fc1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * 128, 384], stddev=5e-2))\n",
    "  b_fc1 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
    "\n",
    "  h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
    "  h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - žðµšÀÇ º¹ÀâµµžŠ ÄÁÆ®·ÑÇÕŽÏŽÙ. Æ¯Â¡µéÀÇ co-adaptationÀ» ¹æÁöÇÕŽÏŽÙ.\n",
    "  h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) \n",
    "\n",
    "  # Fully Connected Layer 2 - 384°³ÀÇ Æ¯Â¡µé(feature)À» 10°³ÀÇ Å¬·¡œº-airplane, automobile, bird...-·Î žÊÇÎ(maping)ÇÕŽÏŽÙ.\n",
    "  W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10], stddev=5e-2))\n",
    "  b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "  logits = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "  y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "  return y_pred, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 71s 0us/step\n",
      "WARNING:tensorflow:From <ipython-input-4-21928a0395b0>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ÀÎÇ² ŸÆ¿ôÇ² µ¥ÀÌÅÍ, µå·ÓŸÆ¿ô È®·üÀ» ÀÔ·Â¹Þ±âÀ§ÇÑ ÇÃ·¹ÀÌœºÈŠŽõžŠ Á€ÀÇÇÕŽÏŽÙ.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# CIFAR-10 µ¥ÀÌÅÍžŠ ŽÙ¿î·ÎµåÇÏ°í µ¥ÀÌÅÍžŠ ºÒ·¯¿ÉŽÏŽÙ.\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "# scalar ÇüÅÂÀÇ ·¹ÀÌºí(0~9)À» One-hot Encoding ÇüÅÂ·Î º¯È¯ÇÕŽÏŽÙ.\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10),axis=1)\n",
    "\n",
    "# Convolutional Neural Networks(CNN) ±×·¡ÇÁžŠ »ýŒºÇÕŽÏŽÙ.\n",
    "y_pred, logits = build_CNN_classifier(x)\n",
    "\n",
    "# Cross EntropyžŠ ºñ¿ëÇÔŒö(loss function)Àž·Î Á€ÀÇÇÏ°í, RMSPropOptimizeržŠ ÀÌ¿ëÇØŒ­ ºñ¿ë ÇÔŒöžŠ ÃÖŒÒÈ­ÇÕŽÏŽÙ.\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "# Á€È®µµžŠ °è»êÇÏŽÂ ¿¬»êÀ» Ãß°¡ÇÕŽÏŽÙ.\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¹Ýº¹(Epoch): 0, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.109375, ŒÕœÇ ÇÔŒö(loss): 106.030365\n",
      "¹Ýº¹(Epoch): 100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.156250, ŒÕœÇ ÇÔŒö(loss): 2.259440\n",
      "¹Ýº¹(Epoch): 200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.265625, ŒÕœÇ ÇÔŒö(loss): 2.019624\n",
      "¹Ýº¹(Epoch): 300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.234375, ŒÕœÇ ÇÔŒö(loss): 2.039469\n",
      "¹Ýº¹(Epoch): 400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.343750, ŒÕœÇ ÇÔŒö(loss): 1.771991\n",
      "¹Ýº¹(Epoch): 500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.484375, ŒÕœÇ ÇÔŒö(loss): 1.494523\n",
      "¹Ýº¹(Epoch): 600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.421875, ŒÕœÇ ÇÔŒö(loss): 1.586675\n",
      "¹Ýº¹(Epoch): 700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.468750, ŒÕœÇ ÇÔŒö(loss): 1.582230\n",
      "¹Ýº¹(Epoch): 800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.523438, ŒÕœÇ ÇÔŒö(loss): 1.348082\n",
      "¹Ýº¹(Epoch): 900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.515625, ŒÕœÇ ÇÔŒö(loss): 1.419751\n",
      "¹Ýº¹(Epoch): 1000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.523438, ŒÕœÇ ÇÔŒö(loss): 1.336760\n",
      "¹Ýº¹(Epoch): 1100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.546875, ŒÕœÇ ÇÔŒö(loss): 1.265695\n",
      "¹Ýº¹(Epoch): 1200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.523438, ŒÕœÇ ÇÔŒö(loss): 1.280042\n",
      "¹Ýº¹(Epoch): 1300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 0.945620\n",
      "¹Ýº¹(Epoch): 1400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.578125, ŒÕœÇ ÇÔŒö(loss): 1.065536\n",
      "¹Ýº¹(Epoch): 1500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.578125, ŒÕœÇ ÇÔŒö(loss): 1.092664\n",
      "¹Ýº¹(Epoch): 1600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.546875, ŒÕœÇ ÇÔŒö(loss): 1.244639\n",
      "¹Ýº¹(Epoch): 1700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 1.039542\n",
      "¹Ýº¹(Epoch): 1800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 0.980410\n",
      "¹Ýº¹(Epoch): 1900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 0.985656\n",
      "¹Ýº¹(Epoch): 2000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.656250, ŒÕœÇ ÇÔŒö(loss): 1.035265\n",
      "¹Ýº¹(Epoch): 2100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.640625, ŒÕœÇ ÇÔŒö(loss): 1.139947\n",
      "¹Ýº¹(Epoch): 2200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.609375, ŒÕœÇ ÇÔŒö(loss): 1.014882\n",
      "¹Ýº¹(Epoch): 2300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.585938, ŒÕœÇ ÇÔŒö(loss): 1.125854\n",
      "¹Ýº¹(Epoch): 2400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.539062, ŒÕœÇ ÇÔŒö(loss): 1.294480\n",
      "¹Ýº¹(Epoch): 2500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.656250, ŒÕœÇ ÇÔŒö(loss): 0.966708\n",
      "¹Ýº¹(Epoch): 2600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.562500, ŒÕœÇ ÇÔŒö(loss): 1.144148\n",
      "¹Ýº¹(Epoch): 2700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.671875, ŒÕœÇ ÇÔŒö(loss): 0.902025\n",
      "¹Ýº¹(Epoch): 2800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 1.154309\n",
      "¹Ýº¹(Epoch): 2900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 0.982967\n",
      "¹Ýº¹(Epoch): 3000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.625000, ŒÕœÇ ÇÔŒö(loss): 1.150179\n",
      "¹Ýº¹(Epoch): 3100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.640625, ŒÕœÇ ÇÔŒö(loss): 1.080635\n",
      "¹Ýº¹(Epoch): 3200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.687500, ŒÕœÇ ÇÔŒö(loss): 0.992186\n",
      "¹Ýº¹(Epoch): 3300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.656250, ŒÕœÇ ÇÔŒö(loss): 1.096272\n",
      "¹Ýº¹(Epoch): 3400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 1.034584\n",
      "¹Ýº¹(Epoch): 3500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.593750, ŒÕœÇ ÇÔŒö(loss): 1.005914\n",
      "¹Ýº¹(Epoch): 3600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.640625, ŒÕœÇ ÇÔŒö(loss): 0.981876\n",
      "¹Ýº¹(Epoch): 3700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.687500, ŒÕœÇ ÇÔŒö(loss): 0.946201\n",
      "¹Ýº¹(Epoch): 3800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.771452\n",
      "¹Ýº¹(Epoch): 3900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.656250, ŒÕœÇ ÇÔŒö(loss): 0.947307\n",
      "¹Ýº¹(Epoch): 4000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.750000, ŒÕœÇ ÇÔŒö(loss): 0.779021\n",
      "¹Ýº¹(Epoch): 4100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 0.891939\n",
      "¹Ýº¹(Epoch): 4200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.802200\n",
      "¹Ýº¹(Epoch): 4300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.718750, ŒÕœÇ ÇÔŒö(loss): 1.035918\n",
      "¹Ýº¹(Epoch): 4400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.679688, ŒÕœÇ ÇÔŒö(loss): 0.962641\n",
      "¹Ýº¹(Epoch): 4500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.818836\n",
      "¹Ýº¹(Epoch): 4600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.664062, ŒÕœÇ ÇÔŒö(loss): 0.896885\n",
      "¹Ýº¹(Epoch): 4700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.593750, ŒÕœÇ ÇÔŒö(loss): 1.151993\n",
      "¹Ýº¹(Epoch): 4800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.679688, ŒÕœÇ ÇÔŒö(loss): 0.889732\n",
      "¹Ýº¹(Epoch): 4900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.671875, ŒÕœÇ ÇÔŒö(loss): 0.894881\n",
      "¹Ýº¹(Epoch): 5000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.562500, ŒÕœÇ ÇÔŒö(loss): 1.365304\n",
      "¹Ýº¹(Epoch): 5100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 1.011120\n",
      "¹Ýº¹(Epoch): 5200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.719592\n",
      "¹Ýº¹(Epoch): 5300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 0.853642\n",
      "¹Ýº¹(Epoch): 5400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.648438, ŒÕœÇ ÇÔŒö(loss): 1.075156\n",
      "¹Ýº¹(Epoch): 5500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.750000, ŒÕœÇ ÇÔŒö(loss): 0.625076\n",
      "¹Ýº¹(Epoch): 5600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.671875, ŒÕœÇ ÇÔŒö(loss): 1.121111\n",
      "¹Ýº¹(Epoch): 5700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.687500, ŒÕœÇ ÇÔŒö(loss): 0.967533\n",
      "¹Ýº¹(Epoch): 5800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.750000, ŒÕœÇ ÇÔŒö(loss): 0.781750\n",
      "¹Ýº¹(Epoch): 5900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.664062, ŒÕœÇ ÇÔŒö(loss): 0.966391\n",
      "¹Ýº¹(Epoch): 6000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 0.983874\n",
      "¹Ýº¹(Epoch): 6100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.773438, ŒÕœÇ ÇÔŒö(loss): 0.651718\n",
      "¹Ýº¹(Epoch): 6200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.734375, ŒÕœÇ ÇÔŒö(loss): 0.778655\n",
      "¹Ýº¹(Epoch): 6300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 0.795035\n",
      "¹Ýº¹(Epoch): 6400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.546875, ŒÕœÇ ÇÔŒö(loss): 1.150902\n",
      "¹Ýº¹(Epoch): 6500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.679688, ŒÕœÇ ÇÔŒö(loss): 0.889939\n",
      "¹Ýº¹(Epoch): 6600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.789062, ŒÕœÇ ÇÔŒö(loss): 0.680545\n",
      "¹Ýº¹(Epoch): 6700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.835958\n",
      "¹Ýº¹(Epoch): 6800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.781250, ŒÕœÇ ÇÔŒö(loss): 0.807819\n",
      "¹Ýº¹(Epoch): 6900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.601562, ŒÕœÇ ÇÔŒö(loss): 1.156631\n",
      "¹Ýº¹(Epoch): 7000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.835938, ŒÕœÇ ÇÔŒö(loss): 0.546766\n",
      "¹Ýº¹(Epoch): 7100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.767308\n",
      "¹Ýº¹(Epoch): 7200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.734375, ŒÕœÇ ÇÔŒö(loss): 0.721742\n",
      "¹Ýº¹(Epoch): 7300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.781250, ŒÕœÇ ÇÔŒö(loss): 0.646001\n",
      "¹Ýº¹(Epoch): 7400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.975399\n",
      "¹Ýº¹(Epoch): 7500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.721060\n",
      "¹Ýº¹(Epoch): 7600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 1.020330\n",
      "¹Ýº¹(Epoch): 7700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.695312, ŒÕœÇ ÇÔŒö(loss): 1.061879\n",
      "¹Ýº¹(Epoch): 7800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.781802\n",
      "¹Ýº¹(Epoch): 7900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.703125, ŒÕœÇ ÇÔŒö(loss): 0.804749\n",
      "¹Ýº¹(Epoch): 8000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.578125, ŒÕœÇ ÇÔŒö(loss): 1.060732\n",
      "¹Ýº¹(Epoch): 8100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.821475\n",
      "¹Ýº¹(Epoch): 8200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.601562, ŒÕœÇ ÇÔŒö(loss): 1.091893\n",
      "¹Ýº¹(Epoch): 8300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.757812, ŒÕœÇ ÇÔŒö(loss): 0.730283\n",
      "¹Ýº¹(Epoch): 8400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.718750, ŒÕœÇ ÇÔŒö(loss): 0.782565\n",
      "¹Ýº¹(Epoch): 8500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.812584\n",
      "¹Ýº¹(Epoch): 8600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.773438, ŒÕœÇ ÇÔŒö(loss): 0.767718\n",
      "¹Ýº¹(Epoch): 8700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.828689\n",
      "¹Ýº¹(Epoch): 8800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.757812, ŒÕœÇ ÇÔŒö(loss): 0.682062\n",
      "¹Ýº¹(Epoch): 8900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.820312, ŒÕœÇ ÇÔŒö(loss): 0.656038\n",
      "¹Ýº¹(Epoch): 9000, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.773438, ŒÕœÇ ÇÔŒö(loss): 0.764106\n",
      "¹Ýº¹(Epoch): 9100, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.750000, ŒÕœÇ ÇÔŒö(loss): 0.814146\n",
      "¹Ýº¹(Epoch): 9200, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.710938, ŒÕœÇ ÇÔŒö(loss): 0.915372\n",
      "¹Ýº¹(Epoch): 9300, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.765625, ŒÕœÇ ÇÔŒö(loss): 0.776557\n",
      "¹Ýº¹(Epoch): 9400, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.585938, ŒÕœÇ ÇÔŒö(loss): 1.292905\n",
      "¹Ýº¹(Epoch): 9500, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.664062, ŒÕœÇ ÇÔŒö(loss): 0.966596\n",
      "¹Ýº¹(Epoch): 9600, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.757812, ŒÕœÇ ÇÔŒö(loss): 0.909548\n",
      "¹Ýº¹(Epoch): 9700, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.460938, ŒÕœÇ ÇÔŒö(loss): 1.402737\n",
      "¹Ýº¹(Epoch): 9800, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.726562, ŒÕœÇ ÇÔŒö(loss): 0.701945\n",
      "¹Ýº¹(Epoch): 9900, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: 0.734375, ŒÕœÇ ÇÔŒö(loss): 0.747868\n",
      "Å×œºÆ® µ¥ÀÌÅÍ Á€È®µµ: 0.657000\n"
     ]
    }
   ],
   "source": [
    "# ŒŒŒÇÀ» ¿­Ÿî œÇÁŠ ÇÐœÀÀ» ÁøÇàÇÕŽÏŽÙ.\n",
    "with tf.Session() as sess:\n",
    "  # žðµç º¯ŒöµéÀ» ÃÊ±âÈ­ÇÑŽÙ. \n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "# 10000 StepžžÅ­ ÃÖÀûÈ­žŠ ŒöÇàÇÕŽÏŽÙ.\n",
    "  for i in range(10000):\n",
    "    batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
    "\n",
    "    # 100 Stepž¶ŽÙ training µ¥ÀÌÅÍŒÂ¿¡ ŽëÇÑ Á€È®µµ¿Í lossžŠ Ãâ·ÂÇÕŽÏŽÙ.\n",
    "    if i % 100 == 0:\n",
    "      train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "      loss_print = loss.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "\n",
    "      print(\"¹Ýº¹(Epoch): %d, Æ®·¹ÀÌŽ× µ¥ÀÌÅÍ Á€È®µµ: %f, ŒÕœÇ ÇÔŒö(loss): %f\" % (i, train_accuracy, loss_print))\n",
    "    # 20% È®·üÀÇ DropoutÀ» ÀÌ¿ëÇØŒ­ ÇÐœÀÀ» ÁøÇàÇÕŽÏŽÙ.\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1], keep_prob: 0.8})\n",
    "      # ÇÐœÀÀÌ ³¡³ªžé Å×œºÆ® µ¥ÀÌÅÍ(10000°³)¿¡ ŽëÇÑ Á€È®µµžŠ Ãâ·ÂÇÕŽÏŽÙ.  \n",
    "  test_accuracy = 0.0  \n",
    "  for i in range(10):\n",
    "    test_batch = next_batch(1000, x_test, y_test_one_hot.eval())\n",
    "    test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: test_batch[0], y: test_batch[1], keep_prob: 1.0})\n",
    "  test_accuracy = test_accuracy / 10;\n",
    "  print(\"Å×œºÆ® µ¥ÀÌÅÍ Á€È®µµ: %f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

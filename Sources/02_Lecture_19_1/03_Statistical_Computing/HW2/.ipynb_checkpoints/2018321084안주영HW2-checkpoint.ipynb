{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "### True value\n",
    "It is easy to compute integral term\n",
    "$$\n",
    "\\theta = \\int_{0}^{1} \\frac{e^x-1}{e-1} dx = \\frac{e-2}{e-1}\n",
    "$$\n",
    "Thus true value of $\\theta$ is $(e-2)/(e-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the number of iteration $n=1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Cude Monte Carlo\n",
    "Let $X = \\{x_1, x_2 , \\dots , x_n\\}$ and $x_i \\sim^{iid} Unif(0,1)$ for $i=1,\\dots,n$  \n",
    "Suppose $h(x) = \\frac{e^x-1}{e-1}$ and $f(x) =1$\n",
    "$$\n",
    "\\begin{align*}\n",
    "E_f[h(X)] =  \\int_{0}^{1} \\frac{e^x-1}{e-1} dx &\\approx \\frac{1}{n} \\sum_{i=1}^{n}h(x_i)\\\\\n",
    "\\hat{\\theta}^{crude}&=\\frac{1}{n}\\sum_{i=1}^{n}\\frac{e^x_i-1}{e-1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{crude})= E[\\hat{\\theta}^{crude}] - \\theta\n",
    "$$\n",
    "First calculate the expectation of $\\frac{e^x_i-1}{e-1}$. As $x_i$'s follow $Unif(0,1)$\n",
    "$$\n",
    "E_f\\left[\\frac{e^x_i-1}{e-1}\\right] = \\int_{0}^{1}\\frac{e^x_i-1}{e-1}\\cdot 1 dx_i = \\frac{e-2}{e-1}\n",
    "$$\n",
    "Since, $x_i$'s are independent\n",
    "$$\n",
    "E[\\hat{\\theta}^{crude}] = \\frac{1}{n}\\sum_{i=1}^{n} E\\left[\\frac{e^x_i-1}{e-1}\\right] = \\frac{e-2}{e-1} = \\theta\n",
    "$$\n",
    "Then bias of Cude Monte Carlo Estimator is\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{crude})= E[\\hat{\\theta}^{crude}] - \\theta = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var[\\hat{\\theta}^{crude}]  &= Var\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\frac{e^x_i-1}{e-1}\\right]\\\\\n",
    "& = \\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}Var[e^x_i-1]\\\\\n",
    "& = \\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}Var[e^x_i]\\\\\n",
    "& = \\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}\\left[ E[e^{2\\cdot x_i}] - E[e^x_i]^2 \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "as $x_i \\sim Unif(0,1)$ we can use mgf of Unifrom distribution\n",
    "$$\n",
    "E_f[e^{tx}] = \\frac{e^t -1}{t}\n",
    "$$\n",
    "Thus\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_f[\\hat{\\theta}^{crude}] & = \\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}\\left[ \\frac{e^2-1}{2} - (e-1)^2 \\right]\\\\\n",
    "&=\\frac{1}{n (e-1)^2}\\left[ \\frac{e^2-1}{2} - (e-1)^2 \\right]\\\\\n",
    "&=\\frac{3-e}{2n(e-1)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "$mse = bias^2 + var$. Thus,\n",
    "$$\n",
    "MSE(\\hat{\\theta}^{crude}) = 0 + \\frac{3-e}{2n(e-1)} = \\frac{3-e}{2n(e-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrudeMC(n=100,prt = False):\n",
    "    theta = (np.exp(1)-2)/(np.exp(1)-1)\n",
    "    X = np.random.uniform(0,1,n)\n",
    "    theta_hat = ((np.exp(X)-1)/(np.exp(1)-1)).mean()\n",
    "    mse = (3-np.exp(1))/(2*n*(np.exp(1)-1))\n",
    "    if prt==True:\n",
    "        print('theta estimator is : %f' %theta_hat)\n",
    "        print('MSE is : %f' %mse)\n",
    "    return(theta_hat,mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta estimator is : 0.417122\n",
      "MSE is : 0.000082\n"
     ]
    }
   ],
   "source": [
    "crude_est,crude_mse = CrudeMC(n,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Importance sampling\n",
    "Let $g(x)=\\frac{e^{-t}}{1-e^{-1}}$. We need to sample from $g(x)$ which follows truncated exponential distribution. We can use Inverse CDF method  \n",
    "Suppose $G(x)$ is CDF of $g(x)$ then,\n",
    "$$\n",
    "\\begin{align*}\n",
    "G(x) &= \\int_{0}^{x}\\frac{e^{-t}}{1-e^{-1}}dt = \\frac{1 -e^{-x}}{1 -e^{-1}} \\sim Unif(0,1)\\\\\n",
    "G^{-1}(U) &= -log \\left(1-U(1-e^{-1})\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "When $U\\sim Unif(0,1)$, $G^{-1}(U)$ follows truncated exponentail distribution  \n",
    "Like Crude Monte Carlo method suppose $h(x) = \\frac{e^x-1}{e-1}$ and $f(x) =1$ and $x_i$'s follows $g(x)$ which is truncated exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}^{Importance} = E_{g}\\left[h(x)\\frac{f(x)}{g(x)}\\right] &\\approx \\frac{1}{n} \\sum_{i=1}^{n}h(x_i)\\frac{f(x_i)}{g(x_i)}\\\\\n",
    "&=\\frac{1}{n} \\sum_{i=1}^{n}\\frac{e^{x_i}-1}{e^{-(x_i-1)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{Importance})= E[\\hat{\\theta}^{Importance}] - \\theta\n",
    "$$\n",
    "First calculate the expectation of $\\frac{e^{x_i}-1}{e^{-(x_i-1)}}$  \n",
    "As $x_i$'s are iid sampled from pdf $g(x)$\n",
    "$$\n",
    "E_g\\left[\\frac{e^{x_i}-1}{e^{-(x_i-1)}}\\right] =\\int_{0}^{1}\\frac{e^{x_i}-1}{e^{-(x_i-1)}}g(x_i)dx_i= \\int_{0}^{1}\\frac{e^x_i-1}{e-1}dx_i = \\frac{e-2}{e-1}\n",
    "$$\n",
    "Since, $x_i$'s are independent\n",
    "$$\n",
    "E[\\hat{\\theta}^{Importance}] = \\frac{1}{n}\\sum_{i=1}^{n} E_g\\left[\\frac{e^{x_i}-1}{e^{-(x_i-1)}}\\right] = \\frac{e-2}{e-1} =\\theta\n",
    "$$\n",
    "Then bias of Importance sampling is\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{Importance})= E[\\hat{\\theta}^{Importance}] - \\theta = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var[\\hat{\\theta}^{Importance}]  &= Var\\left[\\sum_{i=1}^{n}\\frac{e^{x_i}-1}{e^{-(x_i-1)}}\\right]\\\\\n",
    "& = \\frac{1}{n^2 e^2}\\sum_{i=1}^{n}Var\\left[\\frac{e^{x_i}-1}{e^{-x_i}}\\right]\\\\\n",
    "& = \\frac{1}{n^2 e^2}\\sum_{i=1}^{n}Var[e^{2x_i}-e^{x_i}]\\\\\n",
    "& = \\frac{1}{n^2 e^2}\\sum_{i=1}^{n}\\left[ E_g[e^{4x_i}] - E_g[e^{2x_i}]^2 + E_g[e^{2x_i}] -E_g[e^{x_i}]^2 -2\\left(E_g[e^{3x_i}] - E_g[e^{2x_i}]E_g[e^{x_i}]\\right) \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "First calulate the MGF of g(x)\n",
    "$$\n",
    "M_x(t)=E_g[e^{tx}] = \\int_{0}^{1}e^{tx}\\frac{e^{-x}}{1-e^{-1}}dx = \\frac{e^t-e}{(t-1)(e-1)}\n",
    "$$\n",
    "When $t>1$ and $M_x(1) = e/(e-1)$\n",
    "Thus\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_g[\\hat{\\theta}^{Importance}] & = \\frac{1}{n e^2}\\left[ M_x(4) - M_x(2)^2 + M_x(2) - M_x(1)^2 -2 \\left( M_x(3) - M_x(2)M_x(1)\\right)\\right]\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "$mse = bias^2 + var$. Thus,\n",
    "$$\n",
    "\\begin{align*}\n",
    "MSE(\\hat{\\theta}^{Importance}) &= 0 +\\frac{1}{n e^2}\\left[ M_x(4) - M_x(2)^2 + M_x(2) - M_x(1)^2 -2 \\left( M_x(3) - M_x(2)M_x(1)\\right)\\right]\\\\ &= \\frac{1}{n e^2}\\left[ M_x(4) - M_x(2)^2 + M_x(2) - M_x(1)^2 -2 \\left( M_x(3) - M_x(2)M_x(1)\\right)\\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Samplegx(n=100):\n",
    "    U = np.random.uniform(0,1,n)\n",
    "    X = -np.log(1-U*(1-np.exp(-1)))\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgfgx(t):\n",
    "    if t==1:\n",
    "        out = np.exp(1)/(np.exp(1)-1)\n",
    "    elif t>1:\n",
    "        out = (np.exp(t)-np.exp(1))/((t-1)*(np.exp(1)-1))\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(n=100,prt = False):\n",
    "    X = Samplegx(n)\n",
    "    theta_hat = ((np.exp(X)-1)/(np.exp(-X+1))).mean()\n",
    "    mse = (mgfgx(4) - mgfgx(2)**2 + mgfgx(2) - mgfgx(1)**2 - 2*(mgfgx(3)-mgfgx(2)*mgfgx(1)))/(n*(np.exp(2)))\n",
    "    if prt==True:\n",
    "        print('theta estimator is : %f' %theta_hat)\n",
    "        print('MSE is : %f' %mse)\n",
    "    return(theta_hat,mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps_est,imps_mse = importance(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Control Variates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as (a) Suppose $h(x) = \\frac{e^x-1}{e-1}$, $f(x) =1$ and $g(x)=\\frac{x}{e-1}$\n",
    "$$\n",
    "\\begin{align*}\n",
    " E_f[h(X)]&=E_f[g(X)] + E_f[h(X)-g(X)]\\\\\n",
    "\\hat{\\theta}^{CV} &= E_f[g(X)] +\\frac{1}{n}\\sum_{i=1}^{n}\\left( h(x_i) -g(x_i) \\right)\\\\\n",
    "&=\\frac{1}{2(e-1)} + \\frac{1}{n(e-1)}\\sum_{i=1}^{n} (e^{x_i}-x_i -1)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias\n",
    "$$\n",
    "E_f[x] = 0.5\n",
    "$$\n",
    "From (a)\n",
    "$$\n",
    "E_f[e^{tx}] = \\frac{e^t -1}{t}\n",
    "$$\n",
    "Thus\n",
    "$$\n",
    "E\\left[\\hat{\\theta}^{CV}\\right] = \\frac{1}{2(e-1)} + \\frac{1}{n(e-1)}\\sum_{i=1}^{n}\\left( E\\left[e^{x_i}\\right] - E\\left[x_i\\right] -1\\right) = \\frac{e-2}{e-1} = \\theta\n",
    "$$\n",
    "Then bias of Control variates is\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{CV})= E[\\hat{\\theta}^{CV}] - \\theta = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance\n",
    "as $x_i$'s follows $Unif(0,1)$\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[x_i^2] &= var[x_i] + E[x_i]^2 = \\frac{1}{3}\\\\\n",
    "E[e^{x_i}x_i] &= \\int_{0}^{1} e^{x_i}x_i dx_i = 1\n",
    "\\end{align*}\n",
    "$$\n",
    "Variance of Control variates estimator is\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_f[\\hat{\\theta}^{CV}] & = \\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}Var_f\\left[e^{x_i} - x_i -1\\right]\\\\\n",
    "&=\\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}Var_f\\left[e^{x_i} - x_i\\right]\\\\\n",
    "&=\\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}Var_f\\left[e^{x_i} - x_i\\right]\\\\\n",
    "&=\\frac{1}{n^2 (e-1)^2}\\sum_{i=1}^{n}\\left[E_f[e^{2x_i}]-E_f[e^{x_i}]^2 + E_f[x_i^2] - E_f[x_i]^2 - 2\\left(E[e^{x_i}x_i] - E_f[e^{x_i}]E_f[x_i]\\right)\\right]\\\\\n",
    "&=\\frac{1}{n (e-1)^2}\\left[ (e-1)\\left( \\frac{5-e}{2}\\right) - \\frac{23}{12} \\right]\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "$mse = bias^2 + var$. Thus,\n",
    "$$\n",
    "\\begin{align*}\n",
    "MSE(\\hat{\\theta}^{CV}) &= 0 + \\frac{1}{n (e-1)^2}\\left[ (e-1)\\left( \\frac{5-e}{2}\\right) - \\frac{23}{12} \\right]\\\\ \n",
    "&= \\frac{1}{n (e-1)^2}\\left[ (e-1)\\left( \\frac{5-e}{2}\\right) - \\frac{23}{12} \\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ControlVariates(n=100, prt = False):\n",
    "    theta = (np.exp(1)-2)/(np.exp(1)-1)\n",
    "    X = np.random.uniform(0,1,n)\n",
    "    theta_hat = 1/(2*(np.exp(1)-1)) + (np.exp(X) - X -1).mean()/(np.exp(1)-1)\n",
    "    mse = ((np.exp(1)-1)*((5-np.exp(1))/2) - 23/12)/(n*(np.exp(1)-1)**2)\n",
    "    if prt==True:\n",
    "        print('theta estimator is : %f' %theta_hat)\n",
    "        print('MSE is : %f' %mse)\n",
    "    return(theta_hat,mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta estimator is : 0.411968\n",
      "MSE is : 0.000015\n"
     ]
    }
   ],
   "source": [
    "CV_est , CV_mse = ControlVariates(n,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antithetic Variates\n",
    "As $x\\sim Unif(0,1)$, $1-x \\sim Unif(0,1)$. Thus\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}^{Antithetic} & = \\frac{1}{2n}\\sum_{i=1}^{n} \\left[ h(x_i) - h(1-x_i) \\right]\\\\\n",
    "&= \\frac{1}{2n}\\sum_{i=1}^{n}\\frac{e^{x_i} + e^{1-x_i} -2}{e-1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias\n",
    "As $x\\sim Unif(0,1)$, $1-x \\sim Unif(0,1)$. Thus\n",
    "$$\n",
    "E[e^{x-i}] = E[e^{1-x_i}] = e-1\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[\\hat{\\theta}^{Antithetic}]&= E\\left[\\frac{1}{2n}\\sum_{i=1}^{n}\\frac{e^{x_i} + e^{1-x_i} -2}{e-1}\\right]\\\\\n",
    "& = \\frac{1}{2n}\\sum_{i=1}^{n}\\frac{E[e^{x_i}] + E[e^{1-x_i}] -2}{e-1}\\\\\n",
    "& = \\frac{e-2}{e-1} = \\theta\n",
    "\\end{align*}\n",
    "$$\n",
    "Then bias of Antithetic variates is\n",
    "$$\n",
    "bias_\\theta (\\hat{\\theta}^{Antithetic})= E[\\hat{\\theta}^{Antithetic}] - \\theta = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance\n",
    "as $x_i$'s follows $Unif(0,1)$ and $1-x_i$'s follows $Unif(0,1)$ We can use same expectation and mgf  \n",
    "Variance of Antithetic variates estimator is\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_f[\\hat{\\theta}^{Antithetic}] & = \\frac{1}{4n^2 (e-1)^2}\\sum_{i=1}^{n}Var_f\\left[e^{x_i} - e^{1-x_i} -2\\right]\\\\\n",
    "&= \\frac{1}{4n^2 (e-1)^2}\\sum_{i=1}^{n}Var_f\\left[e^{x_i} - e^{1-x_i}\\right]\\\\\n",
    "&=\\frac{1}{4n^2 (e-1)^2}\\sum_{i=1}^{n}2\\left[E_f[e^{2x_i}]-E_f[e^{x_i}]^2 -\\left(E[e] - E_f[e^{x_i}]^2\\right)\\right]\\\\\n",
    "&=\\frac{1}{4n (e-1)^2}\\left[e^2-1 -4(e-1)^2 + 2e\\right]\\\\\n",
    "&=\\frac{1}{4n (e-1)^2}\\left[-3e^2 + 10e -5\\right]\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "$mse = bias^2 + var$. Thus,\n",
    "$$\n",
    "\\begin{align*}\n",
    "MSE(\\hat{\\theta}^{Antithetic}) &= 0 + \\frac{1}{4n (e-1)^2}\\left[-3e^2 + 10e -5\\right]\\\\ \n",
    "&= \\frac{1}{4n (e-1)^2}\\left[-3e^2 + 10e -5\\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Antithetic(n=100,prt = False):\n",
    "    theta = (np.exp(1)-2)/(np.exp(1)-1)\n",
    "    X = np.random.uniform(0,1,n)\n",
    "    theta_hat = ((np.exp(X) + np.exp(1-X) -2)/(np.exp(1)-1)).mean()/2\n",
    "    mse = (-3 * np.exp(1)**2 + 10 *np.exp(1) -5)/(4*n*((np.exp(1)-1)**2))\n",
    "    if prt==True:\n",
    "        print('theta estimator is : %f' %theta_hat)\n",
    "        print('MSE is : %f' %mse)\n",
    "    return(theta_hat,mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta estimator is : 0.417368\n",
      "MSE is : 0.000001\n"
     ]
    }
   ],
   "source": [
    "ant_est, ant_mse = Antithetic(n,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "MSE of (a) ~ (c) methods can be used for comparison of efficiency when sample size $n$ is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Estimator</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Theta</th>\n",
       "      <td>0.418023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crude Monte Carlo</th>\n",
       "      <td>0.417863</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importance sampling</th>\n",
       "      <td>0.421366</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>2.284921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control variates</th>\n",
       "      <td>0.413983</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.180349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antithetic variates</th>\n",
       "      <td>0.418003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.016165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Point Estimator       MSE  Efficiency\n",
       "True Theta                  0.418023  0.000000    0.000000\n",
       "Crude Monte Carlo           0.417863  0.000082    1.000000\n",
       "Importance sampling         0.421366  0.000187    2.284921\n",
       " Control variates           0.413983  0.000015    0.180349\n",
       "Antithetic variates         0.418003  0.000001    0.016165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1000\n",
    "comp = pd.DataFrame([((np.exp(1)-2)/(np.exp(1)-1),0),CrudeMC(n),importance(n),ControlVariates(n),Antithetic(n)])\n",
    "comp.index = ['True Theta','Crude Monte Carlo','Importance sampling',' Control variates','Antithetic variates']\n",
    "comp.columns = ['Point Estimator','MSE']\n",
    "base = comp['MSE'][comp['MSE'].index == 'Crude Monte Carlo']\n",
    "comp['Efficiency'] = comp['MSE']/float(base)\n",
    "display(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all methods are unbiased estimator we can conclude the efficiency by MSE. Antithetic variates method is most efficiency. Second is Control variates method. Third is Crude Monte Carlo mehod. Importance sampling shows worst efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "Define the varibles\n",
    "$$\n",
    "\\begin{align*}\n",
    "h(X) = I(X>c)\\\\\n",
    "f(X) = \\phi(X)\\\\\n",
    "g(X) = \\phi(X-b)\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\phi(\\cdot)$ denotes a standard normal density function\n",
    "$$\n",
    "\\begin{align*}\n",
    "p &= E_f[h(Z)] = E_g \\left[ h(Z)\\frac{f(Z)}{g(Z)}\\right]\\\\\n",
    "&\\approx \\frac{1}{n} \\sum_{i=1}^{n}h(z_i)\\frac{f(z_i)}{g(z_i)} = \\tilde{p}(b)\n",
    "\\end{align*} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) find $b^*$\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var[\\tilde{p}(b)] &\\propto var_g\\left(h(z)\\frac{f(z)}{g(z))}\\right) \\\\\n",
    "&=\\frac{1}{n^2} \\sum_{i=1}^{n}\\left\\{E_g\\left[\\left(h(z_i)\\frac{f(z_i)}{g(z_i)}\\right)^2\\right] - E_g\\left[h(z_i)\\frac{f(z_i)}{g(z_i)}\\right]^2\\right\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "When $S(\\cdot)$ be the survival function for a standard normal distribution\n",
    "$$\n",
    "\\begin{align*}\n",
    "E_g\\left[\\left(h(z_i)\\frac{f(z_i)}{g(z_i)}\\right)^2\\right] &= e^{b^2}\\int_{-\\infty}^{\\infty} I(z_i > c) \\phi(z_i) dz_i = e^{b^2} S(c+b)\\\\\n",
    "E_g\\left[h(z_i)\\frac{f(z_i)}{g(z_i)}\\right] &= E_f[h(z_i)] = S(c)\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus,\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_g[\\tilde{p}(b)] &= \\frac{1}{n^2} \\sum_{i=1}^{n} \\left[ e^{b^2} S(c+b) - S^2(c)\\right]\\\\\n",
    "&=\\frac{1}{n}\\left[ e^{b^2} S(c+b) - S^2(c)\\right]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "$Var_g[\\tilde{p}(b)]$ minimized when $\\partial Var_g[\\tilde{p}(b)] / \\partial b$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial Var_g[\\tilde{p}(b)]}{ \\partial b}&=^{let}0\\\\\n",
    "2b \\cdot e^{b^2}S(b+c) - e^{b^2}\\phi(b+c)&=0\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Therefore condition for $b^*$ that minimize $Var_g[\\tilde{p}(b)]$ is,\n",
    "$$\n",
    "2b \\cdot e^{b^2}S(b+c) - e^{b^2}\\phi(b+c)=0\\\\\n",
    "\\rightarrow2b^*\\cdot S(b^*+c) = \\phi(b^*+c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Find boundary condition\n",
    "From (a)\n",
    "$$\n",
    "\\frac{S(b^*+c)}{\\phi(b^*+c)} = \\frac{1}{2b^*}\n",
    "$$\n",
    "Use Mills' ratio\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\frac{1}{b^*+c}\\left(1 - \\frac{1}{(b^*+c)^2}\\right) \\ge \\frac{1}{2b^*} \\ge \\frac{1}{b^*+c}\\\\\n",
    "\\rightarrow&\\frac{2(b^*+c)^2-2}{(b^*+c)^3}\\ge \\frac{1}{b^*} \\ge \\frac{2}{b^*+c}\\\\\n",
    "\\rightarrow&\\frac{b^*+c}{2} \\ge b^* \\ge\\frac{(b^*+c)^3}{2(b^*+c)^2-2}\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus boundary conditons for $b^*$ is\n",
    "$$\n",
    "c \\le b^* \\text{ and}\\\\\n",
    "\\frac{(b^*-c)(b^*+c)^2}{2} \\le b^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) bisection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $b^* = c+ \\epsilon$, where $\\epsilon >0$ and $c>0$ Then,\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 \\le \\frac{(b^*-c)(b^*+c)^2}{2} &= \\frac{\\epsilon (2c + \\epsilon)^2}{2} \\le c + \\epsilon\\\\\n",
    "&\\rightarrow 0\\le \\epsilon(4c^2 + 4c\\epsilon + \\epsilon^2) \\le 2c + 2\\epsilon\\\\\n",
    "&\\rightarrow 0 \\le 4\\epsilon c^2 +4\\epsilon^2c + \\epsilon^3 \\le 2c + 2\\epsilon\\\\\n",
    "&\\rightarrow 0 \\le 4 c^2 +4\\epsilon c + \\epsilon^2 \\le 2\\frac{c}{\\epsilon} + 2\n",
    "&\\rightarrow\n",
    "\\end{align*}\n",
    "$$\n",
    "It is always true when $\\epsilon \\le 1$ so, we can setting the upper bound of bisection as $c+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_test(b,c):\n",
    "    return(scipy.stats.norm.sf(b+c)/scipy.stats.norm.pdf(b+c) - 1/(2*b))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(c,criteria = 10**(-7)):\n",
    "    lower= c\n",
    "    upper= c+1\n",
    "    while True: \n",
    "        bstar = (lower+upper)/2\n",
    "        if abs(bisection_test(bstar,c))<criteria:\n",
    "            return(bstar)\n",
    "            break\n",
    "        elif bisection_test(lower,c)*bisection_test(bstar,c)<0:\n",
    "            upper = bstar\n",
    "        else:\n",
    "            lower = bstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When c = 2, b* : 2.215931\n",
      "When c = 3, b* : 3.154846\n",
      "When c = 4, b* : 4.119675\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print('When c = %d, b* : %f' %(i,bisection(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $c= 2,3$ and $4$   \n",
    "$b^* = 2.215931,3.154846$ and $4.119675$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Calculate the efficiency\n",
    "We know that $\\hat{p} =\\tilde{p}(0) $.  \n",
    "From (a)\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var_g[\\tilde{p}(b)] &= \\frac{1}{n^2} \\sum_{i=1}^{n} \\left[ e^{b^2} S(c+b) - S^2(c)\\right]\\\\\n",
    "&=\\frac{1}{n}\\left[ e^{b^2} S(c+b) - S^2(c)\\right]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus,\n",
    "$$\n",
    "Efficiency = \\frac{Var[\\hat{p}]}{Var[\\tilde{p}(b^*)]} =\\frac{ S(c) - S^2(c)}{e^{{b^*}^2} S(c+b^*) - S^2(c)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varatio(b,c):\n",
    "    out = (scipy.stats.norm.sf(c) - \n",
    "           scipy.stats.norm.sf(c)**2)/ \\\n",
    "          (np.exp(b**2)*scipy.stats.norm.sf(c+b) \n",
    "           - scipy.stats.norm.sf(c)**2)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency when c = 2 is : 19.001601\n",
      "Efficiency when c = 3 is : 221.916501\n",
      "Efficiency when c = 4 is : 7061.451247\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print('Efficiency when c = %d is : %f' %(i,varatio(bisection(i),i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $c= 2,3$ and $4$   \n",
    "$Efficiency  = 19.001601,221.916501$ and $7061.451247$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

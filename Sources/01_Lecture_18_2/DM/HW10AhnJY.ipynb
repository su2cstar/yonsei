{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.linalg import *\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import minimize\n",
    "from collections import Counter\n",
    "import random\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivelm():\n",
    "    #input term\n",
    "    infname=input(\"Enter the data file name: \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "    else:\n",
    "        return('You could select only 1 or 2')\n",
    "    \n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "    else:\n",
    "        return('You could select only 1 or 2')\n",
    " \n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "    \n",
    "    data=pd.read_csv(infname,sep=form,header=header)\n",
    "\n",
    "    #calculate term\n",
    "\n",
    "    y=data.iloc[:,col]\n",
    "    x=data.drop(col,1)\n",
    "    n=data.shape[0]\n",
    "    p=data.shape[1]\n",
    "    one=pd.DataFrame(np.ones(n))\n",
    "    x=pd.concat([one,x],axis=1)\n",
    "\n",
    "    bhat=inv(x.transpose().dot(x)).dot(x.transpose()).dot(y)\n",
    "    yhat= x.dot(bhat)\n",
    "\n",
    "    estout=pd.concat([y,yhat],axis=1)\n",
    "\n",
    "    j=np.ones((n,n))\n",
    "    sse=y.transpose().dot(y)-bhat.transpose().dot(x.transpose()).dot(y)\n",
    "    ssto=y.transpose().dot(y) - (1/n)*y.transpose().dot(j).dot(y)\n",
    "\n",
    "    mse = sse /(n-p)\n",
    "    rsquared= 1 - ((n-1)/(n-p))*(sse/ssto)\n",
    "    mseout=pd.DataFrame([mse,rsquared])\n",
    "    #output and naming term\n",
    "    \"\"\"\n",
    "    outputm=input('Select your output 1:bhat 2:fittedvalue 3:mse&r-squared')\n",
    "    if(outputm=='1'):\n",
    "        bhat=pd.DataFrame(bhat)\n",
    "        b=[]\n",
    "        for i in bhat.index:\n",
    "            b.append('Beta' + str(i))\n",
    "        b[0]='Constant'\n",
    "        bhat.index=b\n",
    "        bhat.columns=['Coefficients']\n",
    "        return(bhat)\n",
    "    elif(outputm=='2'):\n",
    "        estout.columns.name = 'ID'\n",
    "        estout.columns = ['Actual values','Fitted values']\n",
    "        return(estout)\n",
    "    elif(outputm=='3'):\n",
    "        mseout.index=['R-Squared = ','MSE = ']\n",
    "        mseout.columns=['Model Summary']\n",
    "        return(mseout)\n",
    "    else:\n",
    "        return('You could select only 1,2 or 3')\n",
    "    \"\"\"\n",
    "    bhat=pd.DataFrame(bhat)\n",
    "    b=[]\n",
    "    for i in bhat.index:\n",
    "        b.append('Beta' + str(i))\n",
    "    b[0]='Constant'\n",
    "    bhat.index=b\n",
    "    bhat.columns=['Coefficients']\n",
    "    estout.columns.name = 'ID'\n",
    "    estout.columns = ['Actual values','Fitted values']\n",
    "    mseout.index=['R-Squared = ','MSE = ']\n",
    "    mseout.columns=['Model Summary']\n",
    "    output = np.array([bhat,estout,mseout])\n",
    "    \n",
    "    fname=input('Select your output file name: ')\n",
    "    bhat.to_csv(fname, mode='w',sep=' ' ,header=False)\n",
    "    estout.to_csv(fname, mode='a', header=True)\n",
    "    mseout.to_csv(fname, mode='a',sep=' ', header=False)\n",
    "    return(output)\n",
    "    #print(bhat,'\\n', estout, '\\n',mseout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startlda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    #calculate term\n",
    "\n",
    "    Y=train.iloc[:,col]\n",
    "    X=train.drop(col,1)\n",
    "    n=train.shape[0]\n",
    "    p=X.shape[1]\n",
    "\n",
    "    testY=test.iloc[:,col]\n",
    "    testX=test.drop(col,1)\n",
    "    testn=test.shape[0]\n",
    "\n",
    "    g=list(set(Y))\n",
    "    k=len(g)\n",
    "\n",
    "    x=[]\n",
    "    testx=[]\n",
    "    for i in g:\n",
    "        x.append(train[train.iloc[:,col]==i].drop(col,1))\n",
    "    for i in g:\n",
    "        testx.append(test[test.iloc[:,col]==i].drop(col,1))\n",
    "\n",
    "    xbar=[]\n",
    "    for i in range(k):\n",
    "        xbar.append(x[i].mean(axis=0))\n",
    "\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(x[i].shape[0]/n)\n",
    "    S=[]\n",
    "    for i in range(k):\n",
    "        S.append(x[i].cov())\n",
    "    p=X.shape[1]\n",
    "    sigma = pd.DataFrame(np.zeros((p,p)))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (x[i].shape[0]-1)*S[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "\n",
    "    #pred function\n",
    "    def dk(vec):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(xbar[i].dot(inv(Sp)).dot(vec) -0.5 * (xbar[i].dot(inv(Sp)).dot(xbar[i].transpose())) + math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    ## resub output\n",
    "    yhat = []\n",
    "    for i in range(n):\n",
    "        yhat.append(pred(dk(X.iloc[i])))\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(n+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "    cont = pd.crosstab(predy.iloc[:,1],predy.iloc[:,2])\n",
    "    acc = sum(np.diag(cont))/n\n",
    "    #acc = pd.DataFrame(acc)\n",
    "    \n",
    "    ## test output\n",
    "    testyhat = []\n",
    "    for i in range(testn):\n",
    "        testyhat.append(pred(dk(testX.iloc[i])))\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(testn+1)),testY,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "    tcont = pd.crosstab(tpredy.iloc[:,1],tpredy.iloc[:,2])\n",
    "    tacc = sum(np.diag(tcont))/testn\n",
    "    #tacc=pd.DataFrame(tacc)\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startqda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    #calculate term\n",
    "\n",
    "    Y=train.iloc[:,col]\n",
    "    X=train.drop(col,1)\n",
    "    n=train.shape[0]\n",
    "    p=X.shape[1]\n",
    "\n",
    "    testY=test.iloc[:,col]\n",
    "    testX=test.drop(col,1)\n",
    "    testn=test.shape[0]\n",
    "\n",
    "    g=list(set(Y))\n",
    "    k=len(g)\n",
    "\n",
    "    x=[]\n",
    "    testx=[]\n",
    "    for i in g:\n",
    "        x.append(train[train.iloc[:,col]==i].drop(col,1))\n",
    "    for i in g:\n",
    "        testx.append(test[test.iloc[:,col]==i].drop(col,1))\n",
    "\n",
    "    xbar=[]\n",
    "    for i in range(k):\n",
    "        xbar.append(x[i].mean(axis=0))\n",
    "\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(x[i].shape[0]/n)\n",
    "    S=[]\n",
    "    for i in range(k):\n",
    "        S.append(x[i].cov())\n",
    "    p=X.shape[1]\n",
    "    sigma = pd.DataFrame(np.zeros((p,p)))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (x[i].shape[0]-1)*S[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "\n",
    "    #pred function\n",
    "    def dk(vec):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "            #out.append(xbar[i].dot(inv(Sp)).dot(vec) -0.5 * (xbar[i].dot(inv(Sp)).dot(xbar[i].transpose())) + math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    ## resub output\n",
    "    yhat = []\n",
    "    for i in range(n):\n",
    "        yhat.append(pred(dk(X.iloc[i])))\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(n+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "    cont = pd.crosstab(predy.iloc[:,1],predy.iloc[:,2])\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    ## test output\n",
    "    testyhat = []\n",
    "    for i in range(testn):\n",
    "        testyhat.append(pred(dk(testX.iloc[i])))\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(testn+1)),testY,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "    tcont = pd.crosstab(tpredy.iloc[:,1],tpredy.iloc[:,2])\n",
    "    tacc = sum(np.diag(tcont))/testn\n",
    "\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startrda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        sh=1\n",
    "    elif hd=='2':\n",
    "        sh=0\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = np.genfromtxt(trfname, delimiter=form, skip_header=sh)\n",
    "    test = np.genfromtxt(tstfname, delimiter=form, skip_header=sh)\n",
    "\n",
    "    #calculate term\n",
    "    X = np.delete(train, col, 1) # input variable\n",
    "    Y = train[:,col] # target variable\n",
    "\n",
    "    n = len(train) # number of obs\n",
    "    p = X.shape[1] # number of variables\n",
    "\n",
    "    testX = np.delete(test, col, 1) # input variable\n",
    "    testY = test[:,col] # target variable\n",
    "\n",
    "    g = np.array(list(set(Y))) # unique value of target variable\n",
    "    k = len(g) # number of unique values\n",
    "\n",
    "    #calculate mean of each variables by y values\n",
    "    tmp=[]\n",
    "    for i in g:\n",
    "        tmp.append(X[np.where(train[:,col]==i)])\n",
    "    xby = np.array(tmp)\n",
    "    xbar = np.array(list(map(lambda x : np.mean(x,axis=0),xby)))\n",
    "\n",
    "    #prior probability\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(xby[i].shape[0]/n)\n",
    "    pw = np.array(pw)\n",
    "\n",
    "    #np.cov(xby[0].transpose())\n",
    "    S0 = np.array(list(map(lambda x : np.cov(x.transpose()) , xby)))\n",
    "\n",
    "    # ready for calculate covariance matrix\n",
    "    sigma =np.zeros((p,p))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (xby[i].shape[0]-1)*S0[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "    \n",
    "    def dk(vec, S = S0):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "        return(out)\n",
    "    \n",
    "    def dk2(vec, S = S0):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*np.diag((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    tp = np.array(list(map(dk,X)))\n",
    "    yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    #ready for grid search\n",
    "    s2=np.diag(Sp).mean()\n",
    "\n",
    "    def getacc(Sk ,a,r):\n",
    "        Sar = a*Sk + (1 - a)*(r*Sp + (1 - r)*s2*np.identity(p))\n",
    "        tp2 = np.array(dk2(testX,Sar)).reshape(k,len(testX)).transpose()\n",
    "        yhatg = np.argmax(tp2,axis =1)\n",
    "        contg = pd.crosstab(testY,yhatg)\n",
    "        acc2 = sum(np.diag(contg))/len(test)\n",
    "        return(acc2)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    gridseed=21\n",
    "    for i in range(gridseed):\n",
    "        df=df.append(pd.DataFrame(np.zeros(gridseed)).transpose())\n",
    "    alpha = gamma = list(map(lambda x : x/(gridseed-1) , list(range(gridseed))))\n",
    "    df.columns=alpha\n",
    "    df.index=gamma\n",
    "    for a ,i in zip(alpha , range(gridseed)):\n",
    "        for r, j in zip(gamma, range(gridseed)) :\n",
    "            df.iloc[i,j]= getacc(S0,a,r)\n",
    "    #get the optimized value of alpha & gamma (alpha = 0.53, beta = 1)\n",
    "    argm=df.stack().index[np.argmax(df.values)]\n",
    "    a = argm[0]\n",
    "    r = argm[1]\n",
    "    Snew = a*S0 + (1 - a)*(r*Sp + (1 - r)*s2*np.identity(p))\n",
    "\n",
    "    #resub output\n",
    "    tp = np.array(list(map(lambda x : dk(x,Snew),X)))\n",
    "    yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    #test output\n",
    "    ttp = np.array(list(map(lambda x : dk(x,Snew),testX)))\n",
    "    tyhat = np.argmax(ttp,axis =1)\n",
    "    tcont = pd.crosstab(testY,tyhat)\n",
    "    tacc = sum(np.diag(tcont))/len(test)\n",
    "\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(len(train)+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(len(test)+1)),testY,tyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "\n",
    "    cont.columns = g\n",
    "    cont.index = g\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "\n",
    "    tcont.columns = g\n",
    "    tcont.index = g\n",
    "    tcont.columns.name = 'Prediction Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #plotting\n",
    "    x = df.columns\n",
    "    y = df.index\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = df\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    plt.show()\n",
    "    \n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startlogi():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        sh=1\n",
    "    elif hd=='2':\n",
    "        sh=0\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "    coff=input(\"Select your cutoff value: \")    \n",
    "    cutoff = float(coff)\n",
    "    \n",
    "    train = np.genfromtxt(trfname, delimiter=form, skip_header=sh)\n",
    "    test = np.genfromtxt(tstfname, delimiter=form, skip_header=sh)\n",
    "\n",
    "    #calculate term\n",
    "    X = np.delete(train, col, 1) # input variable\n",
    "    Y = train[:,col] # target variable\n",
    "\n",
    "    n = len(train) # number of obs\n",
    "    p = X.shape[1] # number of variables\n",
    "\n",
    "    testX = np.delete(test, col, 1) # input variable\n",
    "    testY = test[:,col] # target variable\n",
    "    testn = len(test)\n",
    "\n",
    "    g = np.array(list(set(Y))) # unique value of target variable\n",
    "    k = len(g) # number of unique values\n",
    "\n",
    "    tmp = np.zeros((X.shape[0],X.shape[1]+1))\n",
    "    tmp[:,0]= np.ones(n)\n",
    "    tmp[:,1:] = X\n",
    "    Xj= tmp\n",
    "    beta = np.ones(p+1)/10\n",
    "    Yb = np.array(list(map(int,Y==g[1])))\n",
    "\n",
    "    testmp = np.zeros((testX.shape[0],testX.shape[1]+1))\n",
    "    testmp[:,0]= np.ones(testn)\n",
    "    testmp[:,1:] = testX\n",
    "    testXj = testmp\n",
    "    testYb = np.array(list(map(int,testY==g[1])))\n",
    "\n",
    "    def loglike(beta):\n",
    "        a=-Yb.T.dot(Xj).dot(beta)+sum(np.log(1+np.exp(Xj.dot(beta))))\n",
    "        return a\n",
    "    opt = minimize(loglike , beta )\n",
    "    betahat = opt.x\n",
    "\n",
    "    def gety(x):\n",
    "        if x>=cutoff:\n",
    "            return g[1]\n",
    "        elif x<cutoff:\n",
    "            return g[0]\n",
    "\n",
    "    yhat = np.exp(Xj.dot(betahat))/(1+np.exp(Xj.dot(betahat)))\n",
    "    Yhat = np.array(list(map(gety,yhat)))\n",
    "\n",
    "    testyhat = np.exp(testXj.dot(betahat))/(1+np.exp(testXj.dot(betahat)))\n",
    "    testYhat = np.array(list(map(gety,testyhat))) \n",
    "\n",
    "    #resub output\n",
    "    #tp = np.array(list(map(lambda x : dk(x,Snew),X)))\n",
    "    #yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,Yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "    spe = cont.iloc[0,0]/sum(cont.iloc[0,:])\n",
    "    sens = cont.iloc[1,1]/sum(cont.iloc[1,:])\n",
    "    \n",
    "    #test output\n",
    "    #ttp = np.array(list(map(lambda x : dk(x,Snew),testX)))\n",
    "    #tyhat = np.argmax(ttp,axis =1)\n",
    "    tcont = pd.crosstab(testY,testYhat)\n",
    "    tacc = sum(np.diag(tcont))/len(test)\n",
    "    tspe = tcont.iloc[0,0]/sum(tcont.iloc[0,:])\n",
    "    tsens = tcont.iloc[1,1]/sum(tcont.iloc[1,:])\n",
    "    \n",
    "\n",
    "    predy = pd.DataFrame([range(1,(len(train)+1)),Y,Yhat,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred','Pred Prob']\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(len(test)+1)),testY,testYhat,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred','Pred Prob']\n",
    "\n",
    "    cont.columns = g\n",
    "    cont.index = g\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "\n",
    "    tcont.columns = g\n",
    "    tcont.index = g\n",
    "    tcont.columns.name = 'Prediction Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    \n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "    print(\"Sensitivity = %0.3f\" %(sens))\n",
    "    print(\"Specificity = %0.3f\" %(spe))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    print(\"Sensitivity = %0.3f\" %(tsens))\n",
    "    print(\"Specificity = %0.3f\" %(tspe))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(sens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(spe),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(tsens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(tspe),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbayes():\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    #tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "    data= pd.read_csv(trfname, header = header , sep = form)\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    yCol = int(cl)-1\n",
    "    coff=input(\"Select your cutoff value: \")    \n",
    "    cutoff = float(coff)\n",
    "    misVal = input(\"input shape of your missing data: \")\n",
    "\n",
    "    Xraw = data.drop(yCol,1)\n",
    "    Y = data.iloc[:, yCol]\n",
    "\n",
    "    #test Y have 2 category\n",
    "    if len(set(Y))!=2:\n",
    "        return('you must input data with binary y value')\n",
    "    # let max(Y) = 1 (True) , min(Y) = 0 (False)\n",
    "\n",
    "    #treat the missing value\n",
    "    X = Xraw.replace('?',np.nan).apply(pd.to_numeric)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # count the number of unique values, when it is less or equal than 10 treat the variable as categorical\n",
    "    unqCnt = []\n",
    "    for i in range(X.shape[1]):\n",
    "        unqCnt += [len(set(X.iloc[:,i]))]\n",
    "    uqCnt = np.array(unqCnt)\n",
    "\n",
    "    cateVarInd = np.where(uqCnt<=10)[0] # index of the categoral values\n",
    "    numerVarInd = np.where(uqCnt>10)[0] # index of the numerical values\n",
    "\n",
    "    # for gaussian naive bayes we need to calculate the variance and mean of numerical variables\n",
    "    X1 = X[list(map(bool, Y - min(Y)))] # Y = max(Y)\n",
    "    X0 = X[list(map(bool, Y - max(Y)))] # Y = min(Y)\n",
    "    #True\n",
    "    mu1 = dict(np.mean(X1,axis = 0)[numerVarInd])\n",
    "    std1 = dict(np.std(X1,axis = 0)[numerVarInd])\n",
    "    #False\n",
    "    mu0 = dict(np.mean(X0,axis = 0)[numerVarInd])\n",
    "    std0 = dict(np.std(X0,axis = 0)[numerVarInd])\n",
    "\n",
    "\n",
    "    # when true X ~ N (mu1, var1)\n",
    "    # P( X =x | True) =  (1/(sqrt(2pie)*std))*exp((-(x-mu)^2)/(2*std^2))\n",
    "\n",
    "    # make probability table\n",
    "    cst= dict()\n",
    "    for i in cateVarInd:\n",
    "        cst.update({i:pd.crosstab(X.iloc[:,i],Y)})\n",
    "        for j in range(2):\n",
    "            cst[i].iloc[:,j] = cst[i].iloc[:,j]/sum(cst[i].iloc[:,j])\n",
    "\n",
    "    # calculate prob\n",
    "    def calcDPT(row):\n",
    "        p = 1\n",
    "        for j in cateVarInd:\n",
    "            if np.isnan(row[j]):\n",
    "                p = p\n",
    "            else:\n",
    "                p = p * cst[j].loc[row[j]][max(Y)]\n",
    "        return(p)\n",
    "\n",
    "    def calcDPF(row):\n",
    "        p = 1\n",
    "        for j in cateVarInd:\n",
    "            if np.isnan(row[j]):\n",
    "                p = p\n",
    "            else:\n",
    "                p = p * cst[j].loc[row[j]][min(Y)]\n",
    "        return(p)\n",
    "\n",
    "    def calcNPT(row):\n",
    "        p = 1\n",
    "        for j in numerVarInd:\n",
    "            if np.isnan(row[j]):\n",
    "                p = p\n",
    "            else:\n",
    "                p = p * (1/(((2*np.pi)**0.5)*std1[j]))*np.exp((-(row[j]-mu1[j])**2)/(2*std1[j]**2))\n",
    "        return(p)\n",
    "\n",
    "    def calcNPF(row):\n",
    "        p = 1\n",
    "        for j in numerVarInd:\n",
    "            if np.isnan(row[j]):\n",
    "                p = p\n",
    "            else:\n",
    "                p = p * (1/(((2*np.pi)**0.5)*std0[j]))*np.exp((-(row[j]-mu0[j])**2)/(2*std0[j]**2))\n",
    "        return(p)\n",
    "\n",
    "    def calcT(row):\n",
    "        return(calcDPT(row)*calcNPT(row))\n",
    "\n",
    "    def calcF(row):\n",
    "        return(calcDPF(row)*calcNPF(row))\n",
    "\n",
    "    def getTprob(row):\n",
    "        return calcT(row)/(calcT(row)+calcF(row))\n",
    "\n",
    "    predProb = []\n",
    "    for i in range(X.shape[0]):\n",
    "        predProb.append(getTprob(X.iloc[i,:]))\n",
    "\n",
    "    def gety(x):\n",
    "        if x>=cutoff:\n",
    "            return max(Y)\n",
    "        elif x<cutoff:\n",
    "            return min(Y)\n",
    "\n",
    "    Yhat = np.array(list(map(gety,predProb)))\n",
    "    yprob = list(map(lambda x : round(x,3),predProb))\n",
    "\n",
    "    cont = pd.crosstab(Y,Yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "    spe = cont.iloc[0,0]/sum(cont.iloc[0,:])\n",
    "    sens = cont.iloc[1,1]/sum(cont.iloc[1,:])\n",
    "    predy = pd.DataFrame([range(1,(len(X)+1)),Y,Yhat,yprob]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred','Pred Prob']\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "    fname = input('Write your output file name : ')\n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "    print(\"Sensitivity = %0.3f\" %(sens))\n",
    "    print(\"Specificity = %0.3f\" %(spe))\n",
    "\n",
    "    #file output\n",
    "\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(sens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(spe),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT1lvOld():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    yCol = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    X = train.drop(yCol,1)\n",
    "    Y = train.iloc[:, yCol]\n",
    "    df = pd.concat([X, Y], axis=1)\n",
    "\n",
    "    tX = test.drop(yCol,1)\n",
    "    tY = test.iloc[:, yCol]\n",
    "    tdf = pd.concat([tX, tY], axis=1)\n",
    "    unqCnt = []\n",
    "    for i in range(X.shape[1]):\n",
    "        unqCnt += [len(set(X.iloc[:,i]))]\n",
    "    uqCnt = np.array(unqCnt)\n",
    "\n",
    "    cateVarInd = np.where(uqCnt<=10)[0] # index of the categoral values\n",
    "    numerVarInd = np.where(uqCnt>10)[0] # index of the numerical values\n",
    "\n",
    "    def calcGini(vec):\n",
    "        return 1 - (sum(vec==min(Y))/len(vec))**2-(sum(vec==max(Y))/len(vec))**2\n",
    "\n",
    "    def searchCoff(df , cInd):\n",
    "        out = []\n",
    "        for i in sorted(list(set(df[cInd])))[:-1]:\n",
    "            g1 = df[df[cInd] <= i]\n",
    "            g2 = df[df[cInd] > i]\n",
    "            wGini = len(g1)*calcGini(g1[yCol])+len(g2)*calcGini(g2[yCol])\n",
    "            out.append([wGini,i])\n",
    "        return sorted(out , key = lambda x : x[0])[0]\n",
    "\n",
    "    ret = []\n",
    "    for i in numerVarInd:\n",
    "        ret.append([i]+searchCoff(df,i))\n",
    "\n",
    "    res = sorted(ret, key = lambda x : x[1])[0]\n",
    "\n",
    "    g1 = df[df[res[0]] <= res[2]]\n",
    "    g2 = df[df[res[0]] > res[2]]\n",
    "\n",
    "    if Counter(g1[yCol])[min(Y)] > Counter(g1[yCol])[max(Y)]:\n",
    "        g1val = min(Y)\n",
    "        g2val = max(Y)\n",
    "    else:\n",
    "        g1val = max(Y)\n",
    "        g2val = min(Y)\n",
    "\n",
    "    def getYhat(vec):\n",
    "        if vec[res[0]] <= res[2]:\n",
    "            return g1val\n",
    "        else:\n",
    "            return g2val\n",
    "\n",
    "    rslt= []\n",
    "    for i in range(X.shape[0]):\n",
    "        rslt.append(getYhat(X.iloc[i,:]))\n",
    "    rslt = np.array(rslt)\n",
    "\n",
    "    cont = pd.crosstab(Y,rslt)\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "    acc = sum(np.diag(cont))/len(Y)\n",
    "    spe = cont.iloc[0,0]/sum(cont.iloc[0,:])\n",
    "    sens = cont.iloc[1,1]/sum(cont.iloc[1,:])\n",
    "    predy = pd.DataFrame([range(1,(len(X)+1)),Y,rslt]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "\n",
    "    trslt= []\n",
    "    for i in range(tX.shape[0]):\n",
    "        trslt.append(getYhat(tX.iloc[i,:]))\n",
    "    trslt = np.array(trslt)\n",
    "\n",
    "    tcont = pd.crosstab(tY,trslt)\n",
    "    tcont.columns.name = 'Test Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "    tacc = sum(np.diag(tcont))/len(tY)\n",
    "    tspe = tcont.iloc[0,0]/sum(tcont.iloc[0,:])\n",
    "    tsens = tcont.iloc[1,1]/sum(tcont.iloc[1,:])\n",
    "    tpredy = pd.DataFrame([range(1,(len(tX)+1)),tY,trslt]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    \n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "    print(\"Sensitivity = %0.3f\" %(sens))\n",
    "    print(\"Specificity = %0.3f\" %(spe))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    print(\"Sensitivity = %0.3f\" %(tsens))\n",
    "    print(\"Specificity = %0.3f\" %(tspe))\n",
    "\n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(sens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(spe),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(tsens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(tspe),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT1lv():\n",
    "\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    yno = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "\n",
    "    yCol=train.columns[yno]\n",
    "\n",
    "\n",
    "    X = train.drop(yCol,1)\n",
    "    Y = train.iloc[:, yno]\n",
    "    df = pd.concat([X, Y], axis=1)\n",
    "\n",
    "    tX = test.drop(yCol,1)\n",
    "    tY = test.iloc[:, yno]\n",
    "    tdf = pd.concat([tX, tY], axis=1)\n",
    "    unqCnt = []\n",
    "    for i in range(X.shape[1]):\n",
    "        unqCnt += [len(set(X.iloc[:,i]))]\n",
    "    uqCnt = np.array(unqCnt)\n",
    "\n",
    "\n",
    "    unqCnt = []\n",
    "    for i in range(X.shape[1]):\n",
    "        unqCnt += [len(set(X.iloc[:,i]))]\n",
    "    uqCnt = np.array(unqCnt)\n",
    "\n",
    "    cateVarInd = np.where(uqCnt<=10)[0] # index of the categoral values\n",
    "    numerVarInd = np.where(uqCnt>10)[0] # index of the numerical values\n",
    "\n",
    "\n",
    "    def speLst(lst):\n",
    "        n = len(lst)\n",
    "        ctgry=[]\n",
    "        for i in range(1,2**(n-1)):\n",
    "            ctgry.append(list('{:#b}'.format(i)[2:].zfill(n)))\n",
    "\n",
    "        boolCtgry = [[bool(int(y)) for y in x] for x in ctgry]\n",
    "\n",
    "        g1 = []\n",
    "        for i in boolCtgry:\n",
    "            g1.append(sorted(np.array(lst)[i]))\n",
    "        return g1\n",
    "\n",
    "\n",
    "    dicInd = dict()\n",
    "    for i in cateVarInd:\n",
    "        dicInd.update({i:speLst(list(set(X.iloc[:,i])))})\n",
    "\n",
    "\n",
    "    def calcGini(vec):\n",
    "        return 1 - (sum(vec==min(Y))/len(vec))**2-(sum(vec==max(Y))/len(vec))\n",
    "\n",
    "    def searchCoffcat(df,i):\n",
    "        out = []\n",
    "        for j in dicInd[i]:\n",
    "            g1ind = j\n",
    "            g2ind = [x for x in list(set(df.iloc[:,i])) if x not in g1ind]\n",
    "            g1 = df[list(map(lambda x:x in g1ind,df.iloc[:,i]))]\n",
    "            g2 = df[list(map(lambda x:x in g2ind,df.iloc[:,i]))]\n",
    "            wGini = len(g1)*calcGini(g1[yCol])+len(g2)*calcGini(g2[yCol])\n",
    "            out.append([wGini,j])  \n",
    "        return sorted(out , key = lambda x : x[0])[0]\n",
    "\n",
    "\n",
    "    def searchCoff(df , cInd):\n",
    "        out = []\n",
    "        for i in sorted(list(set(df[cInd])))[:-1]:\n",
    "            g1 = df[df[cInd] <= i]\n",
    "            g2 = df[df[cInd] > i]\n",
    "            wGini = len(g1)*calcGini(g1[yCol])+len(g2)*calcGini(g2[yCol])\n",
    "            out.append([wGini,i])\n",
    "        return sorted(out , key = lambda x : x[0])[0]\n",
    "\n",
    "    ret = []\n",
    "    for i in numerVarInd:\n",
    "        ret.append([i]+searchCoff(df,i))\n",
    "\n",
    "    retCat = []\n",
    "    for i in cateVarInd:\n",
    "        retCat.append([i]+searchCoffcat(df,i))\n",
    "\n",
    "\n",
    "    retall = ret + retCat\n",
    "\n",
    "    resCat = sorted(retall, key = lambda x : x[1])[0]\n",
    "\n",
    "    if resCat[0] in cateVarInd:\n",
    "        g1 = df[list(map(lambda x:x in resCat[2], df.iloc[:,resCat[0]]))]\n",
    "        g2 = df[list(map(lambda x:x not in resCat[2], df.iloc[:,resCat[0]]))]\n",
    "        #g2 = df[df[res[0]] > res[2]]\n",
    "    else:\n",
    "        g1 = df[df[resCat[0]] <= resCat[2]]\n",
    "        g2 = df[df[resCat[0]] > resCat[2]]\n",
    "\n",
    "\n",
    "\n",
    "    if Counter(g1[yCol])[min(Y)] > Counter(g1[yCol])[max(Y)]:\n",
    "        g1val = min(Y)\n",
    "        g2val = max(Y)\n",
    "    else:\n",
    "        g1val = max(Y)\n",
    "        g2val = min(Y)\n",
    "\n",
    "\n",
    "\n",
    "    def getYhat(vec):\n",
    "        if resCat[0] in cateVarInd:\n",
    "            if vec[resCat[0]] in resCat[2]:\n",
    "                return g1val\n",
    "            else:\n",
    "                return g2val\n",
    "        else:\n",
    "            if vec[resCat[0]] <= resCat[2]:\n",
    "                return g1val\n",
    "            else:\n",
    "                return g2val\n",
    "\n",
    "\n",
    "    rslt= []\n",
    "    for i in range(X.shape[0]):\n",
    "        rslt.append(getYhat(X.iloc[i,:]))\n",
    "    rslt = np.array(rslt)\n",
    "\n",
    "    cont = pd.crosstab(Y,rslt)\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "    acc = sum(np.diag(cont))/len(Y)\n",
    "    spe = cont.iloc[0,0]/sum(cont.iloc[0,:])\n",
    "    sens = cont.iloc[1,1]/sum(cont.iloc[1,:])\n",
    "    predy = pd.DataFrame([range(1,(len(X)+1)),Y,rslt]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "\n",
    "\n",
    "\n",
    "    trslt= []\n",
    "    for i in range(tX.shape[0]):\n",
    "        trslt.append(getYhat(tX.iloc[i,:]))\n",
    "    trslt = np.array(trslt)\n",
    "\n",
    "    tcont = pd.crosstab(tY,trslt)\n",
    "    tcont.columns.name = 'Test Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "    tacc = sum(np.diag(tcont))/len(tY)\n",
    "    tspe = tcont.iloc[0,0]/sum(tcont.iloc[0,:])\n",
    "    tsens = tcont.iloc[1,1]/sum(tcont.iloc[1,:])\n",
    "    tpredy = pd.DataFrame([range(1,(len(tX)+1)),tY,trslt]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "\n",
    "\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    print('Tree Structure')\n",
    "    if resCat[0] in cateVarInd:\n",
    "        print('\\tNode1 : %s in %s (%d,%d)' %(df.columns[[resCat[0]]][0],set(resCat[2]),Counter(train[yCol])[g1val],Counter(train[yCol])[g2val]))\n",
    "        print('\\t Node2 : %s (%d,%d)' %(str(g1.iloc[:,resCat[0]].iloc[0]==resCat[2][0]),Counter(g1[yCol])[g1val],Counter(g1[yCol])[g2val]))\n",
    "        print('\\t Node2 : %s (%d,%d)' %(str(g2.iloc[:,resCat[0]].iloc[0]==resCat[2][0]),Counter(g2[yCol])[g1val],Counter(g2[yCol])[g2val]))\n",
    "    else:\n",
    "        print('\\tNode1 : X%d <= %f (%d,%d)' %(resCat[0]+1,resCat[2],Counter(train[yCol])[g1val],Counter(train[yCol])[g2val]))    \n",
    "        print('\\t Node2 : %s (%d,%d)' %(str(True),Counter(g1[yCol])[g1val],Counter(g1[yCol])[g2val]))\n",
    "        print('\\t Node2 : %s (%d,%d)' %(str(False),Counter(g2[yCol])[g1val],Counter(g2[yCol])[g2val]))\n",
    "\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "    print(\"Sensitivity = %0.3f\" %(sens))\n",
    "    print(\"Specificity = %0.3f\" %(spe))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    print(\"Sensitivity = %0.3f\" %(tsens))\n",
    "    print(\"Specificity = %0.3f\" %(tspe))\n",
    "    #print(resCat)\n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print('Tree Structure',file=out)\n",
    "        if resCat[0] in cateVarInd:\n",
    "            print('\\tNode1 : %s in %s (%d,%d)' %(df.columns[[resCat[0]]][0],set(resCat[2]),Counter(train[yCol])[g1val],Counter(train[yCol])[g2val]),file=out)\n",
    "            print('\\t Node2 : %s (%d,%d)' %(str(g1.iloc[:,resCat[0]].iloc[0]==resCat[2][0]),Counter(g1[yCol])[g1val],Counter(g1[yCol])[g2val]),file=out)\n",
    "            print('\\t Node2 : %s (%d,%d)' %(str(g2.iloc[:,resCat[0]].iloc[0]==resCat[2][0]),Counter(g2[yCol])[g1val],Counter(g2[yCol])[g2val]),file=out)\n",
    "        else:\n",
    "            print('\\tNode1 : X%d <= %f (%d,%d)' %(resCat[0]+1,resCat[2],Counter(train[yCol])[g1val],Counter(train[yCol])[g2val]),file=out)\n",
    "            print('\\t Node2 : %s (%d,%d)' %(str(True),Counter(g1[yCol])[g1val],Counter(g1[yCol])[g2val]),file=out)\n",
    "            print('\\t Node2 : %s (%d,%d)' %(str(False),Counter(g2[yCol])[g1val],Counter(g2[yCol])[g2val]),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(sens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(spe),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(tsens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(tspe),file=out)\n",
    "    out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baglda():\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    \n",
    "    testY=test.iloc[:,col]\n",
    "    testX=test.drop(col,1)\n",
    "    testn=test.shape[0]\n",
    "    testx = []\n",
    "    g=list(set(testY))\n",
    "    for i in g:\n",
    "        testx.append(test[test.iloc[:,col]==i].drop(col,1))\n",
    "\n",
    "    bagTrainLst=[]\n",
    "    random.seed(0)\n",
    "    for i in range(51):\n",
    "        bagIndex = []\n",
    "        for i in range(train.shape[0]):\n",
    "            bagIndex.append(random.randint(0,train.shape[0]-1))\n",
    "        bagTrain = train.iloc[bagIndex,:]\n",
    "        bagTrain.index = range(bagTrain.shape[0])\n",
    "        bagTrainLst.append(bagTrain)\n",
    "\n",
    "    def geyhat(bagTrain):\n",
    "        bagY=bagTrain.iloc[:,col]\n",
    "        bagX=bagTrain.drop(col,1)\n",
    "        bagn=bagTrain.shape[0]\n",
    "        bagp=bagX.shape[1]\n",
    "\n",
    "        bagG=list(set(bagY))\n",
    "        bagK=len(bagG)\n",
    "\n",
    "        bagx=dict()\n",
    "        for i in bagG:\n",
    "            bagx.update({i:(bagTrain[bagTrain.iloc[:,col]==i].drop(col,1))})\n",
    "        bagXbar=dict()\n",
    "        for i in bagG:\n",
    "            bagXbar.update({i:bagx[i].mean(axis=0)})\n",
    "\n",
    "        bagpw=dict()\n",
    "        for i in bagG:\n",
    "            bagpw.update({i:bagx[i].shape[0]/bagTrain.shape[0]})\n",
    "\n",
    "        bagS=dict()\n",
    "        for i in bagG:\n",
    "            bagS.update({i:bagx[i].cov()})\n",
    "        p=bagX.shape[1]\n",
    "        sigma = pd.DataFrame(np.zeros((p,p)))\n",
    "        for i in bagG:\n",
    "            sigma = sigma + (bagx[i].shape[0]-1)*bagS[i]\n",
    "        bagSp=sigma*(1/(bagTrain.shape[0]-bagK))\n",
    "\n",
    "        #pred function\n",
    "        def dk(vec):\n",
    "            out=dict()\n",
    "            for i in bagG:\n",
    "                out.update({i:bagXbar[i].dot(inv(bagSp)).dot(vec) -0.5 * (bagXbar[i].dot(inv(bagSp)).dot(bagXbar[i].transpose())) + np.log(bagpw[i])})\n",
    "            return(out)\n",
    "        def pred(mydict):\n",
    "            return (max(mydict , key = mydict.get))\n",
    "        testyhat = []\n",
    "        for i in range(testn):\n",
    "            testyhat.append(pred(dk(testX.iloc[i])))\n",
    "\n",
    "        return(testyhat)\n",
    "\n",
    "    yhLst = []\n",
    "    for bgTr in bagTrainLst:\n",
    "        yhLst.append(geyhat(bgTr))\n",
    "\n",
    "    bagYhat = pd.DataFrame(yhLst).mode().values \n",
    "    noBag = np.array(geyhat(train))\n",
    "\n",
    "    tcont = pd.crosstab(testY,list(bagYhat))\n",
    "    tacc = sum(np.diag(tcont))/sum(sum(tcont.values))\n",
    "\n",
    "    cont = pd.crosstab(testY,noBag)\n",
    "    acc = sum(np.diag(cont))/sum(sum(cont.values))\n",
    "\n",
    "    cont.columns.name = 'Predicted Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "\n",
    "    tcont.columns.name = 'Predicted Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(len(test)+1)),testY,noBag]).transpose()\n",
    "    predy.columns=['ID','Actual class','LDA-nobagging pred']\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(len(test)+1)),testY,bagYhat[0]]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','LDA-bagging pred']\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (LDA - no bagging)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (LDA - no bagging)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (LDA - bagging)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (LDA - bagging)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startclf():\n",
    "    inp = input('Select Classification model 1 = LDA , 2 = QDA, 3 = RDA, 4 = logistic regression, 5 = Naive Bayes, 6 = 1 level Dicision Tree, 7 = bagging ensemble : ')\n",
    "    if inp=='1':\n",
    "        return(startlda())\n",
    "    elif inp=='2':\n",
    "        return(startqda())\n",
    "    elif inp=='3':\n",
    "        return(startrda())\n",
    "    elif inp=='4':\n",
    "        return(startlogi())\n",
    "    elif inp=='5':\n",
    "        return(nbayes())\n",
    "    elif inp=='6':\n",
    "        return DT1lv()\n",
    "    elif inp=='7':\n",
    "        return (baglda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    inp = input('Select model 1 = Linear regression , 2 = Classification : ')\n",
    "    if inp=='1':\n",
    "        return(naivelm())\n",
    "    if inp=='2':\n",
    "        return(startclf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select model 1 = Linear regression , 2 = Classification : 2\n",
      "Select Classification model 1 = LDA , 2 = QDA, 3 = RDA, 4 = logistic regression, 5 = Naive Bayes, 6 = 1 level Dicision Tree, 7 = bagging ensemble : 7\n",
      "Write your train data file name : veh.dat\n",
      "Write your test data file name : vehtest.dat\n",
      "Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): 2\n",
      "Select the data header format(1 = with header or 2 = no header): 2\n",
      "Select column# where your y vlaues exist: 19\n",
      "Write your output file name : hw10out.txt\n",
      "ID  Actual class  LDA-nobagging pred\n",
      "  1             1                   2\n",
      "  2             1                   1\n",
      "  3             1                   2\n",
      "  4             1                   4\n",
      "  5             1                   2\n",
      "  6             1                   1\n",
      "  7             1                   2\n",
      "  8             1                   1\n",
      "  9             1                   1\n",
      " 10             1                   2\n",
      " 11             1                   1\n",
      " 12             1                   1\n",
      " 13             1                   2\n",
      " 14             1                   2\n",
      " 15             1                   1\n",
      " 16             1                   1\n",
      " 17             1                   1\n",
      " 18             1                   3\n",
      " 19             1                   1\n",
      " 20             1                   1\n",
      " 21             1                   1\n",
      " 22             2                   2\n",
      " 23             2                   3\n",
      " 24             2                   2\n",
      " 25             2                   1\n",
      " 26             2                   3\n",
      " 27             2                   1\n",
      " 28             2                   2\n",
      " 29             2                   2\n",
      " 30             2                   2\n",
      " 31             2                   1\n",
      " 32             2                   2\n",
      " 33             2                   3\n",
      " 34             2                   2\n",
      " 35             2                   1\n",
      " 36             2                   1\n",
      " 37             2                   1\n",
      " 38             2                   2\n",
      " 39             2                   3\n",
      " 40             2                   1\n",
      " 41             2                   2\n",
      " 42             2                   2\n",
      " 43             2                   1\n",
      " 44             3                   3\n",
      " 45             3                   3\n",
      " 46             3                   3\n",
      " 47             3                   3\n",
      " 48             3                   3\n",
      " 49             3                   3\n",
      " 50             3                   3\n",
      " 51             3                   3\n",
      " 52             3                   3\n",
      " 53             3                   3\n",
      " 54             3                   3\n",
      " 55             3                   3\n",
      " 56             3                   3\n",
      " 57             3                   3\n",
      " 58             3                   3\n",
      " 59             3                   3\n",
      " 60             3                   3\n",
      " 61             3                   3\n",
      " 62             3                   3\n",
      " 63             3                   3\n",
      " 64             3                   3\n",
      " 65             3                   3\n",
      " 66             4                   4\n",
      " 67             4                   4\n",
      " 68             4                   4\n",
      " 69             4                   4\n",
      " 70             4                   4\n",
      " 71             4                   4\n",
      " 72             4                   4\n",
      " 73             4                   4\n",
      " 74             4                   3\n",
      " 75             4                   4\n",
      " 76             4                   4\n",
      " 77             4                   4\n",
      " 78             4                   4\n",
      " 79             4                   4\n",
      " 80             4                   4\n",
      " 81             4                   4\n",
      " 82             4                   4\n",
      " 83             4                   4\n",
      " 84             4                   4\n",
      " 85             4                   4\n",
      " 86             1                   2\n",
      " 87             1                   2\n",
      " 88             1                   1\n",
      " 89             1                   1\n",
      " 90             1                   1\n",
      " 91             1                   2\n",
      " 92             1                   1\n",
      " 93             1                   2\n",
      " 94             1                   1\n",
      " 95             1                   1\n",
      " 96             1                   1\n",
      " 97             1                   1\n",
      " 98             1                   2\n",
      " 99             1                   2\n",
      "100             1                   2\n",
      "101             1                   1\n",
      "102             1                   2\n",
      "103             1                   1\n",
      "104             1                   1\n",
      "105             1                   2\n",
      "106             1                   4\n",
      "107             2                   2\n",
      "108             2                   1\n",
      "109             2                   4\n",
      "110             2                   1\n",
      "111             2                   2\n",
      "112             2                   3\n",
      "113             2                   4\n",
      "114             2                   1\n",
      "115             2                   2\n",
      "116             2                   1\n",
      "117             2                   2\n",
      "118             2                   3\n",
      "119             2                   2\n",
      "120             2                   4\n",
      "121             2                   3\n",
      "122             2                   2\n",
      "123             2                   2\n",
      "124             2                   1\n",
      "125             2                   2\n",
      "126             2                   1\n",
      "127             2                   2\n",
      "128             2                   2\n",
      "129             3                   3\n",
      "130             3                   3\n",
      "131             3                   3\n",
      "132             3                   3\n",
      "133             3                   3\n",
      "134             3                   3\n",
      "135             3                   3\n",
      "136             3                   3\n",
      "137             3                   3\n",
      "138             3                   3\n",
      "139             3                   3\n",
      "140             3                   3\n",
      "141             3                   3\n",
      "142             3                   3\n",
      "143             3                   3\n",
      "144             3                   3\n",
      "145             3                   3\n",
      "146             3                   3\n",
      "147             3                   3\n",
      "148             3                   3\n",
      "149             3                   3\n",
      "150             3                   3\n",
      "151             4                   4\n",
      "152             4                   4\n",
      "153             4                   4\n",
      "154             4                   4\n",
      "155             4                   4\n",
      "156             4                   4\n",
      "157             4                   4\n",
      "158             4                   4\n",
      "159             4                   4\n",
      "160             4                   4\n",
      "161             4                   4\n",
      "162             4                   4\n",
      "163             4                   4\n",
      "164             4                   4\n",
      "165             4                   4\n",
      "166             4                   4\n",
      "167             4                   4\n",
      "168             4                   4\n",
      "169             4                   4\n",
      "170             4                   4\n",
      "171             1                   2\n",
      "172             1                   2\n",
      "173             1                   2\n",
      "174             1                   1\n",
      "175             1                   4\n",
      "176             1                   1\n",
      "177             1                   1\n",
      "178             1                   1\n",
      "179             1                   1\n",
      "180             1                   1\n",
      "181             1                   1\n",
      "182             1                   3\n",
      "183             1                   1\n",
      "184             1                   1\n",
      "185             1                   1\n",
      "186             1                   1\n",
      "187             1                   2\n",
      "188             1                   1\n",
      "189             1                   1\n",
      "190             1                   1\n",
      "191             1                   1\n",
      "192             2                   2\n",
      "193             2                   2\n",
      "194             2                   2\n",
      "195             2                   2\n",
      "196             2                   2\n",
      "197             2                   2\n",
      "198             2                   1\n",
      "199             2                   1\n",
      "200             2                   3\n",
      "201             2                   4\n",
      "202             2                   2\n",
      "203             2                   2\n",
      "204             2                   1\n",
      "205             2                   4\n",
      "206             2                   2\n",
      "207             2                   1\n",
      "208             2                   2\n",
      "209             2                   2\n",
      "210             2                   2\n",
      "211             2                   4\n",
      "212             2                   2\n",
      "213             2                   2\n",
      "214             3                   3\n",
      "215             3                   4\n",
      "216             3                   3\n",
      "217             3                   3\n",
      "218             3                   3\n",
      "219             3                   3\n",
      "220             3                   3\n",
      "221             3                   3\n",
      "222             3                   3\n",
      "223             3                   3\n",
      "224             3                   3\n",
      "225             3                   3\n",
      "226             3                   3\n",
      "227             3                   3\n",
      "228             3                   3\n",
      "229             3                   3\n",
      "230             3                   3\n",
      "231             3                   3\n",
      "232             3                   3\n",
      "233             3                   3\n",
      "234             3                   3\n",
      "235             3                   3\n",
      "236             4                   4\n",
      "237             4                   4\n",
      "238             4                   4\n",
      "239             4                   4\n",
      "240             4                   4\n",
      "241             4                   4\n",
      "242             4                   4\n",
      "243             4                   4\n",
      "244             4                   4\n",
      "245             4                   4\n",
      "246             4                   4\n",
      "247             4                   4\n",
      "248             4                   4\n",
      "249             4                   4\n",
      "250             4                   4\n",
      "251             4                   4\n",
      "252             4                   4\n",
      "253             4                   4\n",
      "254             4                   4\n",
      "255             4                   4\n",
      "256             1                   1\n",
      "257             1                   2\n",
      "258             1                   2\n",
      "259             1                   1\n",
      "260             1                   2\n",
      "261             1                   1\n",
      "262             1                   1\n",
      "263             1                   2\n",
      "264             1                   1\n",
      "265             1                   1\n",
      "266             1                   3\n",
      "267             1                   1\n",
      "268             1                   2\n",
      "269             1                   2\n",
      "270             1                   2\n",
      "271             1                   2\n",
      "272             1                   3\n",
      "273             1                   2\n",
      "274             1                   1\n",
      "275             1                   1\n",
      "276             1                   2\n",
      "277             1                   4\n",
      "278             1                   1\n",
      "279             2                   1\n",
      "280             2                   2\n",
      "281             2                   3\n",
      "282             2                   2\n",
      "283             2                   4\n",
      "284             2                   2\n",
      "285             2                   2\n",
      "286             2                   2\n",
      "287             2                   3\n",
      "288             2                   1\n",
      "289             2                   1\n",
      "290             2                   2\n",
      "291             2                   1\n",
      "292             2                   4\n",
      "293             2                   2\n",
      "294             2                   1\n",
      "295             2                   2\n",
      "296             2                   2\n",
      "297             2                   2\n",
      "298             3                   3\n",
      "299             3                   3\n",
      "300             3                   3\n",
      "301             3                   3\n",
      "302             3                   3\n",
      "303             3                   3\n",
      "304             3                   3\n",
      "305             3                   3\n",
      "306             3                   3\n",
      "307             3                   3\n",
      "308             3                   3\n",
      "309             3                   3\n",
      "310             3                   3\n",
      "311             3                   3\n",
      "312             3                   3\n",
      "313             3                   3\n",
      "314             3                   3\n",
      "315             3                   3\n",
      "316             3                   3\n",
      "317             3                   3\n",
      "318             4                   4\n",
      "319             4                   4\n",
      "320             4                   4\n",
      "321             4                   3\n",
      "322             4                   4\n",
      "323             4                   4\n",
      "324             4                   4\n",
      "325             4                   4\n",
      "326             4                   4\n",
      "327             4                   4\n",
      "328             4                   4\n",
      "329             4                   4\n",
      "330             4                   4\n",
      "331             4                   4\n",
      "332             4                   4\n",
      "333             4                   4\n",
      "334             4                   4\n",
      "335             4                   4\n",
      "336             4                   4\n",
      "Predicted Class   1   2   3   4\n",
      "Actual Class                   \n",
      "1                48  30   4   4\n",
      "2                23  44  10   8\n",
      "3                 0   0  85   1\n",
      "4                 0   0   2  77\n",
      "Overall accuracy = 0.756\n",
      "ID  Actual class  LDA-bagging pred\n",
      "  1             1                 2\n",
      "  2             1                 1\n",
      "  3             1                 2\n",
      "  4             1                 4\n",
      "  5             1                 1\n",
      "  6             1                 1\n",
      "  7             1                 2\n",
      "  8             1                 1\n",
      "  9             1                 1\n",
      " 10             1                 2\n",
      " 11             1                 1\n",
      " 12             1                 1\n",
      " 13             1                 1\n",
      " 14             1                 2\n",
      " 15             1                 1\n",
      " 16             1                 1\n",
      " 17             1                 1\n",
      " 18             1                 3\n",
      " 19             1                 1\n",
      " 20             1                 1\n",
      " 21             1                 1\n",
      " 22             2                 2\n",
      " 23             2                 1\n",
      " 24             2                 2\n",
      " 25             2                 1\n",
      " 26             2                 3\n",
      " 27             2                 1\n",
      " 28             2                 2\n",
      " 29             2                 2\n",
      " 30             2                 2\n",
      " 31             2                 1\n",
      " 32             2                 2\n",
      " 33             2                 3\n",
      " 34             2                 2\n",
      " 35             2                 1\n",
      " 36             2                 1\n",
      " 37             2                 2\n",
      " 38             2                 2\n",
      " 39             2                 3\n",
      " 40             2                 1\n",
      " 41             2                 2\n",
      " 42             2                 2\n",
      " 43             2                 1\n",
      " 44             3                 3\n",
      " 45             3                 3\n",
      " 46             3                 3\n",
      " 47             3                 3\n",
      " 48             3                 3\n",
      " 49             3                 3\n",
      " 50             3                 3\n",
      " 51             3                 3\n",
      " 52             3                 3\n",
      " 53             3                 3\n",
      " 54             3                 3\n",
      " 55             3                 3\n",
      " 56             3                 3\n",
      " 57             3                 3\n",
      " 58             3                 3\n",
      " 59             3                 3\n",
      " 60             3                 3\n",
      " 61             3                 3\n",
      " 62             3                 3\n",
      " 63             3                 3\n",
      " 64             3                 3\n",
      " 65             3                 3\n",
      " 66             4                 4\n",
      " 67             4                 4\n",
      " 68             4                 4\n",
      " 69             4                 4\n",
      " 70             4                 4\n",
      " 71             4                 4\n",
      " 72             4                 4\n",
      " 73             4                 4\n",
      " 74             4                 3\n",
      " 75             4                 4\n",
      " 76             4                 4\n",
      " 77             4                 4\n",
      " 78             4                 4\n",
      " 79             4                 4\n",
      " 80             4                 4\n",
      " 81             4                 4\n",
      " 82             4                 4\n",
      " 83             4                 4\n",
      " 84             4                 4\n",
      " 85             4                 4\n",
      " 86             1                 2\n",
      " 87             1                 2\n",
      " 88             1                 1\n",
      " 89             1                 1\n",
      " 90             1                 1\n",
      " 91             1                 2\n",
      " 92             1                 1\n",
      " 93             1                 2\n",
      " 94             1                 1\n",
      " 95             1                 1\n",
      " 96             1                 1\n",
      " 97             1                 1\n",
      " 98             1                 2\n",
      " 99             1                 2\n",
      "100             1                 2\n",
      "101             1                 1\n",
      "102             1                 2\n",
      "103             1                 1\n",
      "104             1                 1\n",
      "105             1                 2\n",
      "106             1                 4\n",
      "107             2                 2\n",
      "108             2                 1\n",
      "109             2                 4\n",
      "110             2                 1\n",
      "111             2                 2\n",
      "112             2                 3\n",
      "113             2                 4\n",
      "114             2                 1\n",
      "115             2                 2\n",
      "116             2                 1\n",
      "117             2                 2\n",
      "118             2                 3\n",
      "119             2                 2\n",
      "120             2                 4\n",
      "121             2                 3\n",
      "122             2                 2\n",
      "123             2                 2\n",
      "124             2                 1\n",
      "125             2                 2\n",
      "126             2                 1\n",
      "127             2                 2\n",
      "128             2                 2\n",
      "129             3                 3\n",
      "130             3                 3\n",
      "131             3                 3\n",
      "132             3                 3\n",
      "133             3                 3\n",
      "134             3                 3\n",
      "135             3                 3\n",
      "136             3                 3\n",
      "137             3                 3\n",
      "138             3                 3\n",
      "139             3                 3\n",
      "140             3                 3\n",
      "141             3                 3\n",
      "142             3                 3\n",
      "143             3                 3\n",
      "144             3                 3\n",
      "145             3                 3\n",
      "146             3                 3\n",
      "147             3                 3\n",
      "148             3                 3\n",
      "149             3                 3\n",
      "150             3                 3\n",
      "151             4                 4\n",
      "152             4                 4\n",
      "153             4                 4\n",
      "154             4                 4\n",
      "155             4                 4\n",
      "156             4                 4\n",
      "157             4                 4\n",
      "158             4                 4\n",
      "159             4                 4\n",
      "160             4                 4\n",
      "161             4                 4\n",
      "162             4                 4\n",
      "163             4                 4\n",
      "164             4                 4\n",
      "165             4                 4\n",
      "166             4                 4\n",
      "167             4                 4\n",
      "168             4                 4\n",
      "169             4                 4\n",
      "170             4                 4\n",
      "171             1                 2\n",
      "172             1                 2\n",
      "173             1                 2\n",
      "174             1                 1\n",
      "175             1                 4\n",
      "176             1                 1\n",
      "177             1                 1\n",
      "178             1                 1\n",
      "179             1                 1\n",
      "180             1                 1\n",
      "181             1                 1\n",
      "182             1                 3\n",
      "183             1                 1\n",
      "184             1                 1\n",
      "185             1                 1\n",
      "186             1                 1\n",
      "187             1                 2\n",
      "188             1                 1\n",
      "189             1                 1\n",
      "190             1                 1\n",
      "191             1                 1\n",
      "192             2                 2\n",
      "193             2                 2\n",
      "194             2                 2\n",
      "195             2                 2\n",
      "196             2                 1\n",
      "197             2                 2\n",
      "198             2                 1\n",
      "199             2                 1\n",
      "200             2                 3\n",
      "201             2                 4\n",
      "202             2                 2\n",
      "203             2                 2\n",
      "204             2                 1\n",
      "205             2                 4\n",
      "206             2                 2\n",
      "207             2                 1\n",
      "208             2                 2\n",
      "209             2                 2\n",
      "210             2                 2\n",
      "211             2                 4\n",
      "212             2                 2\n",
      "213             2                 2\n",
      "214             3                 3\n",
      "215             3                 4\n",
      "216             3                 3\n",
      "217             3                 3\n",
      "218             3                 3\n",
      "219             3                 3\n",
      "220             3                 3\n",
      "221             3                 3\n",
      "222             3                 3\n",
      "223             3                 3\n",
      "224             3                 3\n",
      "225             3                 3\n",
      "226             3                 3\n",
      "227             3                 3\n",
      "228             3                 3\n",
      "229             3                 3\n",
      "230             3                 3\n",
      "231             3                 3\n",
      "232             3                 3\n",
      "233             3                 3\n",
      "234             3                 3\n",
      "235             3                 3\n",
      "236             4                 4\n",
      "237             4                 4\n",
      "238             4                 4\n",
      "239             4                 4\n",
      "240             4                 4\n",
      "241             4                 4\n",
      "242             4                 4\n",
      "243             4                 4\n",
      "244             4                 4\n",
      "245             4                 4\n",
      "246             4                 4\n",
      "247             4                 4\n",
      "248             4                 4\n",
      "249             4                 4\n",
      "250             4                 4\n",
      "251             4                 4\n",
      "252             4                 4\n",
      "253             4                 4\n",
      "254             4                 4\n",
      "255             4                 4\n",
      "256             1                 1\n",
      "257             1                 2\n",
      "258             1                 2\n",
      "259             1                 1\n",
      "260             1                 2\n",
      "261             1                 1\n",
      "262             1                 1\n",
      "263             1                 2\n",
      "264             1                 1\n",
      "265             1                 2\n",
      "266             1                 3\n",
      "267             1                 1\n",
      "268             1                 2\n",
      "269             1                 2\n",
      "270             1                 2\n",
      "271             1                 2\n",
      "272             1                 3\n",
      "273             1                 2\n",
      "274             1                 1\n",
      "275             1                 1\n",
      "276             1                 2\n",
      "277             1                 4\n",
      "278             1                 1\n",
      "279             2                 1\n",
      "280             2                 2\n",
      "281             2                 3\n",
      "282             2                 2\n",
      "283             2                 4\n",
      "284             2                 2\n",
      "285             2                 2\n",
      "286             2                 2\n",
      "287             2                 3\n",
      "288             2                 1\n",
      "289             2                 1\n",
      "290             2                 2\n",
      "291             2                 1\n",
      "292             2                 2\n",
      "293             2                 2\n",
      "294             2                 1\n",
      "295             2                 2\n",
      "296             2                 1\n",
      "297             2                 2\n",
      "298             3                 3\n",
      "299             3                 3\n",
      "300             3                 3\n",
      "301             3                 3\n",
      "302             3                 3\n",
      "303             3                 3\n",
      "304             3                 3\n",
      "305             3                 3\n",
      "306             3                 3\n",
      "307             3                 3\n",
      "308             3                 3\n",
      "309             3                 3\n",
      "310             3                 3\n",
      "311             3                 3\n",
      "312             3                 3\n",
      "313             3                 3\n",
      "314             3                 3\n",
      "315             3                 3\n",
      "316             3                 3\n",
      "317             3                 3\n",
      "318             4                 4\n",
      "319             4                 4\n",
      "320             4                 4\n",
      "321             4                 3\n",
      "322             4                 4\n",
      "323             4                 4\n",
      "324             4                 4\n",
      "325             4                 4\n",
      "326             4                 4\n",
      "327             4                 4\n",
      "328             4                 4\n",
      "329             4                 4\n",
      "330             4                 4\n",
      "331             4                 4\n",
      "332             4                 4\n",
      "333             4                 4\n",
      "334             4                 4\n",
      "335             4                 4\n",
      "336             4                 4\n",
      "Predicted Class   1   2   3   4\n",
      "Actual Class                   \n",
      "1                49  29   4   4\n",
      "2                25  44   9   7\n",
      "3                 0   0  85   1\n",
      "4                 0   0   2  77\n",
      "Overall accuracy = 0.759\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

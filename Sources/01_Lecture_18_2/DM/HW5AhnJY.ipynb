{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.linalg import *\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivelm():\n",
    "    #input term\n",
    "    infname=input(\"Enter the data file name: \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "    else:\n",
    "        return('You could select only 1 or 2')\n",
    "    \n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "    else:\n",
    "        return('You could select only 1 or 2')\n",
    " \n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "    \n",
    "    data=pd.read_csv(infname,sep=form,header=header)\n",
    "\n",
    "    #calculate term\n",
    "\n",
    "    y=data.iloc[:,col]\n",
    "    x=data.drop(col,1)\n",
    "    n=data.shape[0]\n",
    "    p=data.shape[1]\n",
    "    one=pd.DataFrame(np.ones(n))\n",
    "    x=pd.concat([one,x],axis=1)\n",
    "\n",
    "    bhat=inv(x.transpose().dot(x)).dot(x.transpose()).dot(y)\n",
    "    yhat= x.dot(bhat)\n",
    "\n",
    "    estout=pd.concat([y,yhat],axis=1)\n",
    "\n",
    "    j=np.ones((n,n))\n",
    "    sse=y.transpose().dot(y)-bhat.transpose().dot(x.transpose()).dot(y)\n",
    "    ssto=y.transpose().dot(y) - (1/n)*y.transpose().dot(j).dot(y)\n",
    "\n",
    "    mse = sse /(n-p)\n",
    "    rsquared= 1 - ((n-1)/(n-p))*(sse/ssto)\n",
    "    mseout=pd.DataFrame([mse,rsquared])\n",
    "    #output and naming term\n",
    "    \"\"\"\n",
    "    outputm=input('Select your output 1:bhat 2:fittedvalue 3:mse&r-squared')\n",
    "    if(outputm=='1'):\n",
    "        bhat=pd.DataFrame(bhat)\n",
    "        b=[]\n",
    "        for i in bhat.index:\n",
    "            b.append('Beta' + str(i))\n",
    "        b[0]='Constant'\n",
    "        bhat.index=b\n",
    "        bhat.columns=['Coefficients']\n",
    "        return(bhat)\n",
    "    elif(outputm=='2'):\n",
    "        estout.columns.name = 'ID'\n",
    "        estout.columns = ['Actual values','Fitted values']\n",
    "        return(estout)\n",
    "    elif(outputm=='3'):\n",
    "        mseout.index=['R-Squared = ','MSE = ']\n",
    "        mseout.columns=['Model Summary']\n",
    "        return(mseout)\n",
    "    else:\n",
    "        return('You could select only 1,2 or 3')\n",
    "    \"\"\"\n",
    "    bhat=pd.DataFrame(bhat)\n",
    "    b=[]\n",
    "    for i in bhat.index:\n",
    "        b.append('Beta' + str(i))\n",
    "    b[0]='Constant'\n",
    "    bhat.index=b\n",
    "    bhat.columns=['Coefficients']\n",
    "    estout.columns.name = 'ID'\n",
    "    estout.columns = ['Actual values','Fitted values']\n",
    "    mseout.index=['R-Squared = ','MSE = ']\n",
    "    mseout.columns=['Model Summary']\n",
    "    output = np.array([bhat,estout,mseout])\n",
    "    \n",
    "    fname=input('Select your output file name: ')\n",
    "    bhat.to_csv(fname, mode='w',sep=' ' ,header=False)\n",
    "    estout.to_csv(fname, mode='a', header=True)\n",
    "    mseout.to_csv(fname, mode='a',sep=' ', header=False)\n",
    "    return(output)\n",
    "    #print(bhat,'\\n', estout, '\\n',mseout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startlda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    #calculate term\n",
    "\n",
    "    Y=train.iloc[:,col]\n",
    "    X=train.drop(col,1)\n",
    "    n=train.shape[0]\n",
    "    p=X.shape[1]\n",
    "\n",
    "    testY=test.iloc[:,col]\n",
    "    testX=test.drop(col,1)\n",
    "    testn=test.shape[0]\n",
    "\n",
    "    g=list(set(Y))\n",
    "    k=len(g)\n",
    "\n",
    "    x=[]\n",
    "    testx=[]\n",
    "    for i in g:\n",
    "        x.append(train[train.iloc[:,col]==i].drop(col,1))\n",
    "    for i in g:\n",
    "        testx.append(test[test.iloc[:,col]==i].drop(col,1))\n",
    "\n",
    "    xbar=[]\n",
    "    for i in range(k):\n",
    "        xbar.append(x[i].mean(axis=0))\n",
    "\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(x[i].shape[0]/n)\n",
    "    S=[]\n",
    "    for i in range(k):\n",
    "        S.append(x[i].cov())\n",
    "    p=X.shape[1]\n",
    "    sigma = pd.DataFrame(np.zeros((p,p)))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (x[i].shape[0]-1)*S[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "\n",
    "    #pred function\n",
    "    def dk(vec):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(xbar[i].dot(inv(Sp)).dot(vec) -0.5 * (xbar[i].dot(inv(Sp)).dot(xbar[i].transpose())) + math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    ## resub output\n",
    "    yhat = []\n",
    "    for i in range(n):\n",
    "        yhat.append(pred(dk(X.iloc[i])))\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(n+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "    cont = pd.crosstab(predy.iloc[:,1],predy.iloc[:,2])\n",
    "    acc = sum(np.diag(cont))/n\n",
    "    #acc = pd.DataFrame(acc)\n",
    "    \n",
    "    ## test output\n",
    "    testyhat = []\n",
    "    for i in range(testn):\n",
    "        testyhat.append(pred(dk(testX.iloc[i])))\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(testn+1)),testY,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "    tcont = pd.crosstab(tpredy.iloc[:,1],tpredy.iloc[:,2])\n",
    "    tacc = sum(np.diag(tcont))/testn\n",
    "    #tacc=pd.DataFrame(tacc)\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startqda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        header='infer'\n",
    "    elif hd=='2':\n",
    "        header=None\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = pd.read_csv(trfname,sep=form,header=header)\n",
    "    test = pd.read_csv(tstfname,sep=form,header=header)\n",
    "    #calculate term\n",
    "\n",
    "    Y=train.iloc[:,col]\n",
    "    X=train.drop(col,1)\n",
    "    n=train.shape[0]\n",
    "    p=X.shape[1]\n",
    "\n",
    "    testY=test.iloc[:,col]\n",
    "    testX=test.drop(col,1)\n",
    "    testn=test.shape[0]\n",
    "\n",
    "    g=list(set(Y))\n",
    "    k=len(g)\n",
    "\n",
    "    x=[]\n",
    "    testx=[]\n",
    "    for i in g:\n",
    "        x.append(train[train.iloc[:,col]==i].drop(col,1))\n",
    "    for i in g:\n",
    "        testx.append(test[test.iloc[:,col]==i].drop(col,1))\n",
    "\n",
    "    xbar=[]\n",
    "    for i in range(k):\n",
    "        xbar.append(x[i].mean(axis=0))\n",
    "\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(x[i].shape[0]/n)\n",
    "    S=[]\n",
    "    for i in range(k):\n",
    "        S.append(x[i].cov())\n",
    "    p=X.shape[1]\n",
    "    sigma = pd.DataFrame(np.zeros((p,p)))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (x[i].shape[0]-1)*S[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "\n",
    "    #pred function\n",
    "    def dk(vec):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "            #out.append(xbar[i].dot(inv(Sp)).dot(vec) -0.5 * (xbar[i].dot(inv(Sp)).dot(xbar[i].transpose())) + math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    ## resub output\n",
    "    yhat = []\n",
    "    for i in range(n):\n",
    "        yhat.append(pred(dk(X.iloc[i])))\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(n+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "    cont = pd.crosstab(predy.iloc[:,1],predy.iloc[:,2])\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    ## test output\n",
    "    testyhat = []\n",
    "    for i in range(testn):\n",
    "        testyhat.append(pred(dk(testX.iloc[i])))\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(testn+1)),testY,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "    tcont = pd.crosstab(tpredy.iloc[:,1],tpredy.iloc[:,2])\n",
    "    tacc = sum(np.diag(tcont))/testn\n",
    "\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startrda():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        sh=1\n",
    "    elif hd=='2':\n",
    "        sh=0\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "\n",
    "    train = np.genfromtxt(trfname, delimiter=form, skip_header=sh)\n",
    "    test = np.genfromtxt(tstfname, delimiter=form, skip_header=sh)\n",
    "\n",
    "    #calculate term\n",
    "    X = np.delete(train, col, 1) # input variable\n",
    "    Y = train[:,col] # target variable\n",
    "\n",
    "    n = len(train) # number of obs\n",
    "    p = X.shape[1] # number of variables\n",
    "\n",
    "    testX = np.delete(test, col, 1) # input variable\n",
    "    testY = test[:,col] # target variable\n",
    "\n",
    "    g = np.array(list(set(Y))) # unique value of target variable\n",
    "    k = len(g) # number of unique values\n",
    "\n",
    "    #calculate mean of each variables by y values\n",
    "    tmp=[]\n",
    "    for i in g:\n",
    "        tmp.append(X[np.where(train[:,col]==i)])\n",
    "    xby = np.array(tmp)\n",
    "    xbar = np.array(list(map(lambda x : np.mean(x,axis=0),xby)))\n",
    "\n",
    "    #prior probability\n",
    "    pw=[]\n",
    "    for i in range(k):\n",
    "        pw.append(xby[i].shape[0]/n)\n",
    "    pw = np.array(pw)\n",
    "\n",
    "    #np.cov(xby[0].transpose())\n",
    "    S0 = np.array(list(map(lambda x : np.cov(x.transpose()) , xby)))\n",
    "\n",
    "    # ready for calculate covariance matrix\n",
    "    sigma =np.zeros((p,p))\n",
    "    for i in range(k):\n",
    "        sigma = sigma + (xby[i].shape[0]-1)*S0[i]\n",
    "    Sp=sigma*(1/(n-k))\n",
    "    \n",
    "    def dk(vec, S = S0):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "        return(out)\n",
    "    \n",
    "    def dk2(vec, S = S0):\n",
    "        out=[]\n",
    "        for i in range(k):\n",
    "            out.append(-0.5*(math.log(det(S[i])))-0.5*np.diag((vec-xbar[i]).dot(inv(S[i])).dot((vec-xbar[i]).transpose())) +math.log(pw[i]))\n",
    "        return(out)\n",
    "    def pred(vec):\n",
    "        out=pd.DataFrame(g).loc[pd.DataFrame([g,vec]).iloc[1]==max(pd.DataFrame([g,vec]).iloc[1])].iloc[0][0]\n",
    "        return(out)\n",
    "\n",
    "    tp = np.array(list(map(dk,X)))\n",
    "    yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    #ready for grid search\n",
    "    s2=np.diag(Sp).mean()\n",
    "\n",
    "    def getacc(Sk ,a,r):\n",
    "        Sar = a*Sk + (1 - a)*(r*Sp + (1 - r)*s2*np.identity(p))\n",
    "        tp2 = np.array(dk2(testX,Sar)).reshape(k,len(testX)).transpose()\n",
    "        yhatg = np.argmax(tp2,axis =1)\n",
    "        contg = pd.crosstab(testY,yhatg)\n",
    "        acc2 = sum(np.diag(contg))/len(test)\n",
    "        return(acc2)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    gridseed=21\n",
    "    for i in range(gridseed):\n",
    "        df=df.append(pd.DataFrame(np.zeros(gridseed)).transpose())\n",
    "    alpha = gamma = list(map(lambda x : x/(gridseed-1) , list(range(gridseed))))\n",
    "    df.columns=alpha\n",
    "    df.index=gamma\n",
    "    for a ,i in zip(alpha , range(gridseed)):\n",
    "        for r, j in zip(gamma, range(gridseed)) :\n",
    "            df.iloc[i,j]= getacc(S0,a,r)\n",
    "    #get the optimized value of alpha & gamma (alpha = 0.53, beta = 1)\n",
    "    argm=df.stack().index[np.argmax(df.values)]\n",
    "    a = argm[0]\n",
    "    r = argm[1]\n",
    "    Snew = a*S0 + (1 - a)*(r*Sp + (1 - r)*s2*np.identity(p))\n",
    "\n",
    "    #resub output\n",
    "    tp = np.array(list(map(lambda x : dk(x,Snew),X)))\n",
    "    yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "\n",
    "    #test output\n",
    "    ttp = np.array(list(map(lambda x : dk(x,Snew),testX)))\n",
    "    tyhat = np.argmax(ttp,axis =1)\n",
    "    tcont = pd.crosstab(testY,tyhat)\n",
    "    tacc = sum(np.diag(tcont))/len(test)\n",
    "\n",
    "\n",
    "    predy = pd.DataFrame([range(1,(len(train)+1)),Y,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred']\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(len(test)+1)),testY,tyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred']\n",
    "\n",
    "    cont.columns = g\n",
    "    cont.index = g\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "\n",
    "    tcont.columns = g\n",
    "    tcont.index = g\n",
    "    tcont.columns.name = 'Prediction Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    #plotting\n",
    "    x = df.columns\n",
    "    y = df.index\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = df\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    plt.show()\n",
    "    \n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startlogi():\n",
    "    #input term\n",
    "    trfname=input(\"Write your train data file name : \")\n",
    "    tstfname=input(\"Write your test data file name : \")\n",
    "    sep=input(\"Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): \")\n",
    "    if sep=='1':\n",
    "        form=' '\n",
    "    elif sep=='2':\n",
    "        form=','\n",
    "\n",
    "\n",
    "    hd=input(\"Select the data header format(1 = with header or 2 = no header): \")\n",
    "    if hd=='1':\n",
    "        sh=1\n",
    "    elif hd=='2':\n",
    "        sh=0\n",
    "\n",
    "\n",
    "    cl=input(\"Select column# where your y vlaues exist: \")\n",
    "    col = int(cl)-1\n",
    "    coff=input(\"Select your cutoff value: \")    \n",
    "    cutoff = float(coff)\n",
    "    \n",
    "    train = np.genfromtxt(trfname, delimiter=form, skip_header=sh)\n",
    "    test = np.genfromtxt(tstfname, delimiter=form, skip_header=sh)\n",
    "\n",
    "    #calculate term\n",
    "    X = np.delete(train, col, 1) # input variable\n",
    "    Y = train[:,col] # target variable\n",
    "\n",
    "    n = len(train) # number of obs\n",
    "    p = X.shape[1] # number of variables\n",
    "\n",
    "    testX = np.delete(test, col, 1) # input variable\n",
    "    testY = test[:,col] # target variable\n",
    "    testn = len(test)\n",
    "\n",
    "    g = np.array(list(set(Y))) # unique value of target variable\n",
    "    k = len(g) # number of unique values\n",
    "\n",
    "    tmp = np.zeros((X.shape[0],X.shape[1]+1))\n",
    "    tmp[:,0]= np.ones(n)\n",
    "    tmp[:,1:] = X\n",
    "    Xj= tmp\n",
    "    beta = np.ones(p+1)/10\n",
    "    Yb = np.array(list(map(int,Y==g[1])))\n",
    "\n",
    "    testmp = np.zeros((testX.shape[0],testX.shape[1]+1))\n",
    "    testmp[:,0]= np.ones(testn)\n",
    "    testmp[:,1:] = testX\n",
    "    testXj = testmp\n",
    "    testYb = np.array(list(map(int,testY==g[1])))\n",
    "\n",
    "    def loglike(beta):\n",
    "        a=-Yb.T.dot(Xj).dot(beta)+sum(np.log(1+np.exp(Xj.dot(beta))))\n",
    "        return a\n",
    "    opt = minimize(loglike , beta )\n",
    "    betahat = opt.x\n",
    "\n",
    "    def gety(x):\n",
    "        if x>=cutoff:\n",
    "            return g[1]\n",
    "        elif x<cutoff:\n",
    "            return g[0]\n",
    "\n",
    "    yhat = np.exp(Xj.dot(betahat))/(1+np.exp(Xj.dot(betahat)))\n",
    "    Yhat = np.array(list(map(gety,yhat)))\n",
    "\n",
    "    testyhat = np.exp(testXj.dot(betahat))/(1+np.exp(testXj.dot(betahat)))\n",
    "    testYhat = np.array(list(map(gety,testyhat))) \n",
    "\n",
    "    #resub output\n",
    "    #tp = np.array(list(map(lambda x : dk(x,Snew),X)))\n",
    "    #yhat = np.argmax(tp,axis =1)\n",
    "    cont = pd.crosstab(Y,Yhat)\n",
    "    acc = sum(np.diag(cont))/n\n",
    "    spe = cont.iloc[0,0]/sum(cont.iloc[0,:])\n",
    "    sens = cont.iloc[1,1]/sum(cont.iloc[1,:])\n",
    "    \n",
    "    #test output\n",
    "    #ttp = np.array(list(map(lambda x : dk(x,Snew),testX)))\n",
    "    #tyhat = np.argmax(ttp,axis =1)\n",
    "    tcont = pd.crosstab(testY,testYhat)\n",
    "    tacc = sum(np.diag(tcont))/len(test)\n",
    "    tspe = tcont.iloc[0,0]/sum(tcont.iloc[0,:])\n",
    "    tsens = tcont.iloc[1,1]/sum(tcont.iloc[1,:])\n",
    "    \n",
    "\n",
    "    predy = pd.DataFrame([range(1,(len(train)+1)),Y,Yhat,yhat]).transpose()\n",
    "    predy.columns=['ID','Actual class','Resub pred','Pred Prob']\n",
    "\n",
    "    tpredy = pd.DataFrame([range(1,(len(test)+1)),testY,testYhat,testyhat]).transpose()\n",
    "    tpredy.columns=['ID','Actual class','Test pred','Pred Prob']\n",
    "\n",
    "    cont.columns = g\n",
    "    cont.index = g\n",
    "    cont.columns.name = 'Resub Class'\n",
    "    cont.index.name = 'Actual Class'\n",
    "\n",
    "    tcont.columns = g\n",
    "    tcont.index = g\n",
    "    tcont.columns.name = 'Prediction Class'\n",
    "    tcont.index.name = 'Actual Class'\n",
    "\n",
    "    fname = input('Write your output file name : ')\n",
    "    \n",
    "    #console output\n",
    "    print(predy.to_string(index=False))\n",
    "    print(cont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(acc))\n",
    "    print(\"Sensitivity = %0.3f\" %(sens))\n",
    "    print(\"Specificity = %0.3f\" %(spe))\n",
    "\n",
    "    print(tpredy.to_string(index=False))\n",
    "    print(tcont)\n",
    "    print(\"Overall accuracy = %0.3f\" %(tacc))\n",
    "    print(\"Sensitivity = %0.3f\" %(tsens))\n",
    "    print(\"Specificity = %0.3f\" %(tspe))\n",
    "    \n",
    "    #file output\n",
    "    out = open(fname, 'w')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(predy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Resubstitution)\",file=out)\n",
    "        print(cont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Resubstitution)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(acc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(sens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(spe),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(tpredy.to_string(index=False),file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Confusion Matrix (Test)\",file=out)\n",
    "        print(tcont,file=out)\n",
    "        print(\"\",file=out)\n",
    "        print(\"Model Summary (Test)\",file=out)\n",
    "        print(\"Overall accuracy = %0.3f\" %(tacc),file=out)\n",
    "        print(\"Sensitivity = %0.3f\" %(tsens),file=out)\n",
    "        print(\"Specificity = %0.3f\" %(tspe),file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startclf():\n",
    "    inp = input('Select Classification model 1 = LDA , 2 = QDA, 3 = RDA, 4 = logistic regression : ')\n",
    "    if inp=='1':\n",
    "        return(startlda())\n",
    "    elif inp=='2':\n",
    "        return(startqda())\n",
    "    elif inp=='3':\n",
    "        return(startrda())\n",
    "    elif inp=='4':\n",
    "        return(startlogi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    inp = input('Select model 1 = Linear regression , 2 = Classification : ')\n",
    "    if inp=='1':\n",
    "        return(naivelm())\n",
    "    if inp=='2':\n",
    "        return(startclf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select model 1 = Linear regression , 2 = Classification : 2\n",
      "Select Classification model 1 = LDA , 2 = QDA, 3 = RDA, 4 = logistic regression : 4\n",
      "Write your train data file name : pid.dat\n",
      "Write your test data file name : pidtest.dat\n",
      "Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): 2\n",
      "Select the data header format(1 = with header or 2 = no header): 2\n",
      "Select column# where your y vlaues exist: 8\n",
      "Select your cutoff value: 0.5\n",
      "Write your output file name : hw5\n",
      "ID  Actual class  Resub pred  Pred Prob\n",
      "  1.0           2.0         2.0   0.968038\n",
      "  2.0           2.0         2.0   0.889140\n",
      "  3.0           2.0         2.0   0.957327\n",
      "  4.0           2.0         2.0   0.804815\n",
      "  5.0           2.0         2.0   0.785658\n",
      "  6.0           2.0         2.0   0.746511\n",
      "  7.0           2.0         2.0   0.799528\n",
      "  8.0           2.0         2.0   0.917842\n",
      "  9.0           2.0         2.0   0.901733\n",
      " 10.0           2.0         2.0   0.729017\n",
      " 11.0           2.0         2.0   0.895320\n",
      " 12.0           2.0         2.0   0.959835\n",
      " 13.0           2.0         2.0   0.920145\n",
      " 14.0           2.0         2.0   0.682944\n",
      " 15.0           2.0         2.0   0.867859\n",
      " 16.0           2.0         2.0   0.789410\n",
      " 17.0           2.0         2.0   0.915553\n",
      " 18.0           2.0         1.0   0.080492\n",
      " 19.0           2.0         2.0   0.953544\n",
      " 20.0           2.0         2.0   0.798270\n",
      " 21.0           2.0         2.0   0.954864\n",
      " 22.0           2.0         2.0   0.959827\n",
      " 23.0           2.0         1.0   0.387309\n",
      " 24.0           2.0         2.0   0.992916\n",
      " 25.0           2.0         2.0   0.921015\n",
      " 26.0           2.0         2.0   0.892879\n",
      " 27.0           2.0         2.0   0.745949\n",
      " 28.0           2.0         2.0   0.853548\n",
      " 29.0           2.0         2.0   0.624197\n",
      " 30.0           2.0         2.0   0.669860\n",
      " 31.0           2.0         2.0   0.924772\n",
      " 32.0           2.0         2.0   0.830616\n",
      " 33.0           2.0         2.0   0.950300\n",
      " 34.0           2.0         1.0   0.422706\n",
      " 35.0           2.0         2.0   0.821226\n",
      " 36.0           2.0         2.0   0.744209\n",
      " 37.0           1.0         1.0   0.177739\n",
      " 38.0           1.0         2.0   0.700347\n",
      " 39.0           1.0         2.0   0.743736\n",
      " 40.0           1.0         1.0   0.215616\n",
      " 41.0           1.0         1.0   0.313432\n",
      " 42.0           1.0         2.0   0.691972\n",
      " 43.0           1.0         1.0   0.464659\n",
      " 44.0           1.0         2.0   0.677704\n",
      " 45.0           1.0         2.0   0.760605\n",
      " 46.0           1.0         1.0   0.213091\n",
      " 47.0           1.0         2.0   0.732776\n",
      " 48.0           1.0         2.0   0.619208\n",
      " 49.0           1.0         1.0   0.376068\n",
      " 50.0           1.0         1.0   0.291081\n",
      " 51.0           1.0         2.0   0.508486\n",
      " 52.0           1.0         2.0   0.926406\n",
      " 53.0           1.0         2.0   0.844653\n",
      " 54.0           1.0         1.0   0.241098\n",
      " 55.0           2.0         2.0   0.992787\n",
      " 56.0           2.0         2.0   0.710004\n",
      " 57.0           2.0         2.0   0.949765\n",
      " 58.0           2.0         2.0   0.788440\n",
      " 59.0           2.0         2.0   0.759697\n",
      " 60.0           2.0         2.0   0.729152\n",
      " 61.0           2.0         2.0   0.690746\n",
      " 62.0           2.0         2.0   0.956501\n",
      " 63.0           2.0         2.0   0.888067\n",
      " 64.0           2.0         2.0   0.901945\n",
      " 65.0           2.0         1.0   0.352552\n",
      " 66.0           2.0         2.0   0.981070\n",
      " 67.0           2.0         2.0   0.879011\n",
      " 68.0           2.0         2.0   0.927406\n",
      " 69.0           2.0         2.0   0.626324\n",
      " 70.0           2.0         2.0   0.926761\n",
      " 71.0           2.0         2.0   0.954796\n",
      " 72.0           2.0         2.0   0.949002\n",
      " 73.0           2.0         2.0   0.953573\n",
      " 74.0           2.0         2.0   0.979364\n",
      " 75.0           2.0         2.0   0.948658\n",
      " 76.0           2.0         2.0   0.792834\n",
      " 77.0           2.0         1.0   0.264602\n",
      " 78.0           2.0         2.0   0.980149\n",
      " 79.0           2.0         1.0   0.401561\n",
      " 80.0           2.0         2.0   0.823249\n",
      " 81.0           2.0         2.0   0.914755\n",
      " 82.0           2.0         2.0   0.907491\n",
      " 83.0           2.0         2.0   0.984648\n",
      " 84.0           2.0         2.0   0.604756\n",
      " 85.0           2.0         2.0   0.910886\n",
      " 86.0           2.0         2.0   0.940967\n",
      " 87.0           2.0         1.0   0.321760\n",
      " 88.0           2.0         2.0   0.779678\n",
      " 89.0           2.0         1.0   0.443377\n",
      " 90.0           2.0         2.0   0.921339\n",
      " 91.0           1.0         1.0   0.083275\n",
      " 92.0           1.0         2.0   0.767701\n",
      " 93.0           1.0         1.0   0.124026\n",
      " 94.0           1.0         2.0   0.858275\n",
      " 95.0           1.0         2.0   0.788878\n",
      " 96.0           1.0         1.0   0.035961\n",
      " 97.0           1.0         1.0   0.285508\n",
      " 98.0           1.0         1.0   0.469785\n",
      " 99.0           1.0         2.0   0.579586\n",
      "100.0           1.0         1.0   0.003025\n",
      "101.0           1.0         1.0   0.157765\n",
      "102.0           1.0         1.0   0.191703\n",
      "103.0           1.0         1.0   0.112343\n",
      "104.0           1.0         1.0   0.052030\n",
      "105.0           1.0         2.0   0.882944\n",
      "106.0           1.0         2.0   0.713690\n",
      "107.0           1.0         1.0   0.242914\n",
      "108.0           1.0         1.0   0.038657\n",
      "109.0           2.0         2.0   0.976034\n",
      "110.0           2.0         2.0   0.909473\n",
      "111.0           2.0         2.0   0.951277\n",
      "112.0           2.0         2.0   0.856022\n",
      "113.0           2.0         2.0   0.811888\n",
      "114.0           2.0         2.0   0.881974\n",
      "115.0           2.0         2.0   0.951874\n",
      "116.0           2.0         2.0   0.846964\n",
      "117.0           2.0         2.0   0.969297\n",
      "118.0           2.0         2.0   0.977465\n",
      "119.0           2.0         2.0   0.958394\n",
      "120.0           2.0         2.0   0.675899\n",
      "121.0           2.0         2.0   0.960970\n",
      "122.0           2.0         2.0   0.928439\n",
      "123.0           2.0         1.0   0.497373\n",
      "124.0           2.0         2.0   0.963196\n",
      "125.0           2.0         2.0   0.990659\n",
      "126.0           2.0         1.0   0.398827\n",
      "127.0           2.0         2.0   0.963691\n",
      "128.0           2.0         1.0   0.384743\n",
      "129.0           2.0         2.0   0.976279\n",
      "130.0           2.0         2.0   0.887265\n",
      "131.0           2.0         2.0   0.926124\n",
      "132.0           2.0         2.0   0.909070\n",
      "133.0           2.0         2.0   0.809355\n",
      "134.0           2.0         2.0   0.972185\n",
      "135.0           2.0         1.0   0.353701\n",
      "136.0           2.0         2.0   0.981151\n",
      "137.0           2.0         2.0   0.854272\n",
      "138.0           2.0         2.0   0.962194\n",
      "139.0           2.0         2.0   0.955663\n",
      "140.0           2.0         2.0   0.769950\n",
      "141.0           2.0         2.0   0.823711\n",
      "142.0           2.0         2.0   0.879677\n",
      "143.0           2.0         2.0   0.570647\n",
      "144.0           2.0         2.0   0.936307\n",
      "145.0           1.0         2.0   0.644477\n",
      "146.0           1.0         1.0   0.251549\n",
      "147.0           1.0         1.0   0.339107\n",
      "148.0           1.0         2.0   0.866365\n",
      "149.0           1.0         1.0   0.418103\n",
      "150.0           1.0         1.0   0.390301\n",
      "151.0           1.0         1.0   0.182259\n",
      "152.0           1.0         2.0   0.563363\n",
      "153.0           1.0         1.0   0.018823\n",
      "154.0           1.0         2.0   0.768105\n",
      "155.0           1.0         2.0   0.880194\n",
      "156.0           1.0         2.0   0.748175\n",
      "157.0           1.0         2.0   0.856193\n",
      "158.0           1.0         1.0   0.301678\n",
      "159.0           1.0         1.0   0.037173\n",
      "160.0           1.0         2.0   0.697366\n",
      "161.0           1.0         1.0   0.140833\n",
      "162.0           1.0         1.0   0.396040\n",
      "163.0           2.0         2.0   0.856228\n",
      "164.0           2.0         2.0   0.894808\n",
      "165.0           2.0         2.0   0.948204\n",
      "166.0           2.0         2.0   0.695045\n",
      "167.0           2.0         2.0   0.976853\n",
      "168.0           2.0         2.0   0.900007\n",
      "169.0           2.0         2.0   0.759938\n",
      "170.0           2.0         2.0   0.888035\n",
      "171.0           2.0         2.0   0.991352\n",
      "172.0           2.0         2.0   0.961555\n",
      "173.0           2.0         2.0   0.925332\n",
      "174.0           2.0         2.0   0.876334\n",
      "175.0           2.0         2.0   0.885806\n",
      "176.0           2.0         2.0   0.835092\n",
      "177.0           2.0         2.0   0.908990\n",
      "178.0           2.0         2.0   0.850448\n",
      "179.0           2.0         2.0   0.882486\n",
      "180.0           2.0         2.0   0.645377\n",
      "181.0           2.0         1.0   0.004707\n",
      "182.0           2.0         2.0   0.895957\n",
      "183.0           2.0         2.0   0.654141\n",
      "184.0           2.0         2.0   0.944443\n",
      "185.0           2.0         2.0   0.729385\n",
      "186.0           2.0         2.0   0.867177\n",
      "187.0           2.0         2.0   0.975545\n",
      "188.0           2.0         2.0   0.983801\n",
      "189.0           2.0         2.0   0.973060\n",
      "190.0           2.0         2.0   0.659605\n",
      "191.0           2.0         2.0   0.864778\n",
      "192.0           2.0         2.0   0.872022\n",
      "193.0           2.0         2.0   0.965326\n",
      "194.0           2.0         2.0   0.885170\n",
      "195.0           2.0         2.0   0.896161\n",
      "196.0           2.0         2.0   0.987554\n",
      "197.0           2.0         2.0   0.902560\n",
      "198.0           2.0         2.0   0.782609\n",
      "199.0           1.0         1.0   0.274507\n",
      "200.0           1.0         2.0   0.802640\n",
      "201.0           1.0         1.0   0.092377\n",
      "202.0           1.0         2.0   0.754011\n",
      "203.0           1.0         1.0   0.336524\n",
      "204.0           1.0         1.0   0.166066\n",
      "205.0           1.0         2.0   0.615365\n",
      "206.0           1.0         1.0   0.077231\n",
      "207.0           1.0         2.0   0.507000\n",
      "208.0           1.0         2.0   0.876292\n",
      "209.0           1.0         2.0   0.737734\n",
      "210.0           1.0         1.0   0.031165\n",
      "211.0           1.0         1.0   0.049860\n",
      "212.0           1.0         1.0   0.064231\n",
      "213.0           1.0         1.0   0.171336\n",
      "214.0           1.0         1.0   0.412762\n",
      "215.0           1.0         2.0   0.512876\n",
      "216.0           1.0         1.0   0.056547\n",
      "217.0           2.0         2.0   0.986419\n",
      "218.0           2.0         2.0   0.530882\n",
      "219.0           2.0         2.0   0.978032\n",
      "220.0           2.0         2.0   0.979956\n",
      "221.0           2.0         2.0   0.968650\n",
      "222.0           2.0         2.0   0.747405\n",
      "223.0           2.0         2.0   0.965599\n",
      "224.0           2.0         2.0   0.882359\n",
      "225.0           2.0         2.0   0.620441\n",
      "226.0           2.0         2.0   0.974184\n",
      "227.0           2.0         2.0   0.980425\n",
      "228.0           2.0         1.0   0.258436\n",
      "229.0           2.0         2.0   0.950874\n",
      "230.0           2.0         2.0   0.905622\n",
      "231.0           2.0         2.0   0.874359\n",
      "232.0           2.0         2.0   0.938827\n",
      "233.0           2.0         2.0   0.943744\n",
      "234.0           2.0         2.0   0.923589\n",
      "235.0           2.0         2.0   0.975519\n",
      "236.0           2.0         2.0   0.886318\n",
      "237.0           2.0         2.0   0.985789\n",
      "238.0           2.0         2.0   0.594703\n",
      "239.0           2.0         2.0   0.878929\n",
      "240.0           2.0         2.0   0.784382\n",
      "241.0           2.0         2.0   0.964422\n",
      "242.0           2.0         2.0   0.557100\n",
      "243.0           2.0         2.0   0.552138\n",
      "244.0           2.0         2.0   0.960631\n",
      "245.0           2.0         2.0   0.951431\n",
      "246.0           2.0         2.0   0.678759\n",
      "247.0           2.0         2.0   0.727104\n",
      "248.0           2.0         2.0   0.994214\n",
      "249.0           2.0         2.0   0.910998\n",
      "250.0           2.0         2.0   0.979613\n",
      "251.0           2.0         2.0   0.937517\n",
      "252.0           2.0         2.0   0.500503\n",
      "Resub Class   1.0  2.0\n",
      "Actual Class          \n",
      "1.0            41   31\n",
      "2.0            14  166\n",
      "Overall accuracy = 0.821\n",
      "Sensitivity = 0.922\n",
      "Specificity = 0.569\n",
      "ID  Actual class  Test pred  Pred Prob\n",
      "  1.0           1.0        2.0   0.638693\n",
      "  2.0           1.0        1.0   0.082464\n",
      "  3.0           1.0        1.0   0.071534\n",
      "  4.0           1.0        1.0   0.237849\n",
      "  5.0           1.0        2.0   0.506794\n",
      "  6.0           1.0        2.0   0.967502\n",
      "  7.0           1.0        2.0   0.822743\n",
      "  8.0           1.0        2.0   0.669031\n",
      "  9.0           1.0        1.0   0.031254\n",
      " 10.0           1.0        2.0   0.890594\n",
      " 11.0           1.0        1.0   0.158529\n",
      " 12.0           1.0        2.0   0.618532\n",
      " 13.0           1.0        1.0   0.455035\n",
      " 14.0           1.0        1.0   0.141648\n",
      " 15.0           1.0        2.0   0.636793\n",
      " 16.0           1.0        2.0   0.862714\n",
      " 17.0           1.0        2.0   0.727543\n",
      " 18.0           1.0        2.0   0.939875\n",
      " 19.0           2.0        1.0   0.348999\n",
      " 20.0           2.0        2.0   0.949547\n",
      " 21.0           2.0        2.0   0.979652\n",
      " 22.0           2.0        1.0   0.471804\n",
      " 23.0           2.0        2.0   0.530534\n",
      " 24.0           2.0        2.0   0.954204\n",
      " 25.0           2.0        2.0   0.948740\n",
      " 26.0           2.0        2.0   0.938734\n",
      " 27.0           2.0        2.0   0.812538\n",
      " 28.0           2.0        2.0   0.631762\n",
      " 29.0           2.0        2.0   0.907264\n",
      " 30.0           2.0        2.0   0.838605\n",
      " 31.0           2.0        2.0   0.843921\n",
      " 32.0           2.0        1.0   0.285199\n",
      " 33.0           2.0        2.0   0.978235\n",
      " 34.0           2.0        2.0   0.932804\n",
      " 35.0           2.0        2.0   0.612502\n",
      " 36.0           2.0        2.0   0.826292\n",
      " 37.0           2.0        2.0   0.968694\n",
      " 38.0           2.0        2.0   0.790039\n",
      " 39.0           2.0        2.0   0.949347\n",
      " 40.0           2.0        2.0   0.952095\n",
      " 41.0           2.0        1.0   0.303900\n",
      " 42.0           2.0        2.0   0.979872\n",
      " 43.0           2.0        1.0   0.281517\n",
      " 44.0           2.0        2.0   0.966628\n",
      " 45.0           2.0        2.0   0.955034\n",
      " 46.0           2.0        2.0   0.750218\n",
      " 47.0           2.0        2.0   0.723287\n",
      " 48.0           2.0        2.0   0.534931\n",
      " 49.0           2.0        2.0   0.547352\n",
      " 50.0           2.0        2.0   0.713200\n",
      " 51.0           2.0        2.0   0.942610\n",
      " 52.0           2.0        2.0   0.864003\n",
      " 53.0           2.0        2.0   0.957780\n",
      " 54.0           2.0        2.0   0.988802\n",
      " 55.0           1.0        1.0   0.418514\n",
      " 56.0           1.0        2.0   0.744256\n",
      " 57.0           1.0        2.0   0.623750\n",
      " 58.0           1.0        2.0   0.726627\n",
      " 59.0           1.0        2.0   0.594357\n",
      " 60.0           1.0        2.0   0.778804\n",
      " 61.0           1.0        1.0   0.187044\n",
      " 62.0           1.0        1.0   0.181867\n",
      " 63.0           1.0        1.0   0.053386\n",
      " 64.0           1.0        1.0   0.392503\n",
      " 65.0           1.0        1.0   0.170921\n",
      " 66.0           1.0        1.0   0.406001\n",
      " 67.0           1.0        2.0   0.625059\n",
      " 68.0           1.0        2.0   0.660248\n",
      " 69.0           1.0        2.0   0.860335\n",
      " 70.0           1.0        1.0   0.053495\n",
      " 71.0           1.0        2.0   0.552978\n",
      " 72.0           1.0        1.0   0.300104\n",
      " 73.0           2.0        2.0   0.984774\n",
      " 74.0           2.0        2.0   0.952703\n",
      " 75.0           2.0        2.0   0.950947\n",
      " 76.0           2.0        2.0   0.700042\n",
      " 77.0           2.0        2.0   0.926016\n",
      " 78.0           2.0        2.0   0.811701\n",
      " 79.0           2.0        2.0   0.754549\n",
      " 80.0           2.0        2.0   0.922977\n",
      " 81.0           2.0        2.0   0.813186\n",
      " 82.0           2.0        2.0   0.910753\n",
      " 83.0           2.0        2.0   0.970212\n",
      " 84.0           2.0        2.0   0.992923\n",
      " 85.0           2.0        2.0   0.539994\n",
      " 86.0           2.0        1.0   0.025580\n",
      " 87.0           2.0        1.0   0.179258\n",
      " 88.0           2.0        2.0   0.764202\n",
      " 89.0           2.0        2.0   0.922751\n",
      " 90.0           2.0        2.0   0.981624\n",
      " 91.0           2.0        2.0   0.903095\n",
      " 92.0           2.0        2.0   0.796056\n",
      " 93.0           2.0        2.0   0.609535\n",
      " 94.0           2.0        2.0   0.956762\n",
      " 95.0           2.0        2.0   0.979671\n",
      " 96.0           2.0        2.0   0.970878\n",
      " 97.0           2.0        1.0   0.339828\n",
      " 98.0           2.0        2.0   0.793407\n",
      " 99.0           2.0        2.0   0.956889\n",
      "100.0           2.0        2.0   0.947239\n",
      "101.0           2.0        2.0   0.914275\n",
      "102.0           2.0        2.0   0.825698\n",
      "103.0           2.0        2.0   0.966119\n",
      "104.0           2.0        2.0   0.952588\n",
      "105.0           2.0        1.0   0.478314\n",
      "106.0           2.0        2.0   0.976456\n",
      "107.0           2.0        2.0   0.980048\n",
      "108.0           2.0        2.0   0.911862\n",
      "109.0           1.0        1.0   0.054904\n",
      "110.0           1.0        1.0   0.368367\n",
      "111.0           1.0        1.0   0.232205\n",
      "112.0           1.0        1.0   0.296094\n",
      "113.0           1.0        2.0   0.968975\n",
      "114.0           1.0        1.0   0.145606\n",
      "115.0           1.0        2.0   0.689147\n",
      "116.0           1.0        2.0   0.570765\n",
      "117.0           1.0        1.0   0.397901\n",
      "118.0           1.0        1.0   0.291039\n",
      "119.0           1.0        1.0   0.010968\n",
      "120.0           1.0        2.0   0.623014\n",
      "121.0           1.0        1.0   0.124322\n",
      "122.0           1.0        1.0   0.200270\n",
      "123.0           1.0        1.0   0.109997\n",
      "124.0           1.0        2.0   0.593280\n",
      "125.0           1.0        1.0   0.203006\n",
      "126.0           1.0        1.0   0.286307\n",
      "127.0           2.0        2.0   0.785071\n",
      "128.0           2.0        2.0   0.906090\n",
      "129.0           2.0        2.0   0.503930\n",
      "130.0           2.0        2.0   0.946691\n",
      "131.0           2.0        2.0   0.897386\n",
      "132.0           2.0        2.0   0.982740\n",
      "133.0           2.0        2.0   0.934460\n",
      "134.0           2.0        2.0   0.614178\n",
      "135.0           2.0        2.0   0.974844\n",
      "136.0           2.0        2.0   0.882399\n",
      "137.0           2.0        2.0   0.908285\n",
      "138.0           2.0        2.0   0.744388\n",
      "139.0           2.0        2.0   0.938094\n",
      "140.0           2.0        2.0   0.606312\n",
      "141.0           2.0        1.0   0.454140\n",
      "142.0           2.0        2.0   0.866825\n",
      "143.0           2.0        2.0   0.839578\n",
      "144.0           2.0        2.0   0.958706\n",
      "145.0           2.0        2.0   0.878620\n",
      "146.0           2.0        2.0   0.882809\n",
      "147.0           2.0        2.0   0.967232\n",
      "148.0           2.0        2.0   0.973515\n",
      "149.0           2.0        2.0   0.986019\n",
      "150.0           2.0        2.0   0.902245\n",
      "151.0           2.0        2.0   0.915153\n",
      "152.0           2.0        2.0   0.982064\n",
      "153.0           2.0        2.0   0.796635\n",
      "154.0           2.0        2.0   0.979390\n",
      "155.0           2.0        2.0   0.940991\n",
      "156.0           2.0        2.0   0.981926\n",
      "157.0           2.0        1.0   0.200275\n",
      "158.0           2.0        2.0   0.929499\n",
      "159.0           2.0        2.0   0.937592\n",
      "160.0           2.0        2.0   0.664865\n",
      "161.0           2.0        2.0   0.890133\n",
      "162.0           2.0        2.0   0.943898\n",
      "163.0           1.0        1.0   0.392044\n",
      "164.0           1.0        1.0   0.496307\n",
      "165.0           1.0        2.0   0.524223\n",
      "166.0           1.0        2.0   0.921805\n",
      "167.0           1.0        1.0   0.461477\n",
      "168.0           1.0        1.0   0.031575\n",
      "169.0           1.0        2.0   0.743981\n",
      "170.0           1.0        2.0   0.913416\n",
      "171.0           1.0        2.0   0.956265\n",
      "172.0           1.0        1.0   0.164740\n",
      "173.0           1.0        2.0   0.926493\n",
      "174.0           1.0        2.0   0.508756\n",
      "175.0           1.0        1.0   0.361503\n",
      "176.0           1.0        1.0   0.099192\n",
      "177.0           1.0        2.0   0.904442\n",
      "178.0           1.0        2.0   0.878302\n",
      "179.0           1.0        2.0   0.538521\n",
      "180.0           1.0        2.0   0.708584\n",
      "181.0           2.0        2.0   0.984771\n",
      "182.0           2.0        2.0   0.969983\n",
      "183.0           2.0        2.0   0.751602\n",
      "184.0           2.0        2.0   0.947760\n",
      "185.0           2.0        2.0   0.962073\n",
      "186.0           2.0        2.0   0.787688\n",
      "187.0           2.0        2.0   0.960973\n",
      "188.0           2.0        2.0   0.915629\n",
      "189.0           2.0        2.0   0.975168\n",
      "190.0           2.0        2.0   0.814908\n",
      "191.0           2.0        2.0   0.929972\n",
      "192.0           2.0        2.0   0.913344\n",
      "193.0           2.0        2.0   0.849423\n",
      "194.0           2.0        2.0   0.962402\n",
      "195.0           2.0        2.0   0.894559\n",
      "196.0           2.0        1.0   0.200194\n",
      "197.0           2.0        2.0   0.833880\n",
      "198.0           2.0        2.0   0.858572\n",
      "199.0           2.0        1.0   0.408694\n",
      "200.0           2.0        2.0   0.771886\n",
      "201.0           2.0        2.0   0.991222\n",
      "202.0           2.0        2.0   0.988253\n",
      "203.0           2.0        1.0   0.240612\n",
      "204.0           2.0        2.0   0.606104\n",
      "205.0           2.0        2.0   0.925171\n",
      "206.0           2.0        2.0   0.917722\n",
      "207.0           2.0        2.0   0.924364\n",
      "208.0           2.0        1.0   0.380122\n",
      "209.0           2.0        2.0   0.915649\n",
      "210.0           2.0        2.0   0.959802\n",
      "211.0           2.0        1.0   0.446132\n",
      "212.0           1.0        2.0   0.780025\n",
      "213.0           1.0        2.0   0.906012\n",
      "214.0           1.0        1.0   0.259131\n",
      "215.0           1.0        1.0   0.202149\n",
      "216.0           1.0        1.0   0.441207\n",
      "217.0           1.0        2.0   0.874359\n",
      "218.0           1.0        1.0   0.117561\n",
      "219.0           1.0        2.0   0.698123\n",
      "220.0           1.0        2.0   0.839664\n",
      "221.0           1.0        2.0   0.585196\n",
      "222.0           1.0        2.0   0.667735\n",
      "223.0           1.0        1.0   0.270308\n",
      "224.0           1.0        1.0   0.271069\n",
      "225.0           1.0        2.0   0.764620\n",
      "226.0           1.0        1.0   0.403465\n",
      "Prediction Class  1.0  2.0\n",
      "Actual Class              \n",
      "1.0                43   44\n",
      "2.0                16  123\n",
      "Overall accuracy = 0.735\n",
      "Sensitivity = 0.885\n",
      "Specificity = 0.494\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

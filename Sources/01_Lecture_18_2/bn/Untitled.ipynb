{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import graphviz as gv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('train.csv', sep=',')\n",
    "df_test  = pd.read_csv('test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpgm.graphskeleton import GraphSkeleton\n",
    "from libpgm.nodedata import NodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (tablecpdfactor.py, line 235)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\ahn92\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2963\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-8-47cd7ec6d92e>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from libpgm.tablecpdfactorization import TableCPDFactorization\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ahn92\\Anaconda3\\lib\\site-packages\\libpgm\\tablecpdfactorization.py\"\u001b[1;36m, line \u001b[1;32m30\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from libpgm.tablecpdfactor import TableCPDFactor\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ahn92\\Anaconda3\\lib\\site-packages\\libpgm\\tablecpdfactor.py\"\u001b[1;36m, line \u001b[1;32m235\u001b[0m\n\u001b[1;33m    raise Exception, \"Second arg was not a possible value of first arg.\"\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from libpgm.tablecpdfactorization import TableCPDFactorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (discretebayesiannetwork.py, line 87)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\ahn92\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2963\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-19e1e1e2cd5e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from libpgm.discretebayesiannetwork import DiscreteBayesianNetwork\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ahn92\\Anaconda3\\lib\\site-packages\\libpgm\\discretebayesiannetwork.py\"\u001b[1;36m, line \u001b[1;32m87\u001b[0m\n\u001b[1;33m    raise Exception, \"Inputs were malformed; first arg must contain V and E attributes and second arg must contain Vdata attribute.\"\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from libpgm.discretebayesiannetwork import DiscreteBayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train            = df_input[['Survived', 'Pclass','Sex', 'Fare']][df_input.Fare!=0].dropna()\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.loc[:,'Sex']  = df_train.Sex.map({'female':0 , 'male':1})\n",
    "\n",
    "# Fare is arbitrary divided in two categories: cheap and expensive\n",
    "df_train.loc[:,'Fare'] = pd.cut(df_train.Fare, [df_input.Fare.min(),15, df_input.Fare.max()], labels =[0,1])\n",
    "df_train = df_train.rename(columns = {'Survived' : 'Surv'})\n",
    "df_train_target        = df_train['Surv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs_surv_cond(df, df_target, Surv, Pclass, Sex):\n",
    "    # Return survival probability conditioned on Class and Sex\n",
    "    # P(Surv | Sex, Pclass)\n",
    "    return (df[ (df.Surv==Surv) & (df.Pclass==Pclass) & (df.Sex==Sex)].shape[0]\n",
    "            /(1.0*df[(df.Pclass==Pclass) & (df.Sex==Sex)].shape[0]))\n",
    "\n",
    "def format_data(df):\n",
    "    result = []\n",
    "    for row in df.itertuples():\n",
    "        #print(row.Pclass)\n",
    "        result.append(dict(Surv= row.Surv, Class=row.Pclass , Sex=row.Sex, Fare=row.Fare ))\n",
    "    return result\n",
    "\n",
    "def calc_BNprob(df_test):\n",
    "    \n",
    "    result = pd.Series()\n",
    "    \n",
    "    for row in df_test.itertuples():\n",
    "        tablecpd=TableCPDFactorization(bn)\n",
    "        prob_surv = tablecpd.specificquery(dict(Surv='1'), dict(Fare=str(row.Fare) , Sex=str(row.Sex) , Class=str(row.Pclass) ))\n",
    "\n",
    "        if prob_surv >= 0.5:\n",
    "            surv_class = 1\n",
    "        else:\n",
    "            surv_class  = 0        \n",
    "        result = result.append(pd.Series([surv_class]), ignore_index = True )\n",
    "    return result\n",
    "\n",
    "def calc_accuracy(dff_train, dff_train_target, nb_iterations):\n",
    "    \n",
    "    result = np.zeros(nb_iterations)\n",
    "\n",
    "    for itera in range(nb_iterations):\n",
    "        XX_train, XX_test, yy_train, yy_test = train_test_split(dff_train, dff_train_target, test_size=0.33)\n",
    "        data4bn = format_data(XX_train)\n",
    "        learner = PGMLearner()\n",
    "        # estimate parameters\n",
    "        result_bn = learner.discrete_mle_estimateparams(skel, data4bn)\n",
    "        #result_bn.Vdata\n",
    "        result_predict = calc_BNprob(XX_test)\n",
    "        BN_test_probs = pd.DataFrame()\n",
    "        BN_test_probs['ground_truth'] = yy_test\n",
    "        Test_prob = pd.concat([yy_test.reset_index().Surv, result_predict],  axis = 1, ignore_index = True)\\\n",
    "                    .rename(columns = {0:'ground_truth' , 1:'class_resu'})\n",
    "        accuracy = Test_prob[Test_prob.ground_truth == Test_prob.class_resu].shape[0]/(1.0*Test_prob.shape[0])\n",
    "        #print(\"Accuracy is {}\").format(accuracy)\n",
    "        result[itera] = accuracy\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Class|Fare)\n",
      "Class= 1, 2 ,3  ; Fare = 0 (cheap):\n",
      "0.002257336343115124 0.20090293453724606 0.7968397291196389\n",
      "Class= 1, 2 ,3  ; Fare = 1 (expensive):\n",
      "0.48498845265588914 0.20554272517321015 0.3094688221709007\n",
      "------------\n",
      "P(Sex)\n",
      "Sex = 0 (female), 1 (male)\n",
      "0.3584474885844749 0.6415525114155252\n",
      "------------\n",
      "P(Surv|Class,Sex)\n",
      "Surv = 0 ,1 , Class = 1 , Sex = 0\n",
      "0.031914893617021274 0.9680851063829787\n",
      "Surv = 0 ,1 , Class = 2 , Sex = 0\n",
      "0.07894736842105263 0.9210526315789473\n",
      "Surv = 0 ,1 , Class = 3 , Sex = 0\n",
      "0.5 0.5\n",
      "Surv = 0 ,1 , Class = 1 , Sex = 1\n",
      "0.6153846153846154 0.38461538461538464\n",
      "Surv = 0 ,1 , Class = 2 , Sex = 1\n",
      "0.8333333333333334 0.16666666666666666\n",
      "Surv = 0 ,1 , Class = 3 , Sex = 1\n",
      "0.8658892128279884 0.13411078717201166\n"
     ]
    }
   ],
   "source": [
    "print (\"P(Class|Fare)\")\n",
    "print (\"Class= 1, 2 ,3  ; Fare = 0 (cheap):\")\n",
    "print(df_train[(df_train.Fare==0) & (df_train.Pclass==1)].shape[0] /(1.0*df_train[df_train.Fare==0].shape[0]),\n",
    "df_train[(df_train.Fare==0) & (df_train.Pclass==2)].shape[0] /(1.0*df_train[df_train.Fare==0].shape[0]),\n",
    "df_train[(df_train.Fare==0) & (df_train.Pclass==3)].shape[0]/(1.0*df_train[df_train.Fare==0].shape[0]))\n",
    "print (\"Class= 1, 2 ,3  ; Fare = 1 (expensive):\")\n",
    "print(df_train[(df_train.Fare==1) & (df_train.Pclass==1)].shape[0] /(1.0*df_train[df_train.Fare==1].shape[0]),\n",
    "df_train[(df_train.Fare==1) & (df_train.Pclass==2)].shape[0] /(1.0*df_train[df_train.Fare==1].shape[0]),\n",
    "df_train[(df_train.Fare==1) & (df_train.Pclass==3)].shape[0]/(1.0*df_train[df_train.Fare==1].shape[0]))\n",
    "\n",
    "#Sex: Prior probability\n",
    "print(\"------------\")\n",
    "print (\"P(Sex)\")\n",
    "print (\"Sex = 0 (female), 1 (male)\")\n",
    "print (df_train[df_train.Sex==0].shape[0]/float(df_train.Sex.shape[0]) , \n",
    "       df_train[df_train.Sex==1].shape[0]/float(df_train.Sex.shape[0]))\n",
    "\n",
    "# Surv Probability\n",
    "print(\"------------\")\n",
    "print(\"P(Surv|Class,Sex)\")\n",
    "print(\"Surv = 0 ,1 , Class = 1 , Sex = 0\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 1, 0),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 1, 0))\n",
    "print(\"Surv = 0 ,1 , Class = 2 , Sex = 0\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 2, 0),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 2, 0))\n",
    "print(\"Surv = 0 ,1 , Class = 3 , Sex = 0\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 3, 0),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 3, 0))\n",
    "print(\"Surv = 0 ,1 , Class = 1 , Sex = 1\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 1, 1),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 1, 1))\n",
    "print(\"Surv = 0 ,1 , Class = 2 , Sex = 1\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 2, 1),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 2, 1))\n",
    "print(\"Surv = 0 ,1 , Class = 3 , Sex = 1\")\n",
    "print(get_probs_surv_cond(df_train, df_train_target, 0, 3, 1),\n",
    "get_probs_surv_cond(df_train, df_train_target, 1, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NodeData' object has no attribute 'dictload'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a37e65292e2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjsonpath_skel\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"titanic_skel.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mjsonpath_node\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"titanic_nodes.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonpath_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mskel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonpath_skel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\libpgm\\nodedata.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         '''\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# try to load both for normal and dynamic cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NodeData' object has no attribute 'dictload'"
     ]
    }
   ],
   "source": [
    "nd       = NodeData()\n",
    "skel     = GraphSkeleton()\n",
    "jsonpath_skel =\"titanic_skel.json\"\n",
    "jsonpath_node =\"titanic_nodes.json\"\n",
    "nd.load(jsonpath_node)\n",
    "skel.load(jsonpath_skel)\n",
    "\n",
    "# load bayesian network\n",
    "bn       = DiscreteBayesianNetwork(skel, nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

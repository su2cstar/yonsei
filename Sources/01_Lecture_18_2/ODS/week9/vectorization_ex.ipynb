{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer # frequency based DTM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf based DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features, columns=feature_names)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_extractor(corpus): \n",
    "    # returns a frequency-based DTM\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "    # min_df: minimum document frequency threshold\n",
    "         # if min_df = 1 -> 최소 적어도 하나의 문서에서 사용된 단어들은 모두 포함\n",
    "    # ngram_range=(1,1) -> unigram 만 포함\n",
    "    # ngram_range=(1,3) -> unigram, bi-gram, tri-gram 까지 고려\n",
    "    features = vectorizer.fit_transform(corpus) # transform texts to a frequency matrix\n",
    "    return vectorizer, features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus):\n",
    "    # returns a tf-idf based DTM\n",
    "    vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the corpus is composed of 4 documents\n",
    "CORPUS = [\n",
    "'the sky is blue',\n",
    "'sky is blue and sky is beautiful',\n",
    "'the beautiful sky is so blue',\n",
    "'i love blue cheese'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 6)\t2\n",
      "  (2, 7)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer, tf_features = tf_extractor(CORPUS)\n",
    "# You should remember what type of input data is provided\n",
    "# CORPUS: a list of sentences\n",
    "\n",
    "print(tf_features) # this prints out the words used in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (0,2)   1 -> index 2에 해당하는 단어가 0번 문서에서 1번 사용되었다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 1, 0, 2, 0, 2, 0, 0],\n",
       "        [0, 1, 1, 0, 1, 0, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf_features.todense()\n",
    "features # nd array, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'and' -> 0\n",
    "'beautiful' -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  beautiful  blue  cheese  is  love  sky  so  the\n",
      "0    0          0     1       0   1     0    1   0    1\n",
      "1    1          1     1       0   2     0    2   0    0\n",
      "2    0          1     1       0   1     0    1   1    1\n",
      "3    0          0     1       1   0     1    0   0    0\n"
     ]
    }
   ],
   "source": [
    "display_features(features, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    and  beautiful  blue  cheese    is  love   sky    so   the\n",
      "0  0.00       0.00  0.40    0.00  0.49  0.00  0.49  0.00  0.60\n",
      "1  0.44       0.35  0.23    0.00  0.56  0.00  0.56  0.00  0.00\n",
      "2  0.00       0.43  0.29    0.00  0.35  0.00  0.35  0.55  0.43\n",
      "3  0.00       0.00  0.35    0.66  0.00  0.66  0.00  0.00  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sang\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, tdidf_features = tfidf_extractor(CORPUS)\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "display_features(np.round(tdidf_features.todense(), 2), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

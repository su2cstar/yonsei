{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_extractor(corpus):  \n",
    "    # returns a frequency-based DTM\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1)) \n",
    "    features = vectorizer.fit_transform(corpus) # transform texts to a frequency matrix\n",
    "    return vectorizer, features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus):\n",
    "    # returns a tf-idf based DTM\n",
    "    vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('2016_filtered_review.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t\\t') for doc in f]\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    # To read the second and third column info from each row\n",
    "    texts, scores = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_texts = []\n",
    "filtered_labels = []\n",
    "\n",
    "for text, score in zip(texts, scores):\n",
    "    if 4 <= score <= 8:\n",
    "        continue\n",
    "        \n",
    "    # 평점 기준으로 문서에 label을 부여\n",
    "    # 1 ~ 4 -> 부정, -1\n",
    "    # 8 ~ 10 -> 긍정, 1\n",
    "    filtered_texts.append(text)\n",
    "    filtered_labels.append(1 if score > 8 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews = len(filtered_texts) #788189\n",
    "\n",
    "num_train = int(num_reviews*0.7) #551732\n",
    "# 전체 리뷰 중에서 70%를 training data로 사용하고, 나머지 30%를 test data로 사용\n",
    "train_texts = filtered_texts[:num_train]\n",
    "train_labels = filtered_labels[:num_train]\n",
    "test_texts = filtered_texts[num_train+1:]\n",
    "test_labels = filtered_labels[num_train+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can also use the following method\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(filtered_texts, filtered_labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer, train_tf_features = tf_extractor(train_texts)\n",
    "# input의 형태 = list of docs\n",
    "test_tf_features = tf_vectorizer.transform(test_texts)\n",
    "vocablist = [word for word, _ in sorted(tf_vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "# tf_vectorizer.vocabulary_.items() returns a list of (word, frequency)\n",
    "# We sort words based on their frequencies and save the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 10766 out of 164522\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# tf matrix를 사용한 경우\n",
    "lr = LogisticRegression(C=0.1, penalty='l2', random_state=0) # Lasso regression\n",
    "# C = Inverse of regularization strength, 즉 C 값이 작을수록 penalty를 많이 준다는 것입니다.\n",
    "# penalty를 많이 준다는 뜻은 L1 같은 경우는 feature의 수를 그만큼 많이 줄인다는 뜻이고\n",
    "# L2인 경우는 weight 값을 더 0에 가깝게 한다는 뜻입니다.\n",
    "lr.fit(train_tf_features, train_labels) # 학습\n",
    "pred_labels = lr.predict(test_tf_features)\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sang\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 12071 out of 164522\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# tfidf matrix를 사용한 경우\n",
    "tfidf_vectorizer, train_tfidf_features = tfidf_extractor(train_texts)\n",
    "test_tfidf_features = tfidf_vectorizer.transform(test_texts)\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', random_state=0) # Lasso regression\n",
    "lr.fit(train_tfidf_features, train_labels) # 학습\n",
    "pred_labels = lr.predict(test_tfidf_features)\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8296, 2.724390737323108), (50360, 2.5960653247932326), (50295, 2.5225153393315187), (49708, 2.5213259573042963), (49727, 2.370122339054413)]\n",
      "꿀잼 (2.724)\n",
      "재밌었 (2.596)\n",
      "재밌게 (2.523)\n",
      "재미있게 (2.521)\n",
      "재미있었 (2.370)\n",
      "재밌어 (2.360)\n",
      "재미있어 (2.052)\n",
      "여운 (2.024)\n",
      "재밌네 (1.985)\n",
      "재미있네 (1.944)\n",
      "존잼 (1.884)\n",
      "강추 (1.866)\n",
      "재밌고 (1.839)\n",
      "최고 (1.750)\n",
      "재미있 (1.740)\n",
      "재밌 (1.735)\n",
      "재밋어 (1.725)\n",
      "테러 (1.701)\n",
      "최고다 (1.688)\n",
      "재밌던 (1.679)\n",
      "지루하지 (1.670)\n",
      "즐겁 (1.667)\n",
      "굿굿 (1.665)\n",
      "재밋 (1.657)\n",
      "낮아 (1.655)\n",
      "개꿀잼 (1.631)\n",
      "지루할 (1.608)\n",
      "흥미진진 (1.585)\n",
      "대박 (1.582)\n",
      "수작 (1.575)\n",
      "재밋음 (1.539)\n",
      "울었 (1.522)\n",
      "재미있고 (1.504)\n",
      "빠져 (1.501)\n",
      "졸잼 (1.477)\n",
      "감탄 (1.475)\n",
      "가는 (1.474)\n",
      "가슴 (1.470)\n",
      "심장 (1.462)\n",
      "유쾌 (1.423)\n",
      "재미나 (1.412)\n",
      "사랑해 (1.388)\n",
      "탄탄 (1.379)\n",
      "재밌는 (1.376)\n",
      "만점 (1.351)\n",
      "충분히 (1.347)\n",
      "즐거운 (1.330)\n",
      "만족 (1.322)\n",
      "케미 (1.309)\n",
      "슬펐 (1.305)\n",
      "팔이 (-1.505)\n",
      "삼류 (-1.507)\n",
      "억지로 (-1.532)\n",
      "알바 (-1.552)\n",
      "클레멘타인 (-1.567)\n",
      "자다 (-1.593)\n",
      "미화 (-1.599)\n",
      "망했 (-1.601)\n",
      "짜증 (-1.621)\n",
      "졸다 (-1.632)\n",
      "신파극 (-1.643)\n",
      "아깝 (-1.644)\n",
      "나가고 (-1.646)\n",
      "하품 (-1.667)\n",
      "왜곡 (-1.669)\n",
      "별루 (-1.670)\n",
      "아까웠 (-1.680)\n",
      "망쳐 (-1.683)\n",
      "없고 (-1.735)\n",
      "불륜 (-1.743)\n",
      "거품 (-1.771)\n",
      "지루해 (-1.773)\n",
      "실망했 (-1.779)\n",
      "거르 (-1.781)\n",
      "졸려 (-1.782)\n",
      "광구 (-1.797)\n",
      "별로 (-1.799)\n",
      "아까운 (-1.802)\n",
      "엉망 (-1.824)\n",
      "그닥 (-1.835)\n",
      "낭비 (-1.868)\n",
      "불면증 (-1.871)\n",
      "억지 (-1.874)\n",
      "비추 (-1.927)\n",
      "재미없 (-1.938)\n",
      "지루해서 (-1.957)\n",
      "실망 (-1.996)\n",
      "망작 (-2.007)\n",
      "역사왜곡 (-2.040)\n",
      "졸작 (-2.073)\n",
      "졸았 (-2.096)\n",
      "지루하고 (-2.112)\n",
      "이하 (-2.200)\n",
      "지루했 (-2.224)\n",
      "아까 (-2.337)\n",
      "아까워 (-2.350)\n",
      "쓰레기 (-2.383)\n",
      "차라리 (-2.418)\n",
      "노잼 (-3.149)\n",
      "최악 (-3.723)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "print(sorted_coefficients[:5])\n",
    "# print top 50 positive words\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "# print top 50 negative words\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

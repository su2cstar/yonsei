{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_extractor(corpus):  \n",
    "    # returns a frequency-based DTM\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1)) \n",
    "    features = vectorizer.fit_transform(corpus) # transform texts to a frequency matrix\n",
    "    return vectorizer, features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus):\n",
    "    # returns a tf-idf based DTM\n",
    "    vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2016_filtered_review.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-861d9a06fac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2016_filtered_review.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# To read the second and third column info from each row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2016_filtered_review.txt'"
     ]
    }
   ],
   "source": [
    "with open('2016_filtered_review.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t\\t') for doc in f]\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    # To read the second and third column info from each row\n",
    "    texts, scores = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "df = pd.read_csv('merged_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = tuple(df.iloc[:,3])\n",
    "texts = tuple(df.iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_texts = []\n",
    "filtered_labels = []\n",
    "\n",
    "for text, score in zip(texts, scores):\n",
    "    if 4 <= score <= 8:\n",
    "        continue\n",
    "        \n",
    "    # 평점 기준으로 문서에 label을 부여\n",
    "    # 1 ~ 4 -> 부정, -1\n",
    "    # 8 ~ 10 -> 긍정, 1\n",
    "    filtered_texts.append(text)\n",
    "    filtered_labels.append(1 if score > 8 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reviews = len(filtered_texts) #788189\n",
    "\n",
    "num_train = int(num_reviews*0.7) #551732\n",
    "# 전체 리뷰 중에서 70%를 training data로 사용하고, 나머지 30%를 test data로 사용\n",
    "train_texts = filtered_texts[:num_train]\n",
    "train_labels = filtered_labels[:num_train]\n",
    "test_texts = filtered_texts[num_train+1:]\n",
    "test_labels = filtered_labels[num_train+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the following method\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(filtered_texts, filtered_labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer, train_tf_features = tf_extractor(train_texts)\n",
    "# input의 형태 = list of docs\n",
    "test_tf_features = tf_vectorizer.transform(test_texts)\n",
    "vocablist = [word for word, _ in sorted(tf_vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "# tf_vectorizer.vocabulary_.items() returns a list of (word, frequency)\n",
    "# We sort words based on their frequencies and save the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jydev/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 19173 out of 170106\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# tf matrix를 사용한 경우\n",
    "lr = LogisticRegression(C=0.1, penalty='l2', random_state=0) # Lasso regression\n",
    "# C = Inverse of regularization strength, 즉 C 값이 작을수록 penalty를 많이 준다는 것입니다.\n",
    "# penalty를 많이 준다는 뜻은 L1 같은 경우는 feature의 수를 그만큼 많이 줄인다는 뜻이고\n",
    "# L2인 경우는 weight 값을 더 0에 가깝게 한다는 뜻입니다.\n",
    "lr.fit(train_tf_features, train_labels) # 학습\n",
    "pred_labels = lr.predict(test_tf_features)\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 24484 out of 170106\n",
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# tfidf matrix를 사용한 경우\n",
    "tfidf_vectorizer, train_tfidf_features = tfidf_extractor(train_texts)\n",
    "test_tfidf_features = tfidf_vectorizer.transform(test_texts)\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', random_state=0) # Lasso regression\n",
    "lr.fit(train_tfidf_features, train_labels) # 학습\n",
    "pred_labels = lr.predict(test_tfidf_features)\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(504279, 9.659400584263386), (440515, 8.851325781716714), (467113, 8.7756171900682), (352347, 8.07702074475683), (437736, 7.884602329433185)]\n",
      "최고 (9.659)\n",
      "재밌었어요 (8.851)\n",
      "좋았어요 (8.776)\n",
      "여운이 (8.077)\n",
      "재밌게 (7.885)\n",
      "재밌어요 (7.775)\n",
      "꿀잼 (7.541)\n",
      "재미있게 (7.511)\n",
      "좋았습니다 (7.149)\n",
      "눈물이 (7.026)\n",
      "재밌었음 (6.832)\n",
      "재밌고 (6.356)\n",
      "좋고 (6.290)\n",
      "재미있었어요 (6.211)\n",
      "최고다 (6.084)\n",
      "좋았고 (5.742)\n",
      "좋았다 (5.712)\n",
      "최고의 (5.666)\n",
      "역시 (5.642)\n",
      "존잼 (5.604)\n",
      "재밌는데 (5.537)\n",
      "마음이 (5.503)\n",
      "봤어요 (5.427)\n",
      "재밌다 (5.367)\n",
      "좋았음 (5.341)\n",
      "좋아요 (5.338)\n",
      "대박 (5.315)\n",
      "재밌음 (5.241)\n",
      "강추 (5.150)\n",
      "재미있어요 (5.121)\n",
      "최고입니다 (5.024)\n",
      "믿고보는 (4.943)\n",
      "재밌었다 (4.823)\n",
      "지루하지 (4.821)\n",
      "모르고 (4.712)\n",
      "개꿀잼 (4.676)\n",
      "주지훈 (4.623)\n",
      "재밌었습니다 (4.603)\n",
      "오랜만에 (4.571)\n",
      "감동 (4.447)\n",
      "아름다운 (4.444)\n",
      "아깝지 (4.431)\n",
      "인생영화 (4.370)\n",
      "소름 (4.352)\n",
      "재밌습니다 (4.315)\n",
      "있는 (4.289)\n",
      "재미있고 (4.251)\n",
      "감사합니다 (4.196)\n",
      "가슴이 (4.176)\n",
      "간만에 (4.091)\n",
      "보다가 (-4.947)\n",
      "ㅡㅡ (-5.008)\n",
      "영화냐 (-5.055)\n",
      "돈주고 (-5.072)\n",
      "지루함 (-5.080)\n",
      "고구마 (-5.108)\n",
      "억지 (-5.182)\n",
      "졸작 (-5.212)\n",
      "개연성도 (-5.267)\n",
      "이걸 (-5.291)\n",
      "무슨 (-5.420)\n",
      "내돈 (-5.448)\n",
      "알바가 (-5.480)\n",
      "재미없어서 (-5.481)\n",
      "2점 (-5.521)\n",
      "0점 (-5.616)\n",
      "거르는 (-5.668)\n",
      "알바 (-5.671)\n",
      "알바들 (-5.686)\n",
      "유치하고 (-5.793)\n",
      "억지로 (-5.855)\n",
      "동성애는 (-5.904)\n",
      "0점은 (-6.114)\n",
      "지루해서 (-6.173)\n",
      "없고 (-6.231)\n",
      "재미없는 (-6.267)\n",
      "쓰레기영화 (-6.320)\n",
      "그나마 (-6.708)\n",
      "최악이다 (-6.842)\n",
      "재미없고 (-7.014)\n",
      "아까운 (-7.101)\n",
      "1점도 (-7.240)\n",
      "재미없다 (-7.241)\n",
      "에이즈 (-7.251)\n",
      "보지마세요 (-7.467)\n",
      "핵노잼 (-7.703)\n",
      "개연성 (-7.862)\n",
      "이딴 (-7.934)\n",
      "아까움 (-7.985)\n",
      "망작 (-8.012)\n",
      "재미없어요 (-8.143)\n",
      "재미없음 (-8.335)\n",
      "개노잼 (-8.612)\n",
      "쓰레기 (-9.025)\n",
      "지루하고 (-9.724)\n",
      "노잼 (-11.439)\n",
      "차라리 (-11.461)\n",
      "최악 (-11.597)\n",
      "최악의 (-12.358)\n",
      "아깝다 (-12.485)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "print(sorted_coefficients[:5])\n",
    "# print top 50 positive words\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "# print top 50 negative words\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
